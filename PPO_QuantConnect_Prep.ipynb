{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/exploratory_daytrading/blob/main/PPO_QuantConnect_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run to get paramaters for QuantConnect (from this codes output)\n",
        "#get live_signals.json → the output your backtest consumes."
      ],
      "metadata": {
        "id": "EtHqFF5L3EKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y opencv-python opencv-python-headless opencv-contrib-python"
      ],
      "metadata": {
        "id": "hSXunPFBywlh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall stuff that conflicts with a PyTorch+SB3+Gymnasium workflow (safe if absent)\n",
        "!pip -q uninstall -y \\\n",
        "  gym gymnasium shimmy stable-baselines3 dopamine-rl \\\n",
        "  tensorflow tensorflow-hub tf-keras tensorflow-text tensorflow-decision-forests \\\n",
        "  cudf-cu12 dask-cudf-cu12 dask-cuda rapids-dask-dependency \\\n",
        "  libcudf-cu12 libcuml-cu12 pylibcudf-cu12 pylibraft-cu12 \\\n",
        "  libcugraph-cu12 pylibcugraph-cu12 rmm-cu12 libcuvs-cu12 cuvs-cu12 \\\n",
        "  cupy-cuda12x opencv-python opencv-python-headless opencv-contrib-python || true\n",
        "\n",
        "# PyTorch (CUDA 12.4 wheels that match Colab GPU VMs)\n",
        "!pip -q install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio\n",
        "\n",
        "# Core RL/ML stack pinned to avoid Colab’s resolver nags\n",
        "# - pandas==2.2.2 and requests==2.32.4 match google-colab’s constraints\n",
        "# - numpy==2.0.2 avoids the OpenCV / numba complaints and works fine with SB3\n",
        "!pip -q install -U \\\n",
        "  \"protobuf>=5.29.1,<6\" \\\n",
        "  \"gymnasium>=1.1,<1.3\" \\\n",
        "  \"stable-baselines3==2.7.0\" \\\n",
        "  \"numpy==2.0.2\" \"pandas==2.2.2\" \"requests==2.32.4\" \\\n",
        "  yfinance pywavelets transformers python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtTdPuFmmfuU",
        "outputId": "ee014afd-8094-4f86-d3e4-a0f2255fef9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping shimmy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping stable-baselines3 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.3/944.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shell cell\n",
        "!pip -q install \"opencv-python-headless==4.12.0.88\""
      ],
      "metadata": {
        "id": "-8l2uyRI00wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, shutil\n",
        "for p in glob.glob('/usr/local/lib/python*/dist-packages/~*'):\n",
        "    print(\"Removing\", p)\n",
        "    shutil.rmtree(p, ignore_errors=True)\n"
      ],
      "metadata": {
        "id": "DqOLGvBfspsh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SB3-safe cv2 shim: run this BEFORE `import stable_baselines3 as sb3`\n",
        "import sys, types\n",
        "try:\n",
        "    import cv2  # Colab may auto-load a minimal cv2\n",
        "except Exception:\n",
        "    cv2 = None\n",
        "\n",
        "if cv2 is None:\n",
        "    cv2 = types.ModuleType(\"cv2\")\n",
        "    cv2.ocl = types.SimpleNamespace(setUseOpenCL=lambda *a, **k: None)\n",
        "    sys.modules[\"cv2\"] = cv2\n",
        "else:\n",
        "    if not hasattr(cv2, \"ocl\"):\n",
        "        cv2.ocl = types.SimpleNamespace(setUseOpenCL=lambda *a, **k: None)\n",
        "    elif not hasattr(cv2.ocl, \"setUseOpenCL\"):\n",
        "        cv2.ocl.setUseOpenCL = lambda *a, **k: None\n",
        "\n",
        "# Now safe to import SB3 & friends\n",
        "import torch, gymnasium, stable_baselines3 as sb3, transformers, pandas as pd, numpy as np\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda, \"| GPU:\", torch.cuda.is_available())\n",
        "print(\"Gymnasium:\", gymnasium.__version__)\n",
        "print(\"SB3:\", sb3.__version__)\n",
        "print(\"Transformers:\", transformers.__version__)\n",
        "print(\"pandas:\", pd.__version__, \"| numpy:\", np.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-lNJSkXstmf",
        "outputId": "ffa7b3d1-8b1f-4e5e-9598-f40d4b500661"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA: 12.6 | GPU: False\n",
            "Gymnasium: 1.2.0\n",
            "SB3: 2.7.0\n",
            "Transformers: 4.56.1\n",
            "pandas: 2.2.2 | numpy: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shimmy_needed = False\n",
        "try:\n",
        "    import gym_anytrading  # legacy gym-based\n",
        "    shimmy_needed = True\n",
        "    print(\"Detected gym-anytrading → Shimmy wrapper recommended.\")\n",
        "except Exception:\n",
        "    print(\"gym-anytrading not installed → Shimmy not needed.\")\n",
        "\n",
        "print(\"Shimmy needed? \", shimmy_needed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoCOU9Sas6_T",
        "outputId": "38fab575-3924-436f-fa87-605244c2a75e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gym-anytrading not installed → Shimmy not needed.\n",
            "Shimmy needed?  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gym-anytrading shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKPWP-Pps-oS",
        "outputId": "312a9137-fc77-4d98-cb2b-0325f8844233"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/172.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Where you keep all PPO artifacts\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "# Pick a symbol/prefix you’re uploading for (repeat for CVX, etc.)\n",
        "PREFIX = \"ppo_GE_window1\"   # change to \"ppo_CVX_window1\" when uploading CVX files\n",
        "\n",
        "# === 1) Upload PPO artifacts from your local machine ===\n",
        "# Expecting files named exactly like:\n",
        "#   ppo_GE_window1_model.zip\n",
        "#   ppo_GE_window1_vecnorm.pkl\n",
        "#   ppo_GE_window1_features.json\n",
        "# (optionally) ppo_GE_window1_probability_config.json, ppo_GE_window1_model_info.json\n",
        "uploaded = files.upload()   # choose the files above\n",
        "\n",
        "# Persist uploads to your MASTER_DIR\n",
        "for name, data in uploaded.items():\n",
        "    # Ensure file exists on the runtime filesystem (Colab sometimes does this automatically)\n",
        "    with open(name, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    # Move into your master artifacts folder\n",
        "    shutil.move(name, os.path.join(MASTER_DIR, name))\n",
        "\n",
        "print(\"Saved to:\", MASTER_DIR)\n",
        "print(sorted([f for f in os.listdir(MASTER_DIR) if f.startswith(PREFIX)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Lbr47SbWC5HP",
        "outputId": "823db666-9dd7-4d0a-a96f-f3db2885d601"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-57092073-7374-4a58-a2b2-3566f95fd048\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-57092073-7374-4a58-a2b2-3566f95fd048\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ppo_GE_window1_features.json to ppo_GE_window1_features.json\n",
            "Saving ppo_GE_window1_model_info.json to ppo_GE_window1_model_info.json\n",
            "Saving ppo_GE_window1_model.zip to ppo_GE_window1_model.zip\n",
            "Saving ppo_GE_window1_probability_config.json to ppo_GE_window1_probability_config.json\n",
            "Saving ppo_GE_window1_vecnorm.pkl to ppo_GE_window1_vecnorm.pkl\n",
            "Saved to: /content/drive/MyDrive/Results_May_2025/ppo_models_master\n",
            "['ppo_GE_window1_features.json', 'ppo_GE_window1_model.zip', 'ppo_GE_window1_model_info.json', 'ppo_GE_window1_probability_config.json', 'ppo_GE_window1_vecnorm.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Upload your local env file (e.g., Github.env.txt or .env.github)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # run this cell and choose the file"
      ],
      "metadata": {
        "id": "fK_jkdQlHB3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "677da2e2-2b3e-424d-c109-efbbc3ea57d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28d4bf7e-ab10-4f87-ad00-5af8c1b708ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28d4bf7e-ab10-4f87-ad00-5af8c1b708ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Github_key.env.txt to Github_key.env.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2) Rename to .env (only if your filename isn't already \".env\")\n",
        "import os\n",
        "if \"Github_key.env.txt\" in uploaded:\n",
        "    os.rename(\"Github_key.env.txt\", \".env\")    # adjust if your uploaded name differs\n"
      ],
      "metadata": {
        "id": "5We3sEjgpqhb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, shutil\n",
        "\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "PREFIX = \"ppo_GE_window1\"  # change to ppo_CVX_window1 for CVX\n",
        "\n",
        "# Only upload if the key files are missing\n",
        "needed = [f\"{PREFIX}_model.zip\", f\"{PREFIX}_vecnorm.pkl\", f\"{PREFIX}_features.json\"]\n",
        "missing = [f for f in needed if not os.path.exists(os.path.join(MASTER_DIR, f))]\n",
        "if missing:\n",
        "    from google.colab import files\n",
        "    print(\"Missing:\", missing, \"\\nPlease upload the listed files.\")\n",
        "    uploaded = files.upload()\n",
        "    for name, data in uploaded.items():\n",
        "        with open(name, \"wb\") as f:\n",
        "            f.write(data)\n",
        "        shutil.move(name, os.path.join(MASTER_DIR, name))\n",
        "    print(\"Saved to:\", MASTER_DIR)\n",
        "\n",
        "# Token: prefer .env OR set once in-session, not both\n",
        "token = os.getenv(\"GITHUB_TOKEN\")\n",
        "if not token:\n",
        "    try:\n",
        "        # If you keep secrets in a .env file on Drive:\n",
        "        # !pip -q install python-dotenv\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv(\".env\")\n",
        "        token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if not token:\n",
        "    # Last-resort secure prompt (doesn't echo)\n",
        "    from getpass import getpass\n",
        "    token = getpass(\"Paste your GitHub token (won't be printed): \").strip()\n",
        "    os.environ[\"GITHUB_TOKEN\"] = token\n",
        "\n",
        "print(\"Artifacts present:\", all(os.path.exists(os.path.join(MASTER_DIR, f)) for f in needed))\n",
        "print(\"Token present?   \", bool(os.getenv(\"GITHUB_TOKEN\")))\n"
      ],
      "metadata": {
        "id": "t-MxocSjHIiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88263afc-f339-4266-eb04-ccb00eace4f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifacts present: True\n",
            "Token present?    True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------- 3) IMPORTS -------------------------------------------\n",
        "import os, json, time, logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import yfinance as yf\n",
        "\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# gym-anytrading (legacy Gym API); harmless banner may print on import\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "from gymnasium.spaces import Box as GBox\n",
        "\n",
        "# ---------------------------------- 4) LOGGING & COLAB DRIVE ---------------------------------\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "L = logging.getLogger(\"producer\")\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    if not os.path.ismount(\"/content/drive\"):\n",
        "        drive.mount(\"/content/drive\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ---------------------------------- 5) PATHS & CONFIG ----------------------------------------\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")   # where <prefix>_model.zip etc. live\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "STATE_DIR    = \"/content/drive/MyDrive/QuantConnect_Ready\"\n",
        "os.makedirs(STATE_DIR, exist_ok=True)\n",
        "GIST_ID_PATH = os.path.join(STATE_DIR, \"live_signals_gist_id.txt\")\n",
        "\n",
        "# Which models to publish\n",
        "PICKS: Dict[str, str] = {\n",
        "    \"GE\":  \"ppo_GE_window1\",\n",
        "    \"CVX\": \"ppo_CVX_window1\",    # leave in; will gracefully warn if artifacts missing\n",
        "}\n",
        "\n",
        "# yfinance fetch params\n",
        "YF_INTERVAL = \"1m\"   # 1-minute bars\n",
        "YF_DAYS     = 5      # yfinance supports about 7 days of 1m history\n",
        "\n",
        "# ---------------------------------- 6) AUTH / SECRETS ----------------------------------------\n",
        "# Load .env if present; otherwise you can set os.environ[\"GITHUB_TOKEN\"] = \"ghp_...\"\n",
        "if os.path.exists(\".env\"):\n",
        "    load_dotenv(\".env\")\n",
        "\n",
        "GITHUB_TOKEN  = os.environ.get(\"GITHUB_TOKEN\", \"\").strip()\n",
        "GIST_ID       = os.environ.get(\"GIST_ID\", \"\").strip()        # optional override; else persisted to file\n",
        "GIST_FILENAME = \"live_signals.json\"\n",
        "GIST_DESC     = \"Live PPO signals for QC (Producer→Consumer)\"\n",
        "\n",
        "# ---------------------------------- 7) OPTIONAL UPLOAD (INTERACTIVE) -------------------------\n",
        "# If you need to upload artifacts from your local machine, set this True and follow the prompt.\n",
        "ENABLE_INTERACTIVE_UPLOAD = False\n",
        "UPLOAD_PREFIX = \"ppo_GE_window1\"   # change to \"ppo_CVX_window1\" to upload CVX\n",
        "\n",
        "if ENABLE_INTERACTIVE_UPLOAD:\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        needed = [f\"{UPLOAD_PREFIX}_model.zip\", f\"{UPLOAD_PREFIX}_vecnorm.pkl\", f\"{UPLOAD_PREFIX}_features.json\"]\n",
        "        missing = [f for f in needed if not os.path.exists(os.path.join(MASTER_DIR, f))]\n",
        "        if missing:\n",
        "            print(\"Missing files:\", missing)\n",
        "            print(\"Please upload the listed files (they will be moved into ppo_models_master).\")\n",
        "            uploaded = files.upload()\n",
        "            for name, data in uploaded.items():\n",
        "                with open(name, \"wb\") as f:\n",
        "                    f.write(data)\n",
        "                shutil.move(name, os.path.join(MASTER_DIR, name))\n",
        "            print(\"Saved to:\", MASTER_DIR)\n",
        "    except Exception as e:\n",
        "        print(\"Upload step skipped or failed:\", e)\n",
        "\n",
        "# ---------------------------------- 8) FEATURE PIPELINE (DUMMY) ------------------------------\n",
        "# Replace with your real feature computation if you have one.\n",
        "def compute_enhanced_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df_in\n",
        "\n",
        "# ---------------------------------- 9) TRADING ENV (StocksEnv → Gymnasium) -------------------\n",
        "class ContinuousPositionEnv(StocksEnv):\n",
        "    \"\"\"\n",
        "    Wraps gym_anytrading.envs.StocksEnv (legacy Gym) but returns Gymnasium-style (obs, reward, terminated, truncated, info).\n",
        "    Action: continuous position target in [-1, +1].\n",
        "    \"\"\"\n",
        "    def __init__(self, df, frame_bound, window_size,\n",
        "                 cost_rate=0.0002, slip_rate=0.0003,\n",
        "                 k_alpha=0.20, k_mom=0.05, k_sent=0.0,\n",
        "                 mom_source=\"denoised\", mom_lookback=20,\n",
        "                 min_trade_delta=0.01, cooldown=5, reward_clip=1.0):\n",
        "        super().__init__(df=df.reset_index(drop=True), frame_bound=frame_bound, window_size=window_size)\n",
        "        # Ensure spaces are Gymnasium Boxes\n",
        "        if isinstance(self.observation_space, gym.spaces.Box):\n",
        "            self.observation_space = GBox(\n",
        "                low=self.observation_space.low,\n",
        "                high=self.observation_space.high,\n",
        "                shape=self.observation_space.shape,\n",
        "                dtype=self.observation_space.dtype,\n",
        "            )\n",
        "        self.action_space = GBox(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "        self.cost_rate, self.slip_rate = float(cost_rate), float(slip_rate)\n",
        "        self.k_alpha, self.k_mom = float(k_alpha), float(k_mom)\n",
        "        self.k_sent = float(k_sent)\n",
        "        self.mom_source, self.mom_lookback = str(mom_source), int(mom_lookback)\n",
        "        self.min_trade_delta, self.cooldown = float(min_trade_delta), int(cooldown)\n",
        "        self.reward_clip = float(reward_clip)\n",
        "\n",
        "        self.nav, self.pos, self._last_trade_step = 1.0, 0.0, -self.cooldown\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        out = super().reset(**kwargs)\n",
        "        obs, info = (out if isinstance(out, tuple) else (out, {}))\n",
        "        self.nav, self.pos, self._last_trade_step = 1.0, 0.0, -self.cooldown\n",
        "        info = info or {}\n",
        "        info.update({\"nav\": self.nav, \"pos\": self.pos})\n",
        "        return obs, info\n",
        "\n",
        "    def _step_parent_hold(self):\n",
        "        # Parent env uses discrete actions; action 2 = HOLD (no-op)\n",
        "        step_result = super().step(2)\n",
        "        if len(step_result) == 5:  # already Gymnasium format\n",
        "            obs, _env_rew, terminated, truncated, info = step_result\n",
        "        else:                      # legacy Gym 4-tuple\n",
        "            obs, _env_rew, done, info = step_result\n",
        "            terminated, truncated = bool(done), False\n",
        "        return obs, terminated, truncated, info\n",
        "\n",
        "    def _ret_t(self):\n",
        "        cur  = float(self.df.loc[self._current_tick, 'Close'])\n",
        "        prev = float(self.df.loc[max(self._current_tick - 1, 0), 'Close'])\n",
        "        return 0.0 if prev <= 0 else (cur - prev) / prev\n",
        "\n",
        "    def _mom_signal(self):\n",
        "        if self.mom_source == \"macd\" and \"MACD_Line\" in self.df.columns:\n",
        "            recent = self.df[\"MACD_Line\"].iloc[max(self._current_tick-200,0):self._current_tick+1]\n",
        "            return float(np.tanh(float(self.df.loc[self._current_tick, \"MACD_Line\"]) / (1e-6 + recent.std())))\n",
        "        if \"Denoised_Close\" in self.df.columns and self._current_tick - self.mom_lookback >= 0:\n",
        "            now  = float(self.df.loc[self._current_tick, \"Denoised_Close\"])\n",
        "            then = float(self.df.loc[self._current_tick - self.mom_lookback, \"Denoised_Close\"])\n",
        "            base = float(self.df.loc[max(self._current_tick - 1, 0), \"Close\"])\n",
        "            slope = (now - then) / max(self.mom_lookback, 1)\n",
        "            return float(np.tanh(10.0 * (slope / max(abs(base), 1e-6))))\n",
        "        return 0.0\n",
        "\n",
        "    def step(self, action):\n",
        "        a = float(np.array(action).squeeze())\n",
        "        target_pos = float(np.clip(a, -1.0, 1.0))\n",
        "\n",
        "        r_t = self._ret_t()\n",
        "        base_ret = self.pos * r_t\n",
        "\n",
        "        changed = (abs(target_pos - self.pos) >= self.min_trade_delta) and \\\n",
        "                  ((self._current_tick - self._last_trade_step) >= self.cooldown)\n",
        "        delta_pos = (target_pos - self.pos) if changed else 0.0\n",
        "        trade_cost = (self.cost_rate + self.slip_rate) * abs(delta_pos)\n",
        "\n",
        "        rel_alpha  = base_ret - r_t\n",
        "        mom_term   = self.pos * self._mom_signal()\n",
        "        shaped     = base_ret + self.k_alpha*rel_alpha + self.k_mom*mom_term - trade_cost\n",
        "        reward     = float(np.clip(shaped, -self.reward_clip, self.reward_clip))\n",
        "\n",
        "        self.nav  *= (1.0 + base_ret - trade_cost)\n",
        "        if changed:\n",
        "            self.pos = target_pos\n",
        "            self._last_trade_step = self._current_tick\n",
        "\n",
        "        obs, terminated, truncated, info = self._step_parent_hold()\n",
        "        info = info or {}\n",
        "        info.update({\"ret_t\": r_t, \"nav\": self.nav, \"pos\": self.pos,\n",
        "                     \"trade_cost\": trade_cost, \"base_ret\": base_ret,\n",
        "                     \"rel_alpha\": rel_alpha, \"mom\": self._mom_signal()})\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "# ------------------------------- 10) ARTIFACT HELPERS ----------------------------------------\n",
        "def _features_list_for(prefix: str) -> List[str]:\n",
        "    fpath = os.path.join(MASTER_DIR, f\"{prefix}_features.json\")\n",
        "    if os.path.exists(fpath):\n",
        "        try:\n",
        "            meta = json.load(open(fpath, \"r\"))\n",
        "            feats = meta.get(\"features\") or []\n",
        "            if isinstance(feats, list):\n",
        "                return [str(c) for c in feats]\n",
        "        except Exception as e:\n",
        "            L.warning(f\"features.json read failed for {prefix}: {e}\")\n",
        "    return []\n",
        "\n",
        "def _align_columns(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
        "    feats = _features_list_for(prefix)\n",
        "    if not feats:\n",
        "        return df\n",
        "    aligned = df.copy()\n",
        "    for c in feats:\n",
        "        if c not in aligned.columns:\n",
        "            aligned[c] = 0.0\n",
        "    ordered = [c for c in feats if c in aligned.columns] + [c for c in aligned.columns if c not in feats]\n",
        "    return aligned[ordered]\n",
        "\n",
        "def _check_artifacts(prefix: str) -> Dict[str, bool]:\n",
        "    need = [\"_model.zip\", \"_vecnorm.pkl\"]\n",
        "    nice = [\"_features.json\", \"_probability_config.json\", \"_model_info.json\"]\n",
        "    return {s: os.path.exists(os.path.join(MASTER_DIR, prefix + s)) for s in need + nice}\n",
        "\n",
        "# -------------------------------- 11) MODEL / ENV LOADING ------------------------------------\n",
        "def get_mu_sigma(model, obs):\n",
        "    with torch.no_grad():\n",
        "        obs_t, _     = model.policy.obs_to_tensor(obs)\n",
        "        feats        = model.policy.extract_features(obs_t)\n",
        "        latent_pi, _ = model.policy.mlp_extractor(feats)\n",
        "        mean_actions = model.policy.action_net(latent_pi)\n",
        "        log_std      = model.policy.log_std\n",
        "        mu    = float(mean_actions.detach().cpu().numpy().squeeze())\n",
        "        sigma = float(log_std.exp().detach().cpu().numpy().squeeze())\n",
        "    return mu, sigma\n",
        "\n",
        "def load_model_and_env(prefix: str):\n",
        "    model_path = os.path.join(MASTER_DIR, f\"{prefix}_model.zip\")\n",
        "    vec_path   = os.path.join(MASTER_DIR, f\"{prefix}_vecnorm.pkl\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Missing model: {model_path}\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = PPO.load(model_path, device=device)\n",
        "\n",
        "    def make_env(df_window: pd.DataFrame):\n",
        "        # simple frame bound near the end\n",
        "        frame_bound = (max(50, len(df_window)//3), len(df_window) - 3)\n",
        "        e = DummyVecEnv([lambda: ContinuousPositionEnv(\n",
        "            df=df_window, frame_bound=frame_bound, window_size=10,\n",
        "            cost_rate=0.0002, slip_rate=0.0003,\n",
        "            k_alpha=0.20, k_mom=0.05, k_sent=0.0,\n",
        "            mom_source=\"denoised\", mom_lookback=20,\n",
        "            min_trade_delta=0.01, cooldown=5, reward_clip=1.0\n",
        "        )])\n",
        "        if os.path.exists(vec_path):\n",
        "            e = VecNormalize.load(vec_path, e)\n",
        "        e.training = False\n",
        "        e.norm_reward = False\n",
        "        return e\n",
        "    return model, make_env\n",
        "\n",
        "# -------------------------------- 12) DATA FETCH / PREP --------------------------------------\n",
        "def _flatten_yf_columns(df: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        new_cols = []\n",
        "        for c0, c1 in df.columns.to_list():\n",
        "            if c1 in (\"\", symbol):\n",
        "                new_cols.append(c0)\n",
        "            else:\n",
        "                new_cols.append(f\"{c0}_{c1}\")\n",
        "        df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "def latest_df_for_symbol(symbol: str, horizon_days: int = YF_DAYS, interval: str = YF_INTERVAL) -> pd.DataFrame | None:\n",
        "    end   = datetime.now(timezone.utc)\n",
        "    start = end - timedelta(days=horizon_days)\n",
        "    df = yf.download(symbol,\n",
        "                     start=start.strftime(\"%Y-%m-%d\"),\n",
        "                     end=end.strftime(\"%Y-%m-%d\"),\n",
        "                     interval=interval,\n",
        "                     progress=False,\n",
        "                     auto_adjust=False)\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    df = df.reset_index()\n",
        "    df[\"Symbol\"] = symbol\n",
        "    df = _flatten_yf_columns(df, symbol)\n",
        "    df = compute_enhanced_features(df)\n",
        "    return df\n",
        "\n",
        "# -------------------------------- 13) INFERENCE ----------------------------------------------\n",
        "def predict_latest(symbol: str, prefix: str) -> Dict[str, Any]:\n",
        "    status = _check_artifacts(prefix)\n",
        "    missing_hard = [k for k in [\"_model.zip\", \"_vecnorm.pkl\"] if not status.get(k, False)]\n",
        "    if missing_hard:\n",
        "        return {\"symbol\": symbol, \"prefix\": prefix, \"error\": f\"missing artifacts: {missing_hard}\"}\n",
        "\n",
        "    model, make_env = load_model_and_env(prefix)\n",
        "    live_df = latest_df_for_symbol(symbol)\n",
        "    if live_df is None or len(live_df) < 120:\n",
        "        return {\"symbol\": symbol, \"prefix\": prefix, \"error\": \"no fresh data\"}\n",
        "\n",
        "    live_df = _align_columns(live_df, prefix)\n",
        "    df_window = live_df.iloc[-2500:].reset_index(drop=True) if len(live_df) > 2500 else live_df.copy()\n",
        "\n",
        "    env = make_env(df_window)\n",
        "    obs = env.reset()\n",
        "    if isinstance(obs, tuple):\n",
        "        obs, _ = obs\n",
        "\n",
        "    # Roll forward with a neutral policy to get to the end-of-window observation\n",
        "    for _ in range(max(1, len(df_window) - 5)):\n",
        "        obs, _, dones, _ = env.step([np.array([0.0], dtype=np.float32)])  # (n_envs, action_dim)\n",
        "        if isinstance(dones, (np.ndarray, list)) and bool(dones[0]):\n",
        "            break\n",
        "\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    mu, sigma = get_mu_sigma(model, obs)\n",
        "    from math import erf, sqrt\n",
        "    Phi   = lambda x: 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
        "    p_long = 1.0 - Phi((0.0 - mu) / max(sigma, 1e-6))\n",
        "\n",
        "    a = float(np.array(action).squeeze())\n",
        "    signal = \"BUY\" if a > 0.10 else (\"SELL\" if a < -0.30 else \"HOLD\")\n",
        "    ts = df_window[\"Datetime\"].iloc[-1] if \"Datetime\" in df_window.columns else None\n",
        "    px = float(df_window[\"Close\"].iloc[-1])\n",
        "\n",
        "    return {\n",
        "        \"symbol\": symbol,\n",
        "        \"prefix\": prefix,\n",
        "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"bar_ts\": str(ts),\n",
        "        \"price\": px,\n",
        "        \"action\": a,\n",
        "        \"signal\": signal,\n",
        "        \"confidence\": abs(a),\n",
        "        \"p_long\": float(p_long),\n",
        "        \"p_short\": float(1.0 - p_long),\n",
        "        \"mu\": float(mu),\n",
        "        \"sigma\": float(sigma)\n",
        "    }\n",
        "\n",
        "# -------------------------------- 14) GIST HELPERS (ROBUST) ----------------------------------\n",
        "def _headers(token: str) -> Dict[str, str]:\n",
        "    return {\"Authorization\": f\"token {token}\"} if token else {}\n",
        "\n",
        "def _load_saved_gist_id() -> str:\n",
        "    if GIST_ID:\n",
        "        return GIST_ID\n",
        "    try:\n",
        "        gid = open(GIST_ID_PATH, \"r\").read().strip()\n",
        "        return gid if gid else \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def _save_gist_id(gid: str):\n",
        "    try:\n",
        "        with open(GIST_ID_PATH, \"w\") as f:\n",
        "            f.write(gid)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def publish_json_to_gist(payload: dict, filename: str, gist_id: str, token: str, desc: str) -> dict:\n",
        "    \"\"\"\n",
        "    Returns: {\"id\": <gist_id>, \"owner\": <login or 'anonymous'>, \"raw_url\": <raw file url or ''>}\n",
        "    \"\"\"\n",
        "    if not token:\n",
        "        raise RuntimeError(\"GITHUB_TOKEN not set. Set os.environ['GITHUB_TOKEN']='ghp_...' or create a .env first.\")\n",
        "\n",
        "    files = {filename: {\"content\": json.dumps(payload, indent=2)}}\n",
        "\n",
        "    if gist_id:\n",
        "        r = requests.patch(f\"https://api.github.com/gists/{gist_id}\",\n",
        "                           headers=_headers(token),\n",
        "                           json={\"files\": files, \"description\": desc}, timeout=30)\n",
        "    else:\n",
        "        r = requests.post(\"https://api.github.com/gists\",\n",
        "                          headers=_headers(token),\n",
        "                          json={\"files\": files, \"description\": desc, \"public\": True},\n",
        "                          timeout=30)\n",
        "\n",
        "    if not r.ok:\n",
        "        raise RuntimeError(f\"Gist API error {r.status_code}: {r.text[:300]}\")\n",
        "\n",
        "    data = r.json()\n",
        "    gid = data.get(\"id\", gist_id or \"\")\n",
        "    owner = ((data.get(\"owner\") or {}).get(\"login\")) or \"anonymous\"\n",
        "    raw_url = ((data.get(\"files\") or {}).get(filename) or {}).get(\"raw_url\", \"\")\n",
        "\n",
        "    if not gid:\n",
        "        raise RuntimeError(\"Gist ID missing in API response.\")\n",
        "\n",
        "    if not raw_url:\n",
        "        m = requests.get(f\"https://api.github.com/gists/{gid}\", headers=_headers(token), timeout=30)\n",
        "        if m.ok and m.headers.get(\"content-type\",\"\").startswith(\"application/json\"):\n",
        "            md = m.json()\n",
        "            raw_url = ((md.get(\"files\") or {}).get(filename) or {}).get(\"raw_url\", \"\")\n",
        "\n",
        "    _save_gist_id(gid)\n",
        "    return {\"id\": gid, \"owner\": owner, \"raw_url\": raw_url}\n",
        "\n",
        "def gist_raw_url(gist_id: str, filename: str, token: str = \"\") -> str:\n",
        "    if not gist_id:\n",
        "        return \"\"\n",
        "    r = requests.get(f\"https://api.github.com/gists/{gist_id}\", headers=_headers(token), timeout=20)\n",
        "    if not r.ok or not r.headers.get(\"content-type\",\"\").startswith(\"application/json\"):\n",
        "        return \"\"\n",
        "    data = r.json()\n",
        "    return ((data.get(\"files\") or {}).get(filename) or {}).get(\"raw_url\", \"\") or \"\"\n",
        "\n",
        "# -------------------------------- 15) PUBLISH LOOP -------------------------------------------\n",
        "RUN_LOOP  = False\n",
        "SLEEP_SEC = 60\n",
        "\n",
        "def run_once():\n",
        "    # Optionally filter out symbols missing core artifacts so the Gist shows only valid models\n",
        "    results = []\n",
        "    for sym, pref in PICKS.items():\n",
        "        try:\n",
        "            out = predict_latest(sym, pref)\n",
        "            if out.get(\"error\"):\n",
        "                L.warning(f\"{sym} -> {out['error']}\")\n",
        "            results.append(out)\n",
        "        except Exception as e:\n",
        "            L.exception(f\"{sym} predict error: {e}\")\n",
        "            results.append({\"symbol\": sym, \"prefix\": pref, \"error\": str(e)})\n",
        "\n",
        "    payload = {\n",
        "        \"generated_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"valid_until_utc\": (datetime.now(timezone.utc) + timedelta(minutes=3)).isoformat(),\n",
        "        \"producer\": \"colab-sb3\",\n",
        "        \"interval\": YF_INTERVAL,\n",
        "        \"models\": results\n",
        "    }\n",
        "\n",
        "    meta = publish_json_to_gist(payload, filename=GIST_FILENAME,\n",
        "                                gist_id=_load_saved_gist_id(),\n",
        "                                token=GITHUB_TOKEN, desc=GIST_DESC)\n",
        "\n",
        "    gid = meta[\"id\"]\n",
        "    raw = meta.get(\"raw_url\") or gist_raw_url(gid, GIST_FILENAME, token=GITHUB_TOKEN)\n",
        "\n",
        "    print(\"Published:\", f\"https://gist.github.com/{gid}\")\n",
        "    print(\"RAW URL  :\", raw or \"(raw url not available yet — open gist page)\")\n",
        "    print(\"Preview  :\", json.dumps(payload, indent=2)[:900], \"...\")\n",
        "\n",
        "# -------------------------------- 16) SANITY CHECK + EXECUTE ---------------------------------\n",
        "for sym, pref in PICKS.items():\n",
        "    status = _check_artifacts(pref)\n",
        "    hard_miss = [k for k in [\"_model.zip\", \"_vecnorm.pkl\"] if not status.get(k, False)]\n",
        "    print(f\"{pref}: {'OK' if not hard_miss else 'MISSING ' + str(hard_miss)}\")\n",
        "\n",
        "# Fallback prompt if token missing (won't echo); comment out if you prefer exception instead\n",
        "if not GITHUB_TOKEN:\n",
        "    try:\n",
        "        from getpass import getpass\n",
        "        os.environ[\"GITHUB_TOKEN\"] = getpass(\"Paste your GitHub token (won't be printed): \").strip()\n",
        "        GITHUB_TOKEN = os.environ[\"GITHUB_TOKEN\"]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "run_once()\n",
        "\n",
        "if RUN_LOOP:\n",
        "    while True:\n",
        "        try:\n",
        "            run_once()\n",
        "        except Exception as e:\n",
        "            L.error(f\"Publish error: {e}\")\n",
        "        time.sleep(SLEEP_SEC)\n",
        "\n",
        "# -------------------------------- 17) OPTIONAL: PRINT STABLE RAW URL LATER -------------------\n",
        "try:\n",
        "    gid = open(GIST_ID_PATH, \"r\").read().strip()\n",
        "    if gid:\n",
        "        r = requests.get(f\"https://api.github.com/gists/{gid}\", headers=_headers(GITHUB_TOKEN), timeout=20)\n",
        "        if r.ok and r.headers.get(\"content-type\",\"\").startswith(\"application/json\"):\n",
        "            meta = r.json()\n",
        "            owner = (meta.get(\"owner\") or {}).get(\"login\", \"anonymous\")\n",
        "            raw_url_stable = f\"https://gist.githubusercontent.com/{owner}/{gid}/raw/{GIST_FILENAME}\"\n",
        "            raw_url_api    = (meta.get(\"files\", {}).get(GIST_FILENAME, {}) or {}).get(\"raw_url\", \"\")\n",
        "            print(\"Gist page   :\", f\"https://gist.github.com/{owner}/{gid}\")\n",
        "            print(\"Raw (stable):\", raw_url_stable)\n",
        "            print(\"Raw (API)   :\", raw_url_api)\n",
        "        else:\n",
        "            print(\"Gist meta fetch skipped (non-JSON or HTTP error).\")\n",
        "    else:\n",
        "        print(\"No saved Gist ID yet.\")\n",
        "except Exception as e:\n",
        "    print(\"Gist meta check skipped:\", e)"
      ],
      "metadata": {
        "id": "6cMq8kbmgzts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45eb9991-ed51-4e96-b0df-a60a95b6612c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppo_GE_window1: OK\n",
            "ppo_CVX_window1: MISSING ['_model.zip', '_vecnorm.pkl']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:producer:CVX -> missing artifacts: ['_model.zip', '_vecnorm.pkl']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Published: https://gist.github.com/3deb62ce13c3eaa57b5d58c6eb858ce6\n",
            "RAW URL  : https://gist.githubusercontent.com/racoope70/3deb62ce13c3eaa57b5d58c6eb858ce6/raw/75b5166bfb1cfadbf650c0ba594a70881e978ff4/live_signals.json\n",
            "Preview  : {\n",
            "  \"generated_utc\": \"2025-09-13T20:47:27.699041+00:00\",\n",
            "  \"valid_until_utc\": \"2025-09-13T20:50:27.699055+00:00\",\n",
            "  \"producer\": \"colab-sb3\",\n",
            "  \"interval\": \"1m\",\n",
            "  \"models\": [\n",
            "    {\n",
            "      \"symbol\": \"GE\",\n",
            "      \"prefix\": \"ppo_GE_window1\",\n",
            "      \"timestamp\": \"2025-09-13T20:47:27.697474+00:00\",\n",
            "      \"bar_ts\": \"2025-09-12 19:59:00+00:00\",\n",
            "      \"price\": 281.70001220703125,\n",
            "      \"action\": 0.1543455868959427,\n",
            "      \"signal\": \"BUY\",\n",
            "      \"confidence\": 0.1543455868959427,\n",
            "      \"p_long\": 0.5598957990575731,\n",
            "      \"p_short\": 0.44010420094242686,\n",
            "      \"mu\": 0.1543455868959427,\n",
            "      \"sigma\": 1.0241568088531494\n",
            "    },\n",
            "    {\n",
            "      \"symbol\": \"CVX\",\n",
            "      \"prefix\": \"ppo_CVX_window1\",\n",
            "      \"error\": \"missing artifacts: ['_model.zip', '_vecnorm.pkl']\"\n",
            "    }\n",
            "  ]\n",
            "} ...\n",
            "Gist page   : https://gist.github.com/racoope70/3deb62ce13c3eaa57b5d58c6eb858ce6\n",
            "Raw (stable): https://gist.githubusercontent.com/racoope70/3deb62ce13c3eaa57b5d58c6eb858ce6/raw/live_signals.json\n",
            "Raw (API)   : https://gist.githubusercontent.com/racoope70/3deb62ce13c3eaa57b5d58c6eb858ce6/raw/75b5166bfb1cfadbf650c0ba594a70881e978ff4/live_signals.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}