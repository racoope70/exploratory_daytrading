{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/exploratory_daytrading/blob/main/PPO_QuantConnect_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run to get paramaters for QuantConnect (from this codes output)\n",
        "#get live_signals.json → the output your backtest consumes."
      ],
      "metadata": {
        "id": "EtHqFF5L3EKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y opencv-python opencv-python-headless opencv-contrib-python"
      ],
      "metadata": {
        "id": "hSXunPFBywlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall stuff that conflicts with a PyTorch+SB3+Gymnasium workflow (safe if absent)\n",
        "!pip -q uninstall -y \\\n",
        "  gym gymnasium shimmy stable-baselines3 dopamine-rl \\\n",
        "  tensorflow tensorflow-hub tf-keras tensorflow-text tensorflow-decision-forests \\\n",
        "  cudf-cu12 dask-cudf-cu12 dask-cuda rapids-dask-dependency \\\n",
        "  libcudf-cu12 libcuml-cu12 pylibcudf-cu12 pylibraft-cu12 \\\n",
        "  libcugraph-cu12 pylibcugraph-cu12 rmm-cu12 libcuvs-cu12 cuvs-cu12 \\\n",
        "  cupy-cuda12x opencv-python opencv-python-headless opencv-contrib-python || true\n",
        "\n",
        "# PyTorch (CUDA 12.4 wheels that match Colab GPU VMs)\n",
        "!pip -q install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio\n",
        "\n",
        "# Core RL/ML stack pinned to avoid Colab’s resolver nags\n",
        "# - pandas==2.2.2 and requests==2.32.4 match google-colab’s constraints\n",
        "# - numpy==2.0.2 avoids the OpenCV / numba complaints and works fine with SB3\n",
        "!pip -q install -U \\\n",
        "  \"protobuf>=5.29.1,<6\" \\\n",
        "  \"gymnasium>=1.1,<1.3\" \\\n",
        "  \"stable-baselines3==2.7.0\" \\\n",
        "  \"numpy==2.0.2\" \"pandas==2.2.2\" \"requests==2.32.4\" \\\n",
        "  yfinance pywavelets transformers python-dotenv\n"
      ],
      "metadata": {
        "id": "DtTdPuFmmfuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402e1d42-6f86-4647-87a0-cf64e5ae69a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping shimmy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping stable-baselines3 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.3/944.3 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shell cell\n",
        "!pip -q install \"opencv-python-headless==4.12.0.88\""
      ],
      "metadata": {
        "id": "-8l2uyRI00wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7262a1d4-e117-4836-a59d-9a5f03d66562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, shutil\n",
        "for p in glob.glob('/usr/local/lib/python*/dist-packages/~*'):\n",
        "    print(\"Removing\", p)\n",
        "    shutil.rmtree(p, ignore_errors=True)\n"
      ],
      "metadata": {
        "id": "DqOLGvBfspsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SB3-safe cv2 shim: run this BEFORE `import stable_baselines3 as sb3`\n",
        "import sys, types\n",
        "try:\n",
        "    import cv2  # Colab may auto-load a minimal cv2\n",
        "except Exception:\n",
        "    cv2 = None\n",
        "\n",
        "if cv2 is None:\n",
        "    cv2 = types.ModuleType(\"cv2\")\n",
        "    cv2.ocl = types.SimpleNamespace(setUseOpenCL=lambda *a, **k: None)\n",
        "    sys.modules[\"cv2\"] = cv2\n",
        "else:\n",
        "    if not hasattr(cv2, \"ocl\"):\n",
        "        cv2.ocl = types.SimpleNamespace(setUseOpenCL=lambda *a, **k: None)\n",
        "    elif not hasattr(cv2.ocl, \"setUseOpenCL\"):\n",
        "        cv2.ocl.setUseOpenCL = lambda *a, **k: None\n",
        "\n",
        "# Now safe to import SB3 & friends\n",
        "import torch, gymnasium, stable_baselines3 as sb3, transformers, pandas as pd, numpy as np\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda, \"| GPU:\", torch.cuda.is_available())\n",
        "print(\"Gymnasium:\", gymnasium.__version__)\n",
        "print(\"SB3:\", sb3.__version__)\n",
        "print(\"Transformers:\", transformers.__version__)\n",
        "print(\"pandas:\", pd.__version__, \"| numpy:\", np.__version__)\n"
      ],
      "metadata": {
        "id": "h-lNJSkXstmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861bc3c2-0e7b-4eae-e7cb-cb9a0171a4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA: 12.6 | GPU: False\n",
            "Gymnasium: 1.2.0\n",
            "SB3: 2.7.0\n",
            "Transformers: 4.56.1\n",
            "pandas: 2.2.2 | numpy: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shimmy_needed = False\n",
        "try:\n",
        "    import gym_anytrading  # legacy gym-based\n",
        "    shimmy_needed = True\n",
        "    print(\"Detected gym-anytrading → Shimmy wrapper recommended.\")\n",
        "except Exception:\n",
        "    print(\"gym-anytrading not installed → Shimmy not needed.\")\n",
        "\n",
        "print(\"Shimmy needed? \", shimmy_needed)\n"
      ],
      "metadata": {
        "id": "hoCOU9Sas6_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370ac10d-9786-4546-d307-522690c7e246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gym-anytrading not installed → Shimmy not needed.\n",
            "Shimmy needed?  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gym-anytrading shimmy"
      ],
      "metadata": {
        "id": "UKPWP-Pps-oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7862ea-4d0b-4810-8395-5c39ae94e8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Where you keep all PPO artifacts\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "# Pick a symbol/prefix you’re uploading for (repeat for CVX, etc.)\n",
        "PREFIX = \"ppo_CVX_window1\"   # change to \"ppo_CVX_window1\" when uploading CVX files\n",
        "\n",
        "# === 1) Upload PPO artifacts from your local machine ===\n",
        "# Expecting files named exactly like:\n",
        "#   ppo_GE_window1_model.zip\n",
        "#   ppo_GE_window1_vecnorm.pkl\n",
        "#   ppo_GE_window1_features.json\n",
        "# (optionally) ppo_GE_window1_probability_config.json, ppo_GE_window1_model_info.json\n",
        "uploaded = files.upload()   # choose the files above\n",
        "\n",
        "# Persist uploads to your MASTER_DIR\n",
        "for name, data in uploaded.items():\n",
        "    # Ensure file exists on the runtime filesystem (Colab sometimes does this automatically)\n",
        "    with open(name, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    # Move into your master artifacts folder\n",
        "    shutil.move(name, os.path.join(MASTER_DIR, name))\n",
        "\n",
        "print(\"Saved to:\", MASTER_DIR)\n",
        "print(sorted([f for f in os.listdir(MASTER_DIR) if f.startswith(PREFIX)]))"
      ],
      "metadata": {
        "id": "Lbr47SbWC5HP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "87a66eed-fd80-4ac2-eeab-0e32b4554ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-394e5e3c-5362-434b-b0ad-946886df810d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-394e5e3c-5362-434b-b0ad-946886df810d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ppo_CVX_window1_features.json to ppo_CVX_window1_features.json\n",
            "Saving ppo_CVX_window1_model_info.json to ppo_CVX_window1_model_info.json\n",
            "Saving ppo_CVX_window1_model.zip to ppo_CVX_window1_model.zip\n",
            "Saving ppo_CVX_window1_probability_config.json to ppo_CVX_window1_probability_config.json\n",
            "Saving ppo_CVX_window1_vecnorm.pkl to ppo_CVX_window1_vecnorm.pkl\n",
            "Saving ppo_GE_window1_features.json to ppo_GE_window1_features.json\n",
            "Saving ppo_GE_window1_model_info.json to ppo_GE_window1_model_info.json\n",
            "Saving ppo_GE_window1_model.zip to ppo_GE_window1_model.zip\n",
            "Saving ppo_GE_window1_probability_config.json to ppo_GE_window1_probability_config.json\n",
            "Saving ppo_GE_window1_vecnorm.pkl to ppo_GE_window1_vecnorm.pkl\n",
            "Saving ppo_UNH_window3_features.json to ppo_UNH_window3_features.json\n",
            "Saving ppo_UNH_window3_model_info.json to ppo_UNH_window3_model_info.json\n",
            "Saving ppo_UNH_window3_model.zip to ppo_UNH_window3_model.zip\n",
            "Saving ppo_UNH_window3_probability_config.json to ppo_UNH_window3_probability_config.json\n",
            "Saving ppo_UNH_window3_vecnorm.pkl to ppo_UNH_window3_vecnorm.pkl\n",
            "Saved to: /content/drive/MyDrive/Results_May_2025/ppo_models_master\n",
            "['ppo_CVX_window1_features.json', 'ppo_CVX_window1_model.zip', 'ppo_CVX_window1_model_info.json', 'ppo_CVX_window1_probability_config.json', 'ppo_CVX_window1_vecnorm.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Upload your local env file (e.g., Github.env.txt or .env.github)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # run this cell and choose the file"
      ],
      "metadata": {
        "id": "fK_jkdQlHB3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "7e25a08d-6bec-46f2-924a-3e94f260f745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9bd1a6c-efb1-405e-b39f-9fa69ac26187\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9bd1a6c-efb1-405e-b39f-9fa69ac26187\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Github_key.env.txt to Github_key.env.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2) Rename to .env (only if your filename isn't already \".env\")\n",
        "import os\n",
        "if \"Github_key.env.txt\" in uploaded:\n",
        "    os.rename(\"Github_key.env.txt\", \".env\")    # adjust if your uploaded name differs\n"
      ],
      "metadata": {
        "id": "5We3sEjgpqhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== PPO Producer with Live JSON + History CSV (Gist) ======================\n",
        "# Colab-ready. Paste this whole cell.\n",
        "\n",
        "# -------- 0) Minimal bootstrap: ensure secrets/artifacts and paths --------\n",
        "import os, json, shutil\n",
        "\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "# Pick ONE prefix you’re working on right now (others will still publish if in PICKS below)\n",
        "PREFIX = \"ppo_GE_window1\"  # e.g., \"ppo_CVX_window1\", \"ppo_UNH_window3\"\n",
        "\n",
        "needed = [f\"{PREFIX}_model.zip\", f\"{PREFIX}_vecnorm.pkl\", f\"{PREFIX}_features.json\"]\n",
        "missing = [f for f in needed if not os.path.exists(os.path.join(MASTER_DIR, f))]\n",
        "if missing:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"Missing:\", missing, \"\\nPlease upload the listed files.\")\n",
        "        uploaded = files.upload()\n",
        "        for name, data in uploaded.items():\n",
        "            with open(name, \"wb\") as f: f.write(data)\n",
        "            shutil.move(name, os.path.join(MASTER_DIR, name))\n",
        "        print(\"Saved to:\", MASTER_DIR)\n",
        "    except Exception as e:\n",
        "        print(\"Upload step skipped/failed:\", e)\n",
        "\n",
        "# Token from env or .env (don’t hardcode in code)\n",
        "token = os.getenv(\"GITHUB_TOKEN\")\n",
        "if not token:\n",
        "    try:\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv(\".env\")\n",
        "        token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    except Exception:\n",
        "        token = None\n",
        "if not token:\n",
        "    from getpass import getpass\n",
        "    token = getpass(\"Paste your GitHub token (won't be printed): \").strip()\n",
        "    os.environ[\"GITHUB_TOKEN\"] = token\n",
        "\n",
        "print(\"Artifacts present:\", all(os.path.exists(os.path.join(MASTER_DIR, f)) for f in needed))\n",
        "print(\"Token present?   \", bool(os.getenv(\"GITHUB_TOKEN\")))\n"
      ],
      "metadata": {
        "id": "t-MxocSjHIiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9005ca3-ff97-46bc-825b-cc28f3cf2c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifacts present: True\n",
            "Token present?    True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------- 1) IMPORTS -------------------------------------------\n",
        "import time, logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import yfinance as yf\n",
        "\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "from gymnasium.spaces import Box as GBox\n",
        "\n",
        "# ---------------------------------- 2) LOGGING & DRIVE ---------------------------------------\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "L = logging.getLogger(\"producer\")\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    if not os.path.ismount(\"/content/drive\"):\n",
        "        drive.mount(\"/content/drive\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ---------------------------------- 3) PATHS & CONFIG ----------------------------------------\n",
        "RESULTS_ROOT = \"/content/drive/MyDrive/Results_May_2025\"\n",
        "MASTER_DIR   = os.path.join(RESULTS_ROOT, \"ppo_models_master\")\n",
        "os.makedirs(MASTER_DIR, exist_ok=True)\n",
        "\n",
        "STATE_DIR    = \"/content/drive/MyDrive/QuantConnect_Ready\"\n",
        "os.makedirs(STATE_DIR, exist_ok=True)\n",
        "\n",
        "GIST_ID_PATH = os.path.join(STATE_DIR, \"live_signals_gist_id.txt\")\n",
        "\n",
        "# Which models to publish each run\n",
        "PICKS: Dict[str, str] = {\n",
        "    \"GE\":  \"ppo_GE_window1\",\n",
        "    \"CVX\": \"ppo_CVX_window1\",\n",
        "    \"UNH\": \"ppo_UNH_window3\",  # add/remove as you like\n",
        "}\n",
        "\n",
        "# yfinance fetch params\n",
        "YF_INTERVAL = \"1m\"   # 1-minute bars\n",
        "YF_DAYS     = 5      # ~7d max for 1m\n",
        "\n",
        "# GitHub / Gist\n",
        "from dotenv import load_dotenv as _ld  # harmless if not installed\n",
        "try:\n",
        "    _ld(\".env\")\n",
        "except Exception:\n",
        "    pass\n",
        "GITHUB_TOKEN  = os.environ.get(\"GITHUB_TOKEN\", \"\").strip()\n",
        "GIST_ID       = os.environ.get(\"GIST_ID\", \"\").strip()\n",
        "GIST_JSON     = \"live_signals.json\"\n",
        "GIST_CSV      = \"signal_history.csv\"\n",
        "GIST_DESC     = \"Live PPO signals + history (Producer→Consumer)\"\n",
        "\n",
        "# Local history CSV (mirrors Gist CSV)\n",
        "LOCAL_HISTORY = os.path.join(STATE_DIR, GIST_CSV)\n",
        "HISTORY_FIELDS = [\n",
        "    \"timestamp_utc\",\"bar_ts\",\"symbol\",\"price\",\n",
        "    \"action\",\"signal\",\"confidence\",\"p_long\",\"p_short\",\"mu\",\"sigma\",\"prefix\"\n",
        "]\n",
        "\n",
        "# ---------------------------------- 4) FEATURE PIPELINE --------------------------------------\n",
        "def compute_enhanced_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Replace with your real feature pipeline if needed\n",
        "    return df_in\n",
        "\n",
        "# ---------------------------------- 5) ENV WRAPPER -------------------------------------------\n",
        "class ContinuousPositionEnv(StocksEnv):\n",
        "    def __init__(self, df, frame_bound, window_size,\n",
        "                 cost_rate=0.0002, slip_rate=0.0003,\n",
        "                 k_alpha=0.20, k_mom=0.05, k_sent=0.0,\n",
        "                 mom_source=\"denoised\", mom_lookback=20,\n",
        "                 min_trade_delta=0.01, cooldown=5, reward_clip=1.0):\n",
        "        super().__init__(df=df.reset_index(drop=True), frame_bound=frame_bound, window_size=window_size)\n",
        "        if isinstance(self.observation_space, gym.spaces.Box):\n",
        "            self.observation_space = GBox(\n",
        "                low=self.observation_space.low,\n",
        "                high=self.observation_space.high,\n",
        "                shape=self.observation_space.shape,\n",
        "                dtype=self.observation_space.dtype,\n",
        "            )\n",
        "        self.action_space = GBox(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.cost_rate, self.slip_rate = float(cost_rate), float(slip_rate)\n",
        "        self.k_alpha, self.k_mom, self.k_sent = float(k_alpha), float(k_mom), float(k_sent)\n",
        "        self.mom_source, self.mom_lookback = str(mom_source), int(mom_lookback)\n",
        "        self.min_trade_delta, self.cooldown = float(min_trade_delta), int(cooldown)\n",
        "        self.reward_clip = float(reward_clip)\n",
        "        self.nav, self.pos, self._last_trade_step = 1.0, 0.0, -self.cooldown\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        out = super().reset(**kwargs)\n",
        "        obs, info = (out if isinstance(out, tuple) else (out, {}))\n",
        "        self.nav, self.pos, self._last_trade_step = 1.0, 0.0, -self.cooldown\n",
        "        info = info or {}\n",
        "        info.update({\"nav\": self.nav, \"pos\": self.pos})\n",
        "        return obs, info\n",
        "\n",
        "    def _step_parent_hold(self):\n",
        "        step_result = super().step(2)\n",
        "        if len(step_result) == 5:\n",
        "            obs, _env_rew, terminated, truncated, info = step_result\n",
        "        else:\n",
        "            obs, _env_rew, done, info = step_result\n",
        "            terminated, truncated = bool(done), False\n",
        "        return obs, terminated, truncated, info\n",
        "\n",
        "    def _ret_t(self):\n",
        "        cur  = float(self.df.loc[self._current_tick, 'Close'])\n",
        "        prev = float(self.df.loc[max(self._current_tick - 1, 0), 'Close'])\n",
        "        return 0.0 if prev <= 0 else (cur - prev) / prev\n",
        "\n",
        "    def _mom_signal(self):\n",
        "        if self.mom_source == \"macd\" and \"MACD_Line\" in self.df.columns:\n",
        "            recent = self.df[\"MACD_Line\"].iloc[max(self._current_tick-200,0):self._current_tick+1]\n",
        "            return float(np.tanh(float(self.df.loc[self._current_tick, \"MACD_Line\"]) / (1e-6 + recent.std())))\n",
        "        if \"Denoised_Close\" in self.df.columns and self._current_tick - self.mom_lookback >= 0:\n",
        "            now  = float(self.df.loc[self._current_tick, \"Denoised_Close\"])\n",
        "            then = float(self.df.loc[self._current_tick - self.mom_lookback, \"Denoised_Close\"])\n",
        "            base = float(self.df.loc[max(self._current_tick - 1, 0), \"Close\"])\n",
        "            slope = (now - then) / max(self.mom_lookback, 1)\n",
        "            return float(np.tanh(10.0 * (slope / max(abs(base), 1e-6))))\n",
        "        return 0.0\n",
        "\n",
        "    def step(self, action):\n",
        "        a = float(np.array(action).squeeze())\n",
        "        target_pos = float(np.clip(a, -1.0, 1.0))\n",
        "        r_t = self._ret_t()\n",
        "        base_ret = self.pos * r_t\n",
        "        changed = (abs(target_pos - self.pos) >= self.min_trade_delta) and \\\n",
        "                  ((self._current_tick - self._last_trade_step) >= self.cooldown)\n",
        "        delta_pos = (target_pos - self.pos) if changed else 0.0\n",
        "        trade_cost = (self.cost_rate + self.slip_rate) * abs(delta_pos)\n",
        "        rel_alpha  = base_ret - r_t\n",
        "        mom_term   = self.pos * self._mom_signal()\n",
        "        shaped     = base_ret + self.k_alpha*rel_alpha + self.k_mom*mom_term - trade_cost\n",
        "        reward     = float(np.clip(shaped, -self.reward_clip, self.reward_clip))\n",
        "        self.nav  *= (1.0 + base_ret - trade_cost)\n",
        "        if changed:\n",
        "            self.pos = target_pos\n",
        "            self._last_trade_step = self._current_tick\n",
        "        obs, terminated, truncated, info = self._step_parent_hold()\n",
        "        info = info or {}\n",
        "        info.update({\"ret_t\": r_t, \"nav\": self.nav, \"pos\": self.pos,\n",
        "                     \"trade_cost\": trade_cost, \"base_ret\": base_ret,\n",
        "                     \"rel_alpha\": rel_alpha, \"mom\": self._mom_signal()})\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "# ------------------------------- 6) ARTIFACT HELPERS -----------------------------------------\n",
        "def _features_list_for(prefix: str) -> List[str]:\n",
        "    fpath = os.path.join(MASTER_DIR, f\"{prefix}_features.json\")\n",
        "    if os.path.exists(fpath):\n",
        "        try:\n",
        "            meta = json.load(open(fpath, \"r\"))\n",
        "            feats = meta.get(\"features\") or []\n",
        "            if isinstance(feats, list):\n",
        "                return [str(c) for c in feats]\n",
        "        except Exception as e:\n",
        "            L.warning(f\"features.json read failed for {prefix}: {e}\")\n",
        "    return []\n",
        "\n",
        "def _align_columns(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
        "    feats = _features_list_for(prefix)\n",
        "    if not feats:\n",
        "        return df\n",
        "    aligned = df.copy()\n",
        "    for c in feats:\n",
        "        if c not in aligned.columns:\n",
        "            aligned[c] = 0.0\n",
        "    ordered = [c for c in feats if c in aligned.columns] + [c for c in aligned.columns if c not in feats]\n",
        "    return aligned[ordered]\n",
        "\n",
        "def _check_artifacts(prefix: str) -> Dict[str, bool]:\n",
        "    need = [\"_model.zip\", \"_vecnorm.pkl\"]\n",
        "    nice = [\"_features.json\", \"_probability_config.json\", \"_model_info.json\"]\n",
        "    return {s: os.path.exists(os.path.join(MASTER_DIR, prefix + s)) for s in need + nice}\n",
        "\n",
        "# -------------------------------- 7) MODEL / ENV LOADING -------------------------------------\n",
        "def get_mu_sigma(model, obs):\n",
        "    with torch.no_grad():\n",
        "        obs_t, _     = model.policy.obs_to_tensor(obs)\n",
        "        feats        = model.policy.extract_features(obs_t)\n",
        "        latent_pi, _ = model.policy.mlp_extractor(feats)\n",
        "        mean_actions = model.policy.action_net(latent_pi)\n",
        "        log_std      = model.policy.log_std\n",
        "        mu    = float(mean_actions.detach().cpu().numpy().squeeze())\n",
        "        sigma = float(log_std.exp().detach().cpu().numpy().squeeze())\n",
        "    return mu, sigma\n",
        "\n",
        "def load_model_and_env(prefix: str):\n",
        "    model_path = os.path.join(MASTER_DIR, f\"{prefix}_model.zip\")\n",
        "    vec_path   = os.path.join(MASTER_DIR, f\"{prefix}_vecnorm.pkl\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Missing model: {model_path}\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = PPO.load(model_path, device=device)\n",
        "\n",
        "    def make_env(df_window: pd.DataFrame):\n",
        "        frame_bound = (max(50, len(df_window)//3), len(df_window) - 3)\n",
        "        e = DummyVecEnv([lambda: ContinuousPositionEnv(\n",
        "            df=df_window, frame_bound=frame_bound, window_size=10,\n",
        "            cost_rate=0.0002, slip_rate=0.0003,\n",
        "            k_alpha=0.20, k_mom=0.05, k_sent=0.0,\n",
        "            mom_source=\"denoised\", mom_lookback=20,\n",
        "            min_trade_delta=0.01, cooldown=5, reward_clip=1.0\n",
        "        )])\n",
        "        if os.path.exists(vec_path):\n",
        "            e = VecNormalize.load(vec_path, e)\n",
        "        e.training = False\n",
        "        e.norm_reward = False\n",
        "        return e\n",
        "    return model, make_env\n",
        "\n",
        "# -------------------------------- 8) DATA FETCH / PREP ---------------------------------------\n",
        "def _flatten_yf_columns(df: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        new_cols = []\n",
        "        for c0, c1 in df.columns.to_list():\n",
        "            new_cols.append(c0 if c1 in (\"\", symbol) else f\"{c0}_{c1}\")\n",
        "        df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "def latest_df_for_symbol(symbol: str, horizon_days: int = YF_DAYS, interval: str = YF_INTERVAL) -> pd.DataFrame | None:\n",
        "    end   = datetime.now(timezone.utc)\n",
        "    start = end - timedelta(days=horizon_days)\n",
        "    df = yf.download(symbol, start=start.strftime(\"%Y-%m-%d\"),\n",
        "                     end=end.strftime(\"%Y-%m-%d\"),\n",
        "                     interval=interval, progress=False, auto_adjust=False)\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    df = df.reset_index()\n",
        "    df[\"Symbol\"] = symbol\n",
        "    df = _flatten_yf_columns(df, symbol)\n",
        "    df = compute_enhanced_features(df)\n",
        "    return df\n",
        "\n",
        "# -------------------------------- 9) INFERENCE -----------------------------------------------\n",
        "def predict_latest(symbol: str, prefix: str) -> Dict[str, Any]:\n",
        "    status = _check_artifacts(prefix)\n",
        "    missing_hard = [k for k in [\"_model.zip\", \"_vecnorm.pkl\"] if not status.get(k, False)]\n",
        "    if missing_hard:\n",
        "        return {\"symbol\": symbol, \"prefix\": prefix, \"error\": f\"missing artifacts: {missing_hard}\"}\n",
        "\n",
        "    model, make_env = load_model_and_env(prefix)\n",
        "    live_df = latest_df_for_symbol(symbol)\n",
        "    if live_df is None or len(live_df) < 120:\n",
        "        return {\"symbol\": symbol, \"prefix\": prefix, \"error\": \"no fresh data\"}\n",
        "\n",
        "    live_df = _align_columns(live_df, prefix)\n",
        "    df_window = live_df.iloc[-2500:].reset_index(drop=True) if len(live_df) > 2500 else live_df.copy()\n",
        "\n",
        "    env = make_env(df_window)\n",
        "    obs = env.reset()\n",
        "    if isinstance(obs, tuple):\n",
        "        obs, _ = obs\n",
        "\n",
        "    for _ in range(max(1, len(df_window) - 5)):\n",
        "        obs, _, dones, _ = env.step([np.array([0.0], dtype=np.float32)])\n",
        "        if isinstance(dones, (np.ndarray, list)) and bool(dones[0]):\n",
        "            break\n",
        "\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    mu, sigma = get_mu_sigma(model, obs)\n",
        "    from math import erf, sqrt\n",
        "    Phi   = lambda x: 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
        "    p_long = 1.0 - Phi((0.0 - mu) / max(sigma, 1e-6))\n",
        "\n",
        "    a = float(np.array(action).squeeze())\n",
        "    signal = \"BUY\" if a > 0.10 else (\"SELL\" if a < -0.30 else \"HOLD\")\n",
        "    ts = df_window[\"Datetime\"].iloc[-1] if \"Datetime\" in df_window.columns else None\n",
        "    px = float(df_window[\"Close\"].iloc[-1])\n",
        "\n",
        "    return {\n",
        "        \"symbol\": symbol, \"prefix\": prefix,\n",
        "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"bar_ts\": str(ts), \"price\": px,\n",
        "        \"action\": a, \"signal\": signal, \"confidence\": abs(a),\n",
        "        \"p_long\": float(p_long), \"p_short\": float(1.0 - p_long),\n",
        "        \"mu\": float(mu), \"sigma\": float(sigma)\n",
        "    }\n",
        "\n",
        "# ------------------------------ 10) HISTORY HELPERS ------------------------------------------\n",
        "def _ensure_history_header(path: str):\n",
        "    if not os.path.exists(path):\n",
        "        with open(path, \"w\") as f:\n",
        "            f.write(\",\".join(HISTORY_FIELDS) + \"\\n\")\n",
        "\n",
        "def append_history_rows(results: List[Dict[str, Any]]):\n",
        "    _ensure_history_header(LOCAL_HISTORY)\n",
        "    lines = []\n",
        "    for r in results:\n",
        "        if r.get(\"error\"):  # skip errored symbols\n",
        "            continue\n",
        "        row = [\n",
        "            r.get(\"timestamp\",\"\"),\n",
        "            r.get(\"bar_ts\",\"\"),\n",
        "            r.get(\"symbol\",\"\"),\n",
        "            str(r.get(\"price\",\"\")),\n",
        "            str(r.get(\"action\",\"\")),\n",
        "            r.get(\"signal\",\"\"),\n",
        "            str(r.get(\"confidence\",\"\")),\n",
        "            str(r.get(\"p_long\",\"\")),\n",
        "            str(r.get(\"p_short\",\"\")),\n",
        "            str(r.get(\"mu\",\"\")),\n",
        "            str(r.get(\"sigma\",\"\")),\n",
        "            r.get(\"prefix\",\"\"),\n",
        "        ]\n",
        "        # naive CSV (no commas in fields), fast and safe here\n",
        "        lines.append(\",\".join(x if x is not None else \"\" for x in row))\n",
        "    if lines:\n",
        "        with open(LOCAL_HISTORY, \"a\") as f:\n",
        "            for ln in lines:\n",
        "                f.write(ln + \"\\n\")\n",
        "\n",
        "# ------------------------------ 11) GIST PUBLISH (BOTH FILES) --------------------------------\n",
        "def _headers(token: str) -> Dict[str, str]:\n",
        "    return {\"Authorization\": f\"token {token}\"} if token else {}\n",
        "\n",
        "def _load_saved_gist_id() -> str:\n",
        "    if GIST_ID: return GIST_ID\n",
        "    try:\n",
        "        return open(GIST_ID_PATH, \"r\").read().strip()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def _save_gist_id(gid: str):\n",
        "    try:\n",
        "        with open(GIST_ID_PATH, \"w\") as f: f.write(gid)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def _stable_raw(owner: str, gid: str, filename: str) -> str:\n",
        "    return f\"https://gist.githubusercontent.com/{owner}/{gid}/raw/{filename}\"\n",
        "\n",
        "def publish_live_and_history(payload: dict, gist_id: str, token: str, desc: str) -> dict:\n",
        "    if not token:\n",
        "        raise RuntimeError(\"GITHUB_TOKEN not set.\")\n",
        "\n",
        "    # Read the local history CSV (ensure exists even if empty)\n",
        "    _ensure_history_header(LOCAL_HISTORY)\n",
        "    with open(LOCAL_HISTORY, \"r\") as f:\n",
        "        csv_text = f.read()\n",
        "\n",
        "    files = {\n",
        "        GIST_JSON: {\"content\": json.dumps(payload, indent=2)},\n",
        "        GIST_CSV:  {\"content\": csv_text},\n",
        "    }\n",
        "\n",
        "    if gist_id:\n",
        "        r = requests.patch(f\"https://api.github.com/gists/{gist_id}\",\n",
        "                           headers=_headers(token),\n",
        "                           json={\"files\": files, \"description\": desc}, timeout=30)\n",
        "    else:\n",
        "        r = requests.post(\"https://api.github.com/gists\",\n",
        "                          headers=_headers(token),\n",
        "                          json={\"files\": files, \"description\": desc, \"public\": True}, timeout=30)\n",
        "    if not r.ok:\n",
        "        raise RuntimeError(f\"Gist API error {r.status_code}: {r.text[:400]}\")\n",
        "\n",
        "    data = r.json()\n",
        "    gid   = data.get(\"id\", gist_id or \"\")\n",
        "    owner = ((data.get(\"owner\") or {}).get(\"login\")) or \"anonymous\"\n",
        "    if gid: _save_gist_id(gid)\n",
        "\n",
        "    # Try to get raw URLs for both files\n",
        "    try:\n",
        "        meta = requests.get(f\"https://api.github.com/gists/{gid}\", headers=_headers(token), timeout=20).json()\n",
        "        files_meta = meta.get(\"files\", {}) or {}\n",
        "        json_raw = (files_meta.get(GIST_JSON) or {}).get(\"raw_url\", _stable_raw(owner, gid, GIST_JSON))\n",
        "        csv_raw  = (files_meta.get(GIST_CSV)  or {}).get(\"raw_url\",  _stable_raw(owner, gid, GIST_CSV))\n",
        "    except Exception:\n",
        "        json_raw = _stable_raw(owner, gid, GIST_JSON)\n",
        "        csv_raw  = _stable_raw(owner, gid, GIST_CSV)\n",
        "\n",
        "    return {\"id\": gid, \"owner\": owner, \"json_raw\": json_raw, \"csv_raw\": csv_raw}\n",
        "\n",
        "# -------------------------------- 12) RUN ONCE -----------------------------------------------\n",
        "RUN_LOOP  = False\n",
        "SLEEP_SEC = 60\n",
        "\n",
        "def run_once():\n",
        "    results = []\n",
        "    for sym, pref in PICKS.items():\n",
        "        try:\n",
        "            out = predict_latest(sym, pref)\n",
        "            if out.get(\"error\"):\n",
        "                L.warning(f\"{sym} -> {out['error']}\")\n",
        "            results.append(out)\n",
        "        except Exception as e:\n",
        "            L.exception(f\"{sym} predict error: {e}\")\n",
        "            results.append({\"symbol\": sym, \"prefix\": pref, \"error\": str(e)})\n",
        "\n",
        "    # Append rows to local CSV before publishing\n",
        "    append_history_rows(results)\n",
        "\n",
        "    payload = {\n",
        "        \"generated_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"valid_until_utc\": (datetime.now(timezone.utc) + timedelta(minutes=3)).isoformat(),\n",
        "        \"producer\": \"colab-sb3\",\n",
        "        \"interval\": YF_INTERVAL,\n",
        "        \"models\": results\n",
        "    }\n",
        "\n",
        "    meta = publish_live_and_history(payload,\n",
        "                                    gist_id=_load_saved_gist_id(),\n",
        "                                    token=GITHUB_TOKEN,\n",
        "                                    desc=GIST_DESC)\n",
        "\n",
        "    print(\"Published Gist:\", f\"https://gist.github.com/{meta['id']}\")\n",
        "    print(\"RAW JSON :\", meta[\"json_raw\"])\n",
        "    print(\"RAW CSV  :\", meta[\"csv_raw\"])\n",
        "    print(\"Preview  :\", json.dumps(payload, indent=2)[:800], \"...\")\n",
        "\n",
        "# -------------------------------- 13) EXECUTE -------------------------------------------------\n",
        "for sym, pref in PICKS.items():\n",
        "    status = _check_artifacts(pref)\n",
        "    hard_miss = [k for k in [\"_model.zip\", \"_vecnorm.pkl\"] if not status.get(k, False)]\n",
        "    print(f\"{pref}: {'OK' if not hard_miss else 'MISSING ' + str(hard_miss)}\")\n",
        "\n",
        "if not GITHUB_TOKEN:\n",
        "    raise RuntimeError(\"No GITHUB_TOKEN available. Add it to a .env or set os.environ['GITHUB_TOKEN'].\")\n",
        "\n",
        "run_once()\n",
        "\n",
        "if RUN_LOOP:\n",
        "    while True:\n",
        "        try:\n",
        "            run_once()\n",
        "        except Exception as e:\n",
        "            L.error(f\"Publish error: {e}\")\n",
        "        time.sleep(SLEEP_SEC)\n"
      ],
      "metadata": {
        "id": "6cMq8kbmgzts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1fbe5f-addc-4d1c-e10c-2fbd242cd05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppo_GE_window1: OK\n",
            "ppo_CVX_window1: OK\n",
            "ppo_UNH_window3: OK\n",
            "Published Gist: https://gist.github.com/8616f88b795081ad008fe4ff686e0dae\n",
            "RAW JSON : https://gist.githubusercontent.com/racoope70/8616f88b795081ad008fe4ff686e0dae/raw/1c0b22f3875ec4f11ca6e85b0726cccd763706bb/live_signals.json\n",
            "RAW CSV  : https://gist.githubusercontent.com/racoope70/8616f88b795081ad008fe4ff686e0dae/raw/7954a8bdb20c48fd9789ada938c92de0acc2e96f/signal_history.csv\n",
            "Preview  : {\n",
            "  \"generated_utc\": \"2025-09-14T16:17:31.557247+00:00\",\n",
            "  \"valid_until_utc\": \"2025-09-14T16:20:31.557269+00:00\",\n",
            "  \"producer\": \"colab-sb3\",\n",
            "  \"interval\": \"1m\",\n",
            "  \"models\": [\n",
            "    {\n",
            "      \"symbol\": \"GE\",\n",
            "      \"prefix\": \"ppo_GE_window1\",\n",
            "      \"timestamp\": \"2025-09-14T16:17:29.460571+00:00\",\n",
            "      \"bar_ts\": \"2025-09-12 19:59:00+00:00\",\n",
            "      \"price\": 281.70001220703125,\n",
            "      \"action\": 0.14700981974601746,\n",
            "      \"signal\": \"BUY\",\n",
            "      \"confidence\": 0.14700981974601746,\n",
            "      \"p_long\": 0.5570690451219047,\n",
            "      \"p_short\": 0.4429309548780953,\n",
            "      \"mu\": 0.14700981974601746,\n",
            "      \"sigma\": 1.0241568088531494\n",
            "    },\n",
            "    {\n",
            "      \"symbol\": \"CVX\",\n",
            "      \"prefix\": \"ppo_CVX_window1\",\n",
            "      \"timestamp\": \"2025-09-14T16:17:30.270356+00:00\",\n",
            "      \"bar_ts\": \"2025-09-12 19:59:00+00:00\",\n",
            "      \"price\": 1 ...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}