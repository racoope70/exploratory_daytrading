{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/daytrading-with-ml/blob/main/implement_market_wizard_strategies_v3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3unZTnDPdSb1",
        "outputId": "f4aa0890-4e71-4866-ff67-8afc3fde9f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask==2024.11.2\n",
            "  Using cached dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting rapids-dask-dependency==24.12.0\n",
            "  Using cached rapids_dask_dependency-24.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cudf-cu12==24.12.0\n",
            "  Using cached cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12==24.12.0\n",
            "  Using cached cuml_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting pylibraft-cu12==24.12.0\n",
            "  Using cached pylibraft_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting pylibcudf-cu12==24.12.0\n",
            "  Using cached pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting numba==0.61.0\n",
            "  Using cached numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gym-anytrading==2.0.0\n",
            "  Using cached gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Using cached stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting click>=8.1 (from dask==2024.11.2)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.11.2)\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask==2024.11.2)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.0 (from dask==2024.11.2)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.11.2)\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.11.2)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.11.2)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib-metadata>=4.13.0 (from dask==2024.11.2)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distributed==2024.11.2 (from rapids-dask-dependency==24.12.0)\n",
            "  Using cached distributed-2024.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.19 (from rapids-dask-dependency==24.12.0)\n",
            "  Using cached dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pynvml<11.5.0a0,>=11.0.0 (from rapids-dask-dependency==24.12.0)\n",
            "  Using cached pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting cachetools (from cudf-cu12==24.12.0)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,<=12.6.0,>=12.0 (from cudf-cu12==24.12.0)\n",
            "  Using cached cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12==24.12.0)\n",
            "  Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting libcudf-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Using cached libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.0.18,>=0.0.13 (from cudf-cu12==24.12.0)\n",
            "  Using cached numba_cuda-0.0.17.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvtx>=0.2.1 (from cudf-cu12==24.12.0)\n",
            "  Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12==24.12.0)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pyarrow<19.0.0a0,>=14.0.0 (from cudf-cu12==24.12.0)\n",
            "  Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12==24.12.0)\n",
            "  Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12==24.12.0)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Using cached rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "Collecting typing_extensions>=4.0.0 (from cudf-cu12==24.12.0)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cuvs-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Using cached cuvs_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting dask-cuda==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Using cached dask_cuda-24.12.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Using cached dask_cudf_cu12-24.12.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12==24.12.0)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting raft-dask-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Using cached raft_dask_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12==24.12.0)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting treelite==4.3.0 (from cuml-cu12==24.12.0)\n",
            "  Using cached treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0)\n",
            "  Using cached llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting matplotlib>=3.1.1 (from gym-anytrading==2.0.0)\n",
            "  Using cached matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libkvikio-cu12==24.12.* (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Using cached libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.1.0.6 (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Using cached nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl.metadata (862 bytes)\n",
            "Collecting distributed-ucxx-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached distributed_ucxx_cu12-0.41.0-py3-none-any.whl\n",
            "Collecting ucx-py-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached ucx_py_cu12-0.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting ucxx-cu12==0.41.* (from distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached ucxx_cu12-0.41.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.41.* (from ucxx-cu12==0.41.*->distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Using cached libucxx_cu12-0.41.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3[extra])\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra])\n",
            "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra])\n",
            "  Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
            "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from stable-baselines3[extra])\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Using cached ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra])\n",
            "  Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12==24.12.0)\n",
            "  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.13.0->dask==2024.11.2)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached setuptools-76.1.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six>1.9 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting filelock (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.12.0)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Using cached dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
            "Using cached rapids_dask_dependency-24.12.0-py3-none-any.whl (15 kB)\n",
            "Using cached cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "Using cached pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (37.3 MB)\n",
            "Using cached numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "Using cached gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "Using cached dask_cuda-24.12.0-py3-none-any.whl (134 kB)\n",
            "Using cached dask_cudf_cu12-24.12.0-py3-none-any.whl (67 kB)\n",
            "Using cached dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
            "Using cached distributed-2024.11.2-py3-none-any.whl (1.0 MB)\n",
            "Using cached libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl (457.8 MB)\n",
            "Using cached rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Using cached treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n",
            "Using cached libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Using cached nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl (28.9 MB)\n",
            "Using cached ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n",
            "Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "Using cached matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Using cached numba_cuda-0.0.17.1-py3-none-any.whl (424 kB)\n",
            "Using cached numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Using cached pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "Using cached pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached setuptools-76.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: triton, sortedcontainers, pytz, nvtx, nvidia-cusparselt-cu12, mpmath, libkvikio-cu12, fastrlock, farama-notifications, cuda-python, zipp, zict, urllib3, tzdata, typing_extensions, tqdm, tornado, toolz, tensorboard-data-server, tblib, sympy, six, setuptools, pyyaml, pyparsing, pynvml, pynvjitlink-cu12, pygments, pygame, pyarrow, psutil, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, msgpack, mdurl, MarkupSafe, markdown, locket, llvmlite, libucx-cu12, kiwisolver, joblib, grpcio, fsspec, fonttools, filelock, cycler, cloudpickle, click, cachetools, absl-py, werkzeug, ucx-py-cu12, scipy, python-dateutil, partd, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib-metadata, gymnasium, cupy-cuda12x, contourpy, ale-py, treelite, tensorboard, rmm-cu12, rich, pandas, nvidia-cusolver-cu12, numba-cuda, matplotlib, dask, ucxx-cu12, torch, pylibraft-cu12, pylibcudf-cu12, gym-anytrading, distributed, dask-expr, stable-baselines3, rapids-dask-dependency, cuvs-cu12, cudf-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 25.2.1\n",
            "    Uninstalling libkvikio-cu12-25.2.1:\n",
            "      Successfully uninstalled libkvikio-cu12-25.2.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: farama-notifications\n",
            "    Found existing installation: Farama-Notifications 0.0.4\n",
            "    Uninstalling Farama-Notifications-0.0.4:\n",
            "      Successfully uninstalled Farama-Notifications-0.0.4\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.8.0\n",
            "    Uninstalling cuda-python-12.8.0:\n",
            "      Successfully uninstalled cuda-python-12.8.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 1.0.0\n",
            "    Uninstalling toolz-1.0.0:\n",
            "      Successfully uninstalled toolz-1.0.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 76.1.0\n",
            "    Uninstalling setuptools-76.1.0:\n",
            "      Successfully uninstalled setuptools-76.1.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 12.0.0\n",
            "    Uninstalling pynvml-12.0.0:\n",
            "      Successfully uninstalled pynvml-12.0.0\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.2\n",
            "    Uninstalling pynvjitlink-cu12-0.5.2:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 19.0.1\n",
            "    Uninstalling pyarrow-19.0.1:\n",
            "      Successfully uninstalled pyarrow-19.0.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.2.0.11\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.2.0.11:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.2.0.11\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.18.0\n",
            "    Uninstalling libucx-cu12-1.18.0:\n",
            "      Successfully uninstalled libucx-cu12-1.18.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.1.0\n",
            "    Uninstalling absl-py-2.1.0:\n",
            "      Successfully uninstalled absl-py-2.1.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.42.0\n",
            "    Uninstalling ucx-py-cu12-0.42.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.42.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.42.0\n",
            "    Uninstalling libucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.42.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 25.2.2\n",
            "    Uninstalling libcudf-cu12-25.2.2:\n",
            "      Successfully uninstalled libcudf-cu12-25.2.2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.29.1\n",
            "    Uninstalling gymnasium-0.29.1:\n",
            "      Successfully uninstalled gymnasium-0.29.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.4.0\n",
            "    Uninstalling cupy-cuda12x-13.4.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.4.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.2\n",
            "    Uninstalling ale-py-0.10.2:\n",
            "      Successfully uninstalled ale-py-0.10.2\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.4.1\n",
            "    Uninstalling treelite-4.4.1:\n",
            "      Successfully uninstalled treelite-4.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 25.2.0\n",
            "    Uninstalling rmm-cu12-25.2.0:\n",
            "      Successfully uninstalled rmm-cu12-25.2.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.2.0\n",
            "    Uninstalling numba-cuda-0.2.0:\n",
            "      Successfully uninstalled numba-cuda-0.2.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.1\n",
            "    Uninstalling matplotlib-3.10.1:\n",
            "      Successfully uninstalled matplotlib-3.10.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.12.1\n",
            "    Uninstalling dask-2024.12.1:\n",
            "      Successfully uninstalled dask-2024.12.1\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.42.0\n",
            "    Uninstalling ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 25.2.0\n",
            "    Uninstalling pylibraft-cu12-25.2.0:\n",
            "      Successfully uninstalled pylibraft-cu12-25.2.0\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 25.2.2\n",
            "    Uninstalling pylibcudf-cu12-25.2.2:\n",
            "      Successfully uninstalled pylibcudf-cu12-25.2.2\n",
            "  Attempting uninstall: gym-anytrading\n",
            "    Found existing installation: gym-anytrading 2.0.0\n",
            "    Uninstalling gym-anytrading-2.0.0:\n",
            "      Successfully uninstalled gym-anytrading-2.0.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.12.1\n",
            "    Uninstalling distributed-2024.12.1:\n",
            "      Successfully uninstalled distributed-2024.12.1\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.21\n",
            "    Uninstalling dask-expr-1.1.21:\n",
            "      Successfully uninstalled dask-expr-1.1.21\n",
            "  Attempting uninstall: stable-baselines3\n",
            "    Found existing installation: stable_baselines3 2.5.0\n",
            "    Uninstalling stable_baselines3-2.5.0:\n",
            "      Successfully uninstalled stable_baselines3-2.5.0\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 25.2.0\n",
            "    Uninstalling rapids-dask-dependency-25.2.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-25.2.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 25.2.1\n",
            "    Uninstalling cuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled cuvs-cu12-25.2.1\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 25.2.2\n",
            "    Uninstalling cudf-cu12-25.2.2:\n",
            "      Successfully uninstalled cudf-cu12-25.2.2\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.42.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 25.2.2\n",
            "    Uninstalling dask-cudf-cu12-25.2.2:\n",
            "      Successfully uninstalled dask-cudf-cu12-25.2.2\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 25.2.0\n",
            "    Uninstalling dask-cuda-25.2.0:\n",
            "      Successfully uninstalled dask-cuda-25.2.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 25.2.0\n",
            "    Uninstalling raft-dask-cu12-25.2.0:\n",
            "      Successfully uninstalled raft-dask-cu12-25.2.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 25.2.1\n",
            "    Uninstalling cuml-cu12-25.2.1:\n",
            "      Successfully uninstalled cuml-cu12-25.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "google-cloud-pubsub 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 ale-py-0.10.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 contourpy-1.3.1 cuda-python-12.6.0 cudf-cu12-24.12.0 cuml-cu12-24.12.0 cupy-cuda12x-13.4.0 cuvs-cu12-24.12.0 cycler-0.12.1 dask-2024.11.2 dask-cuda-24.12.0 dask-cudf-cu12-24.12.0 dask-expr-1.1.19 distributed-2024.11.2 distributed-ucxx-cu12-0.41.0 farama-notifications-0.0.4 fastrlock-0.8.3 filelock-3.18.0 fonttools-4.56.0 fsspec-2025.3.0 grpcio-1.71.0 gym-anytrading-2.0.0 gymnasium-0.29.1 importlib-metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 kiwisolver-1.4.8 libcudf-cu12-24.12.0 libkvikio-cu12-24.12.1 libucx-cu12-1.17.0.post1 libucxx-cu12-0.41.0 llvmlite-0.44.0 locket-1.0.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.61.0 numba-cuda-0.0.17.1 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvcomp-cu12-4.1.0.6 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 nvtx-0.2.11 opencv-python-4.11.0.86 packaging-24.2 pandas-2.2.3 partd-1.4.2 pillow-11.1.0 protobuf-6.30.1 psutil-7.0.0 pyarrow-18.1.0 pygame-2.6.1 pygments-2.19.1 pylibcudf-cu12-24.12.0 pylibraft-cu12-24.12.0 pynvjitlink-cu12-0.5.2 pynvml-11.4.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-24.12.0 rapids-dask-dependency-24.12.0 rich-13.9.4 rmm-cu12-24.12.1 scipy-1.15.2 setuptools-76.1.0 six-1.17.0 sortedcontainers-2.4.0 stable-baselines3-2.5.0 sympy-1.13.1 tblib-3.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 toolz-1.0.0 torch-2.6.0 tornado-6.4.2 tqdm-4.67.1 treelite-4.3.0 triton-3.2.0 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.41.0 ucxx-cu12-0.41.0 urllib3-2.3.0 werkzeug-3.1.3 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "cycler",
                  "dateutil",
                  "importlib_metadata",
                  "kiwisolver",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "4693076da0fc4aaab4ceb46dc17a7379"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall \\\n",
        "    dask==2024.11.2 \\\n",
        "    rapids-dask-dependency==24.12.0 \\\n",
        "    cudf-cu12==24.12.0 \\\n",
        "    cuml-cu12==24.12.0 \\\n",
        "    pylibraft-cu12==24.12.0 \\\n",
        "    pylibcudf-cu12==24.12.0 \\\n",
        "    numba==0.61.0 \\\n",
        "    stable-baselines3[extra] \\\n",
        "    gymnasium==0.29.1 \\\n",
        "    gym-anytrading==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2eXrK9N8sy",
        "outputId": "1d7a2ec2-a0e5-4cff-b62e-af8a551b3e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym-anytrading in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (0.29.1)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.30.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (76.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[box2d] stable-baselines3[extra] gym-anytrading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "simIAIAMDvA9",
        "outputId": "f6dded96-4cb5-41f8-f2b2-f64edfa79ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.1.3)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.1\n",
            "    Uninstalling protobuf-6.30.1:\n",
            "      Successfully uninstalled protobuf-6.30.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "9228201fa855486ba6614209beadfdfa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install yfinance xgboost joblib protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LSRmcQn3MTvU",
        "outputId": "17aa5f2e-6994-4653-924c-f87f0371a069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-pubsub 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-6.30.1\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.1\n",
            "    Uninstalling protobuf-6.30.1:\n",
            "      Successfully uninstalled protobuf-6.30.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a1492cdd593a452eaf7197f7111c4725"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (76.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "Installing collected packages: numpy, tensorboard\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2 tensorboard-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48yV-FjZMW6-",
        "outputId": "760679e1-bc61-46e5-d175-eefc25ddffcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeEKYZmoMaPH",
        "outputId": "d56c8e7e-898f-43ad-e871-9d351e3d8aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cudf-cu12\n",
            "  Using cached cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12\n",
            "  Using cached cuml_cu12-25.2.1-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting rapids-dask-dependency\n",
            "  Using cached rapids_dask_dependency-25.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools (from cudf-cu12)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,>=12.6.2 (from cudf-cu12)\n",
            "  Using cached cuda_python-12.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12)\n",
            "  Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting fsspec>=0.6.0 (from cudf-cu12)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting libcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Using cached libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.3.0a0,>=0.2.0 (from cudf-cu12)\n",
            "  Using cached numba_cuda-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting numba<0.61.0a0,>=0.59.1 (from cudf-cu12)\n",
            "  Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvtx>=0.2.1 (from cudf-cu12)\n",
            "  Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting packaging (from cudf-cu12)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pyarrow<20.0.0a0,>=14.0.0 (from cudf-cu12)\n",
            "  Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pylibcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Using cached pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12)\n",
            "  Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==25.2.* (from cudf-cu12)\n",
            "  Using cached rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "Collecting typing_extensions>=4.0.0 (from cudf-cu12)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting libkvikio-cu12==25.2.* (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Using cached libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.2.0.11 (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Using cached nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl.metadata (863 bytes)\n",
            "Collecting cuvs-cu12==25.2.* (from cuml-cu12)\n",
            "  Using cached cuvs_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting dask-cuda==25.2.* (from cuml-cu12)\n",
            "  Using cached dask_cuda-25.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dask-cudf-cu12==25.2.* (from cuml-cu12)\n",
            "  Using cached dask_cudf_cu12-25.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting libcuml-cu12==25.2.* (from cuml-cu12)\n",
            "  Using cached libcuml_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting pylibraft-cu12==25.2.* (from cuml-cu12)\n",
            "  Using cached pylibraft_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting raft-dask-cu12==25.2.* (from cuml-cu12)\n",
            "  Using cached raft_dask_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting treelite==4.4.1 (from cuml-cu12)\n",
            "  Using cached treelite-4.4.1-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting dask==2024.12.1 (from rapids-dask-dependency)\n",
            "  Using cached dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.12.1 (from rapids-dask-dependency)\n",
            "  Using cached distributed-2024.12.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.21 (from rapids-dask-dependency)\n",
            "  Using cached dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting libcuvs-cu12==25.2.* (from cuvs-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached libcuvs_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "Collecting click>=8.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib_metadata>=4.13.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pynvml<13.0.0a0,>=12.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Using cached pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libraft-cu12==25.2.* (from libcuml-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached libraft_cu12-25.2.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "Collecting distributed-ucxx-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached distributed_ucxx_cu12-0.42.0-py3-none-any.whl\n",
            "Collecting ucx-py-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached ucx_py_cu12-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting ucxx-cu12==0.42.* (from distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached ucxx_cu12-0.42.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting libucx-cu12<1.19,>=1.15.0 (from ucx-py-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.42.* (from ucxx-cu12==0.42.*->distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Using cached libucxx_cu12-0.42.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "Collecting cuda-bindings~=12.8.0 (from cuda-python<13.0a0,>=12.6.2->cudf-cu12)\n",
            "  Using cached cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12)\n",
            "  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba<0.61.0a0,>=0.59.1->cudf-cu12)\n",
            "  Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12->cuml-cu12)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata>=4.13.0->dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.2.*->cuml-cu12)\n",
            "  Using cached nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "Using cached libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl (557.7 MB)\n",
            "Using cached pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.3 MB)\n",
            "Using cached rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "Using cached libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "Using cached nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl (46.3 MB)\n",
            "Using cached rapids_dask_dependency-25.2.0-py3-none-any.whl (22 kB)\n",
            "Using cached dask-2024.12.1-py3-none-any.whl (1.3 MB)\n",
            "Using cached dask_cuda-25.2.0-py3-none-any.whl (133 kB)\n",
            "Using cached dask_cudf_cu12-25.2.2-py3-none-any.whl (50 kB)\n",
            "Using cached dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
            "Using cached distributed-2024.12.1-py3-none-any.whl (1.0 MB)\n",
            "Using cached treelite-4.4.1-py3-none-manylinux2014_x86_64.whl (922 kB)\n",
            "Using cached cuda_python-12.8.0-py3-none-any.whl (11 kB)\n",
            "Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "Using cached numba_cuda-0.2.0-py3-none-any.whl (443 kB)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl (27.5 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: sortedcontainers, pytz, nvtx, nvidia-ml-py, libkvikio-cu12, fastrlock, cuda-bindings, zipp, zict, urllib3, tzdata, typing_extensions, tornado, toolz, tblib, six, pyyaml, pynvml, pynvjitlink-cu12, pygments, pyarrow, psutil, packaging, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-curand-cu12, nvidia-cublas-cu12, numpy, msgpack, mdurl, MarkupSafe, locket, llvmlite, libucx-cu12, joblib, fsspec, cuda-python, cloudpickle, click, cachetools, ucx-py-cu12, scipy, rmm-cu12, python-dateutil, partd, nvidia-cusparse-cu12, nvidia-cufft-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib_metadata, cupy-cuda12x, ucxx-cu12, treelite, rich, pylibcudf-cu12, pandas, nvidia-cusolver-cu12, numba-cuda, dask, libraft-cu12, distributed, dask-expr, cudf-cu12, rapids-dask-dependency, pylibraft-cu12, libcuvs-cu12, libcuml-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, cuvs-cu12, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 12.570.86\n",
            "    Uninstalling nvidia-ml-py-12.570.86:\n",
            "      Successfully uninstalled nvidia-ml-py-12.570.86\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 24.12.1\n",
            "    Uninstalling libkvikio-cu12-24.12.1:\n",
            "      Successfully uninstalled libkvikio-cu12-24.12.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: cuda-bindings\n",
            "    Found existing installation: cuda-bindings 12.8.0\n",
            "    Uninstalling cuda-bindings-12.8.0:\n",
            "      Successfully uninstalled cuda-bindings-12.8.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 1.0.0\n",
            "    Uninstalling toolz-1.0.0:\n",
            "      Successfully uninstalled toolz-1.0.0\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.4.1\n",
            "    Uninstalling pynvml-11.4.1:\n",
            "      Successfully uninstalled pynvml-11.4.1\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.2\n",
            "    Uninstalling pynvjitlink-cu12-0.5.2:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.1.0.6\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.1.0.6:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.1.0.6\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.44.0\n",
            "    Uninstalling llvmlite-0.44.0:\n",
            "      Successfully uninstalled llvmlite-0.44.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.17.0.post1\n",
            "    Uninstalling libucx-cu12-1.17.0.post1:\n",
            "      Successfully uninstalled libucx-cu12-1.17.0.post1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.0\n",
            "    Uninstalling cuda-python-12.6.0:\n",
            "      Successfully uninstalled cuda-python-12.6.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.41.0\n",
            "    Uninstalling ucx-py-cu12-0.41.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.41.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 24.12.1\n",
            "    Uninstalling rmm-cu12-24.12.1:\n",
            "      Successfully uninstalled rmm-cu12-24.12.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.61.0\n",
            "    Uninstalling numba-0.61.0:\n",
            "      Successfully uninstalled numba-0.61.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.41.0\n",
            "    Uninstalling libucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.41.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 24.12.0\n",
            "    Uninstalling libcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled libcudf-cu12-24.12.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.4.0\n",
            "    Uninstalling cupy-cuda12x-13.4.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.4.0\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.41.0\n",
            "    Uninstalling ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.3.0\n",
            "    Uninstalling treelite-4.3.0:\n",
            "      Successfully uninstalled treelite-4.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 24.12.0\n",
            "    Uninstalling pylibcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibcudf-cu12-24.12.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.0.17.1\n",
            "    Uninstalling numba-cuda-0.0.17.1:\n",
            "      Successfully uninstalled numba-cuda-0.0.17.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.11.2\n",
            "    Uninstalling dask-2024.11.2:\n",
            "      Successfully uninstalled dask-2024.11.2\n",
            "  Attempting uninstall: libraft-cu12\n",
            "    Found existing installation: libraft-cu12 25.2.0\n",
            "    Uninstalling libraft-cu12-25.2.0:\n",
            "      Successfully uninstalled libraft-cu12-25.2.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.11.2\n",
            "    Uninstalling distributed-2024.11.2:\n",
            "      Successfully uninstalled distributed-2024.11.2\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.19\n",
            "    Uninstalling dask-expr-1.1.19:\n",
            "      Successfully uninstalled dask-expr-1.1.19\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 24.12.0\n",
            "    Uninstalling cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled cudf-cu12-24.12.0\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 24.12.0\n",
            "    Uninstalling rapids-dask-dependency-24.12.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-24.12.0\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 24.12.0\n",
            "    Uninstalling pylibraft-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibraft-cu12-24.12.0\n",
            "  Attempting uninstall: libcuvs-cu12\n",
            "    Found existing installation: libcuvs-cu12 25.2.1\n",
            "    Uninstalling libcuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuvs-cu12-25.2.1\n",
            "  Attempting uninstall: libcuml-cu12\n",
            "    Found existing installation: libcuml-cu12 25.2.1\n",
            "    Uninstalling libcuml-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuml-cu12-25.2.1\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.41.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 24.12.0\n",
            "    Uninstalling dask-cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled dask-cudf-cu12-24.12.0\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 24.12.0\n",
            "    Uninstalling dask-cuda-24.12.0:\n",
            "      Successfully uninstalled dask-cuda-24.12.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 24.12.0\n",
            "    Uninstalling cuvs-cu12-24.12.0:\n",
            "      Successfully uninstalled cuvs-cu12-24.12.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 24.12.0\n",
            "    Uninstalling raft-dask-cu12-24.12.0:\n",
            "      Successfully uninstalled raft-dask-cu12-24.12.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 24.12.0\n",
            "    Uninstalling cuml-cu12-24.12.0:\n",
            "      Successfully uninstalled cuml-cu12-24.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.6.0 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 cuda-bindings-12.8.0 cuda-python-12.8.0 cudf-cu12-25.2.2 cuml-cu12-25.2.1 cupy-cuda12x-13.4.0 cuvs-cu12-25.2.1 dask-2024.12.1 dask-cuda-25.2.0 dask-cudf-cu12-25.2.2 dask-expr-1.1.21 distributed-2024.12.1 distributed-ucxx-cu12-0.42.0 fastrlock-0.8.3 fsspec-2025.3.0 importlib_metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 libcudf-cu12-25.2.2 libcuml-cu12-25.2.1 libcuvs-cu12-25.2.1 libkvikio-cu12-25.2.1 libraft-cu12-25.2.0 libucx-cu12-1.18.0 libucxx-cu12-0.42.0 llvmlite-0.43.0 locket-1.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 numba-0.60.0 numba-cuda-0.2.0 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cufft-cu12-11.3.3.83 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-ml-py-12.570.86 nvidia-nvcomp-cu12-4.2.0.11 nvidia-nvjitlink-cu12-12.8.93 nvtx-0.2.11 packaging-24.2 pandas-2.2.3 partd-1.4.2 psutil-7.0.0 pyarrow-19.0.1 pygments-2.19.1 pylibcudf-cu12-25.2.2 pylibraft-cu12-25.2.0 pynvjitlink-cu12-0.5.2 pynvml-12.0.0 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-25.2.0 rapids-dask-dependency-25.2.0 rich-13.9.4 rmm-cu12-25.2.0 scipy-1.15.2 six-1.17.0 sortedcontainers-2.4.0 tblib-3.0.0 toolz-1.0.0 tornado-6.4.2 treelite-4.4.1 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.42.0 ucxx-cu12-0.42.0 urllib3-2.3.0 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "importlib_metadata",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "5fc9f760fbeb4ac0b3333452f342e767"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install --force-reinstall cudf-cu12 cuml-cu12 rapids-dask-dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0BxX4NtYJaEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c51597-f293-4e86-9d42-3a6b253269a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuDF Version: 25.02.02\n",
            "cuML Version: 25.02.01\n",
            "Dask Version: 2024.12.1\n",
            "Stable Baselines3 Installed: 2.5.0\n",
            "Gymnasium Version: 0.29.1\n",
            "NumPy Version: 2.0.2\n",
            "SciPy Version: 1.15.2\n",
            "Pandas Version: 2.2.3\n",
            "Tue Mar 18 14:23:11 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Core Libraries\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import numba\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "#Machine Learning & Data Processing\n",
        "import xgboost as xgb\n",
        "import yfinance as yf\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#RAPIDS Libraries (cuDF & cuML for GPU acceleration)\n",
        "import cudf\n",
        "import cuml\n",
        "import dask\n",
        "\n",
        "#Reinforcement Learning (Stable Baselines3)\n",
        "import torch\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import A2C, PPO, DDPG, TD3\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "#Gym & Trading Environments\n",
        "import gymnasium as gym  #Use Gymnasium instead of Gym\n",
        "from gymnasium.spaces import Discrete, Box\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "import gym_anytrading\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "\n",
        "#TensorFlow & GPU Optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "#Set CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "#Print Version Check\n",
        "print(\"cuDF Version:\", cudf.__version__)\n",
        "print(\"cuML Version:\", cuml.__version__)\n",
        "print(\"Dask Version:\", dask.__version__)\n",
        "print(\"Stable Baselines3 Installed:\", stable_baselines3.__version__)\n",
        "print(\"Gymnasium Version:\", gym.__version__)\n",
        "print(\"NumPy Version:\", np.__version__)\n",
        "print(\"SciPy Version:\", scipy.__version__)\n",
        "print(\"Pandas Version:\", pd.__version__)\n",
        "\n",
        "#GPU Check\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Discrete Trading Environment\n",
        "class DiscreteTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(DiscreteTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "        #Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "        self.position_size = 0.1  # 10% of the portfolio per trade\n",
        "\n",
        "        #Logging Trades & Rewards\n",
        "        self.trade_log = []\n",
        "        self.rewards_log = []\n",
        "\n",
        "        #Define Action and Observation Space\n",
        "        self.action_space = Discrete(3)  # Actions: 0 = SELL, 1 = HOLD, 2 = BUY\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        #Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        #Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        reward = 0  # Default reward\n",
        "        executed = False  # Track if a trade was executed\n",
        "\n",
        "        #BUY ACTION (Require a Bigger Price Drop Before Buying)\n",
        "        if action == 2:\n",
        "            allocated_funds = min(self.portfolio_value * self.position_size, self.portfolio_value * 0.3)\n",
        "            if self.portfolio_value >= allocated_funds:\n",
        "                shares_bought = allocated_funds / new_price\n",
        "                self.shares_held += shares_bought\n",
        "                self.portfolio_value -= shares_bought * new_price\n",
        "                self.last_trade_price = new_price\n",
        "                executed = True\n",
        "\n",
        "                #Adjusted Reward Logic for Better Training\n",
        "                price_change = (self.df['Close'].iloc[self.current_step - 1] - new_price) / max(new_price, 1e-6)\n",
        "                if price_change > 0.01:  # 1%+ Drop  High Reward\n",
        "                    reward = price_change * 80\n",
        "                elif price_change > 0.005:  # 0.5%+ Drop  Moderate Reward\n",
        "                    reward = price_change * 60\n",
        "                else:\n",
        "                    reward = 0.003  #No negative BUY rewards!\n",
        "\n",
        "        #SELL ACTION (Encourage Profitable Selling)\n",
        "        elif action == 0 and self.shares_held > 0:\n",
        "            sell_value = self.shares_held * new_price\n",
        "            profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "\n",
        "            #Require at Least 2% Profit Before Selling\n",
        "            profit_percent = (new_price - self.last_trade_price) / max(self.last_trade_price, 1e-6)\n",
        "            if profit_percent > 0.02:\n",
        "                reward = profit_percent * 350  # Strong reward for good sales\n",
        "            else:\n",
        "                reward = profit_percent * 10  # Reduce penalty for small losses\n",
        "\n",
        "            #Reset portfolio after calculation\n",
        "            self.portfolio_value += sell_value\n",
        "            self.shares_held = 0\n",
        "            self.last_trade_price = 0\n",
        "            executed = True\n",
        "\n",
        "        #HOLD ACTION (Encourage Holding If Profitable)\n",
        "        else:\n",
        "            unrealized_profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "            reward = np.tanh(unrealized_profit / self.initial_balance) * 5\n",
        "\n",
        "        #Log Trade\n",
        "        self.trade_log.append({\n",
        "            \"Step\": self.current_step,\n",
        "            \"Action\": [\"SELL\", \"HOLD\", \"BUY\"][action],\n",
        "            \"Shares Held\": self.shares_held,\n",
        "            \"Portfolio Value\": self.portfolio_value,\n",
        "            \"Stock Price\": new_price,\n",
        "            \"Reward\": reward\n",
        "        })\n",
        "\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n"
      ],
      "metadata": {
        "id": "1CVQi1kty22q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKG932vFKBfA",
        "outputId": "987cc8da-e740-4768-a9c6-5b99227b0ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow GPU memory growth enabled\n",
            "Attempt 1: Downloading AAPL stock data...\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded stock data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Ensure TensorFlow GPU Memory Allocation is Configured\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents full allocation\n",
        "        print(\"TensorFlow GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"TensorFlow GPU memory issue: {e}\")\n",
        "\n",
        "#CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "\n",
        "\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\"Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"AAPL\")\n",
        "if df_live is None:\n",
        "    print(\"Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/aaplfeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)\n",
        "\n",
        "df = df_live.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p9Iyp3gMLizz"
      },
      "outputs": [],
      "source": [
        "#Fix Missing Index\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MiabhGq1Lz-n"
      },
      "outputs": [],
      "source": [
        "#Step 3: Feature Engineering\n",
        "def compute_technical_indicators(df):\n",
        "    #Simple Moving Average (SMA) & Bollinger Bands\n",
        "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "\n",
        "    df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "    df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']  #Added Lower Band\n",
        "\n",
        "    #Stochastic Oscillator\n",
        "    df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "    df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "    df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "\n",
        "    #Rolling Volatility Feature\n",
        "    df['volatility'] = df['Close'].pct_change().rolling(20).std()\n",
        "\n",
        "    #Drop NA values after feature calculations\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "#Step 4: Labeling (Buy/Sell Signals)\n",
        "def generate_trade_labels(df, lookahead=10, threshold_factor=2):\n",
        "    #Ensure 'Close' column exists\n",
        "    if 'Close' not in df.columns:\n",
        "        raise KeyError(\"'Close' column is missing. Cannot generate trade labels.\")\n",
        "\n",
        "    #Generate future price shift\n",
        "    df['Future_Close'] = df['Close'].shift(-lookahead)\n",
        "    df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "\n",
        "    #Primary Target Label: Binary Classification (Buy = 1, Sell = 0)\n",
        "    df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "\n",
        "    #Volatility-Adjusted Dynamic Labels\n",
        "    buy_threshold = df['volatility'] * threshold_factor\n",
        "    sell_threshold = -df['volatility'] * threshold_factor\n",
        "\n",
        "    df['Dynamic_Label'] = np.where(df['Price_Change'] > buy_threshold, 1,\n",
        "                            np.where(df['Price_Change'] < sell_threshold, -1, 0))\n",
        "\n",
        "    #Drop NaN values after target calculations\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "#Apply Feature Engineering & Target Labeling\n",
        "df = compute_technical_indicators(df)  #Compute Features\n",
        "df = generate_trade_labels(df)  #Generate 'Target' Column\n",
        "\n",
        "#Check if 'Target' exists before training\n",
        "if 'Target' not in df.columns:\n",
        "    raise KeyError(\"'Target' column is missing after feature engineering. Check generate_trade_labels(df).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure df is preprocessed correctly\n",
        "if \"SMA_20\" not in df.columns:\n",
        "    raise ValueError(\"'SMA_20' feature missing. Ensure feature engineering is applied.\")\n",
        "\n",
        "#Define Features for Model Training\n",
        "features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "target_column = 'Target'\n"
      ],
      "metadata": {
        "id": "GAm2k7tg1E19"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhbHD6ibMJuR",
        "outputId": "f64fcca3-28a2-4550-be51-d526af09a1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Accuracy Across Time Splits: 0.9048\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.98      0.98       808\n",
            "         1.0       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.95       830\n",
            "   macro avg       0.49      0.49      0.49       830\n",
            "weighted avg       0.95      0.95      0.95       830\n",
            "\n",
            "Random Forest model saved as rf_trading_model.pkl\n"
          ]
        }
      ],
      "source": [
        "def train_walk_forward(df, features, label='Target', model_path=\"rf_trading_model.pkl\"):\n",
        "    \"\"\"Train a Random Forest model using time-based walk-forward validation.\"\"\"\n",
        "\n",
        "    #Ensure train-test splits are time-based\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        #Convert pandas to cudf for GPU acceleration (ensure float32)\n",
        "        X_train = cudf.DataFrame.from_pandas(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame.from_pandas(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        #Convert to Pandas before using SMOTE\n",
        "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train.to_pandas(), y_train.to_pandas())\n",
        "\n",
        "        #Convert back to cuDF\n",
        "        X_train = cudf.DataFrame.from_pandas(X_resampled)\n",
        "        y_train = cudf.Series(y_resampled)\n",
        "\n",
        "        #Ensure data is available before training\n",
        "        if X_train.shape[0] == 0:\n",
        "            raise ValueError(\"No training data available! Ensure features are correctly calculated.\")\n",
        "\n",
        "        #Train model\n",
        "        model = RandomForestClassifier(n_estimators=100)\n",
        "        model.fit(X_train.to_pandas(), y_train.to_pandas())  #Explicit conversion\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model, model_path)  #Save the model to a file\n",
        "\n",
        "        #Convert X_test to Pandas before prediction\n",
        "        probs = model.predict_proba(X_test.to_pandas())  #Fix: Convert before calling predict_proba\n",
        "        custom_threshold = 0.4  # Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        #Convert y_test to Pandas before using NumPy functions\n",
        "        y_test = y_test.to_pandas().to_numpy()  #Fix: Convert cuDF Series  Pandas  NumPy\n",
        "\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    #Print Classification Report\n",
        "    print(\"\\nRandom Forest Classification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    print(f\"Random Forest model saved as {model_path}\")\n",
        "    return model\n",
        "\n",
        "#Train & Save Random Forest Model\n",
        "rf_model = train_walk_forward(df, features, label='Target')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ZTff0SMNx4",
        "outputId": "2967b898-a89e-4934-d135-07d6bc237d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and labels are ready for XGBoost training.\n"
          ]
        }
      ],
      "source": [
        "#Ensure Feature Engineering is Applied Before Training\n",
        "if \"SMA_20\" not in df.columns:  # Prevent recomputation\n",
        "    df = compute_technical_indicators(df)\n",
        "\n",
        "df = generate_trade_labels(df)  #Generate Buy/Sell Labels\n",
        "\n",
        "#Ensure Features & Trade Signals Exist\n",
        "required_features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "if not all(feature in df.columns for feature in required_features):\n",
        "    raise ValueError(f\"Missing Features: {set(required_features) - set(df.columns)}. Run feature engineering first!\")\n",
        "\n",
        "if 'Target' not in df.columns:\n",
        "    raise ValueError(\"Target column is missing! Run generate_trade_labels(df) first!\")\n",
        "\n",
        "print(\"Features and labels are ready for XGBoost training.\")\n",
        "\n",
        "#Drop NaN Values Before Training\n",
        "df.dropna(subset=required_features + ['Target'], inplace=True)\n",
        "\n",
        "#Define Feature Columns & Target\n",
        "feature_columns = required_features\n",
        "target_column = 'Target'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_xgboost(df, features, label='Target', model_path=\"xgb_trading_model.pkl\"):\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        #Keep data on GPU\n",
        "        X_train = cudf.DataFrame(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        #Fix scale_pos_weight calculation\n",
        "        scale_pos_weight = (sum(y_train.to_numpy() == 0) / (sum(y_train.to_numpy() == 1) + 1e-6))\n",
        "\n",
        "        #Use latest GPU-optimized settings\n",
        "        params = {\n",
        "            'objective': 'binary:logistic',\n",
        "            'learning_rate': 0.1,\n",
        "            'n_estimators': 50,\n",
        "            'tree_method': 'hist',  #Use \"hist\" instead of \"gpu_hist\"\n",
        "            'device': 'cuda',       #Explicitly set GPU device\n",
        "            'scale_pos_weight': scale_pos_weight,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        #Convert cuDF to NumPy for XGBoost compatibility\n",
        "        X_train_np = X_train.to_numpy()\n",
        "        y_train_np = y_train.to_numpy()\n",
        "\n",
        "        X_test_np = X_test.to_numpy()\n",
        "        y_test_np = y_test.to_numpy()\n",
        "\n",
        "        #Train model\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(X_train_np, y_train_np)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model, model_path)  #Save the model to a file\n",
        "\n",
        "        #Use probability threshold for better predictions\n",
        "        probs = model.predict_proba(X_test_np)\n",
        "        custom_threshold = 0.4  #Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        acc = accuracy_score(y_test_np, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    #Print Classification Report\n",
        "    print(\"\\nXGBoost Classification Report:\")\n",
        "    print(classification_report(y_test_np, preds))\n",
        "\n",
        "    print(f\"XGBoost model saved as {model_path}\")\n",
        "    return model\n",
        "\n",
        "#Train & Save XGBoost Model\n",
        "xgb_model = train_xgboost(df, feature_columns, label=target_column)\n",
        "\n",
        "#Free Memory\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwGIbbrMEmU",
        "outputId": "a0466b18-d58c-4905-c7b7-ec5792a85a5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:23:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Accuracy Across Time Splits: 0.9123\n",
            "\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98       805\n",
            "         1.0       0.08      0.04      0.06        23\n",
            "\n",
            "    accuracy                           0.96       828\n",
            "   macro avg       0.53      0.51      0.52       828\n",
            "weighted avg       0.95      0.96      0.95       828\n",
            "\n",
            "XGBoost model saved as xgb_trading_model.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Discrete Trading Environment\n",
        "class DiscreteTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(DiscreteTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "        #Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "        self.position_size = 0.1  # 10% of the portfolio per trade\n",
        "\n",
        "        #Logging Trades & Rewards\n",
        "        self.trade_log = []\n",
        "        self.rewards_log = []\n",
        "\n",
        "        #Define Action and Observation Space\n",
        "        self.action_space = Discrete(3)  # Actions: 0 = SELL, 1 = HOLD, 2 = BUY\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        #Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        #Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        reward = 0  # Default reward\n",
        "        executed = False  # Track if a trade was executed\n",
        "\n",
        "        #BUY ACTION (Require a Bigger Price Drop Before Buying)\n",
        "        if action == 2:\n",
        "            allocated_funds = min(self.portfolio_value * self.position_size, self.portfolio_value * 0.3)\n",
        "            if self.portfolio_value >= allocated_funds:\n",
        "                shares_bought = allocated_funds / new_price\n",
        "                self.shares_held += shares_bought\n",
        "                self.portfolio_value -= shares_bought * new_price\n",
        "                self.last_trade_price = new_price\n",
        "                executed = True\n",
        "\n",
        "                #Adjusted Reward Logic for Better Training\n",
        "                price_change = (self.df['Close'].iloc[self.current_step - 1] - new_price) / max(new_price, 1e-6)\n",
        "                if price_change > 0.01:  # 1%+ Drop  High Reward\n",
        "                    reward = price_change * 80\n",
        "                elif price_change > 0.005:  # 0.5%+ Drop  Moderate Reward\n",
        "                    reward = price_change * 60\n",
        "                else:\n",
        "                    reward = 0.003  #No negative BUY rewards!\n",
        "\n",
        "        #SELL ACTION (Encourage Profitable Selling)\n",
        "        elif action == 0 and self.shares_held > 0:\n",
        "            sell_value = self.shares_held * new_price\n",
        "            profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "\n",
        "            #Require at Least 2% Profit Before Selling\n",
        "            profit_percent = (new_price - self.last_trade_price) / max(self.last_trade_price, 1e-6)\n",
        "            if profit_percent > 0.02:\n",
        "                reward = profit_percent * 350  # Strong reward for good sales\n",
        "            else:\n",
        "                reward = profit_percent * 10  # Reduce penalty for small losses\n",
        "\n",
        "            #Reset portfolio after calculation\n",
        "            self.portfolio_value += sell_value\n",
        "            self.shares_held = 0\n",
        "            self.last_trade_price = 0\n",
        "            executed = True\n",
        "\n",
        "        #HOLD ACTION (Encourage Holding If Profitable)\n",
        "        else:\n",
        "            unrealized_profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "            reward = np.tanh(unrealized_profit / self.initial_balance) * 5\n",
        "\n",
        "        #Log Trade\n",
        "        self.trade_log.append({\n",
        "            \"Step\": self.current_step,\n",
        "            \"Action\": [\"SELL\", \"HOLD\", \"BUY\"][action],\n",
        "            \"Shares Held\": self.shares_held,\n",
        "            \"Portfolio Value\": self.portfolio_value,\n",
        "            \"Stock Price\": new_price,\n",
        "            \"Reward\": reward\n",
        "        })\n",
        "\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n",
        "\n",
        "#Step 1: Define Environment Creation Function\n",
        "def make_env():\n",
        "    return gym.wrappers.TimeLimit(\n",
        "        DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10),\n",
        "        max_episode_steps=1000\n",
        "    )\n",
        "\n",
        "#Step 2: Properly Create Vectorized Environment\n",
        "env_discrete = make_vec_env(make_env, n_envs=1)\n",
        "\n",
        "#Step 3: Normalize Environment (Fixed Method)\n",
        "env_discrete = VecNormalize(env_discrete, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "#Step 4: Debugging Action Space\n",
        "print(f\"Action Space: {env_discrete.action_space}\")\n",
        "print(f\"Sample Action: {env_discrete.action_space.sample()}\")\n",
        "\n",
        "#Step 5: Train PPO Model\n",
        "print(\"\\nTraining PPO Model...\")\n",
        "ppo_model = PPO(\"MlpPolicy\", env_discrete, verbose=1, device=\"cuda\")\n",
        "ppo_model.learn(total_timesteps=10000)\n",
        "ppo_model.save(\"ppo_trading_model_v1\")\n",
        "print(\"\\nPPO Training Complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf8dSzkExUSP",
        "outputId": "e22b56f6-287b-4471-c092-ae28be58a533"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(3)\n",
            "Sample Action: 0\n",
            "\n",
            "Training PPO Model...\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 123      |\n",
            "| time/              |          |\n",
            "|    fps             | 405      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 99.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010331932 |\n",
            "|    clip_fraction        | 0.0827      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.0986      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.211       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00448    |\n",
            "|    value_loss           | 0.469       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 102          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044632615 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.409        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.178        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 104         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009415315 |\n",
            "|    clip_fraction        | 0.0512      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.378       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0664      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00442    |\n",
            "|    value_loss           | 0.131       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 105        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 344        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 29         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01222939 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.06      |\n",
            "|    explained_variance   | 0.206      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.14       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00913   |\n",
            "|    value_loss           | 0.144      |\n",
            "----------------------------------------\n",
            "\n",
            "PPO Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain A2C Model with Higher Entropy Regularization\n",
        "print(\"\\nRetraining A2C Model with Higher Entropy Regularization...\")\n",
        "a2c_model = A2C(\n",
        "    \"MlpPolicy\",\n",
        "    env_discrete,\n",
        "    learning_rate=0.0005,  #Lower learning rate for more stable updates\n",
        "    gamma=0.98,  #Encourage slightly longer-term rewards\n",
        "    vf_coef=0.4,  #Balance value function loss\n",
        "    ent_coef=0.01,  #Increase entropy for better exploration\n",
        "    verbose=1,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "\n",
        "print(\"\\nRetraining A2C Model with Adjusted Parameters...\")\n",
        "a2c_model.learn(total_timesteps=10000)  #Train for 100000 timesteps\n",
        "a2c_model.save(\"a2c_trading_model_v1\")\n",
        "print(\"\\nA2C Training Complete!\")\n"
      ],
      "metadata": {
        "id": "9FLsWZ7NK1vO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca7c333-7779-492e-92ab-e9261c2a7f3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retraining A2C Model with Higher Entropy Regularization...\n",
            "Using cuda device\n",
            "\n",
            "Retraining A2C Model with Adjusted Parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 350      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1       |\n",
            "|    explained_variance | -44.3    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -0.00294 |\n",
            "|    value_loss         | 0.000698 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 76       |\n",
            "| time/                 |          |\n",
            "|    fps                | 355      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | -30.3    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.156   |\n",
            "|    value_loss         | 0.0204   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 76       |\n",
            "| time/                 |          |\n",
            "|    fps                | 359      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.02    |\n",
            "|    explained_variance | -36      |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.0255   |\n",
            "|    value_loss         | 0.000731 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 82       |\n",
            "| time/                 |          |\n",
            "|    fps                | 346      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.1     |\n",
            "|    explained_variance | -5.42    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.27     |\n",
            "|    value_loss         | 0.063    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 82       |\n",
            "| time/                 |          |\n",
            "|    fps                | 289      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.09    |\n",
            "|    explained_variance | -4.72    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.127    |\n",
            "|    value_loss         | 0.0169   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 96.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | -1.05    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.239    |\n",
            "|    value_loss         | 0.0524   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 96.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 261      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | -5.05    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.234    |\n",
            "|    value_loss         | 0.0495   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 99.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 271      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.06    |\n",
            "|    explained_variance | -2.31    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.146    |\n",
            "|    value_loss         | 0.0182   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 99.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 278      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.983   |\n",
            "|    explained_variance | -0.747   |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.00913 |\n",
            "|    value_loss         | 0.000151 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 99.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 284      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.09    |\n",
            "|    explained_variance | -1.37    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.161   |\n",
            "|    value_loss         | 0.024    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 99.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 290      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.995   |\n",
            "|    explained_variance | -1.35    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.166    |\n",
            "|    value_loss         | 0.053    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 98.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 295      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | -1.72    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.0752  |\n",
            "|    value_loss         | 0.00518  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 98.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 298      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | 0.0504   |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.249    |\n",
            "|    value_loss         | 0.0496   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 296      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.02    |\n",
            "|    explained_variance | -7.46    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.184    |\n",
            "|    value_loss         | 0.0295   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 298      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.999   |\n",
            "|    explained_variance | -44.6    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.0209   |\n",
            "|    value_loss         | 0.000878 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 109      |\n",
            "| time/                 |          |\n",
            "|    fps                | 302      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.09    |\n",
            "|    explained_variance | -1.68    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.132   |\n",
            "|    value_loss         | 0.0164   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 109      |\n",
            "| time/                 |          |\n",
            "|    fps                | 304      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1       |\n",
            "|    explained_variance | -41.8    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0348   |\n",
            "|    value_loss         | 0.00159  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 111      |\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.03    |\n",
            "|    explained_variance | 0.854    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.142    |\n",
            "|    value_loss         | 0.0197   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 111      |\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | 0.728    |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.184    |\n",
            "|    value_loss         | 0.0443   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 1e+03    |\n",
            "|    ep_rew_mean        | 111      |\n",
            "| time/                 |          |\n",
            "|    fps                | 311      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.882   |\n",
            "|    explained_variance | 0.0733   |\n",
            "|    learning_rate      | 0.0005   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0678   |\n",
            "|    value_loss         | 0.01     |\n",
            "------------------------------------\n",
            "\n",
            "A2C Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Model Evaluation Function (Fixed for VecEnv)\n",
        "def evaluate_model(model, env, num_steps=100):\n",
        "    \"\"\"Evaluates a trained model and logs actions taken.\"\"\"\n",
        "    obs = env.reset()  #FIX: No unpacking for VecEnv reset\n",
        "    action_history = []\n",
        "    total_rewards = np.zeros(env.num_envs)  #VecEnv handles multiple environments\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action, _ = model.predict(obs)\n",
        "        action = int(action.item())  #Convert to integer (Discrete Action)\n",
        "\n",
        "        print(f\"Executing action: {action}\")  # Debugging\n",
        "\n",
        "        obs, reward, done, _ = env.step([action])  #FIX: Wrap action in list for VecEnv\n",
        "        action_history.append(action)\n",
        "        total_rewards += reward  #Correctly sum rewards across all environments\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}: Action: {action}, Reward: {reward.mean():.4f}\")\n",
        "\n",
        "        if done.any():  #FIX: `done` is an array in VecEnv\n",
        "            obs = env.reset()\n",
        "\n",
        "    #Print action history and total test reward\n",
        "    unique_actions = set(action_history)\n",
        "    print(f\"Actions Taken: {action_history if action_history else 'No trades executed.'}\")\n",
        "    print(f\"Total Test Reward: {total_rewards.sum():.4f}\")  #FIX: Sum over VecEnv rewards\n",
        "\n",
        "    if len(unique_actions) < 3:\n",
        "        print(\"Agent might not be exploring all actions properly.\")\n",
        "\n",
        "#Evaluate PPO Model\n",
        "print(\"\\nEvaluating PPO Model...\")\n",
        "evaluate_model(ppo_model, env_discrete)\n",
        "\n",
        "#Evaluate A2C Model\n",
        "print(\"\\nEvaluating A2C Model...\")\n",
        "evaluate_model(a2c_model, env_discrete)\n",
        "\n",
        "print(\"\\nPPO & A2C Evaluation Complete!\")\n",
        "\n",
        "#Get the first (and only) wrapped discrete environment\n",
        "wrapped_env = env_discrete.envs[0]\n",
        "\n",
        "#Properly Access Trade Log (Backward Compatible)\n",
        "if hasattr(env_discrete, \"get_wrapper_attr\"):\n",
        "    trade_log_ppo = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_ppo = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "\n",
        "    trade_log_a2c = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_a2c = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "else:\n",
        "    trade_log_ppo = wrapped_env.unwrapped.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_ppo = wrapped_env.unwrapped.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "    trade_log_a2c = wrapped_env.unwrapped.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_a2c = wrapped_env.unwrapped.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "#Summarize Trade Results\n",
        "num_trades_ppo = len(trade_log_ppo)\n",
        "num_rewards_ppo = len(rewards_log_ppo)\n",
        "num_trades_a2c = len(trade_log_a2c)\n",
        "num_rewards_a2c = len(rewards_log_a2c)\n",
        "\n",
        "print(f\"Number of Trades Logged (PPO): {num_trades_ppo}\")\n",
        "print(f\"Number of Rewards Logged (PPO): {num_rewards_ppo}\")\n",
        "\n",
        "#Log Mean & Max Rewards (More Insight)\n",
        "if rewards_log_ppo:\n",
        "    print(f\"PPO Mean Reward: {np.mean(rewards_log_ppo):.4f}, Max Reward: {np.max(rewards_log_ppo):.4f}\")\n",
        "\n",
        "if num_trades_ppo == 0:\n",
        "    print(\"No trades recorded. The PPO agent might not be executing actions.\")\n",
        "if num_rewards_ppo == 0:\n",
        "    print(\"No rewards recorded. The PPO environment might not be returning meaningful rewards.\")\n",
        "\n",
        "print(f\"Number of Trades Logged (A2C): {num_trades_a2c}\")\n",
        "print(f\"Number of Rewards Logged (A2C): {num_rewards_a2c}\")\n",
        "\n",
        "if rewards_log_a2c:\n",
        "    print(f\"A2C Mean Reward: {np.mean(rewards_log_a2c):.4f}, Max Reward: {np.max(rewards_log_a2c):.4f}\")\n",
        "\n",
        "if num_trades_a2c == 0:\n",
        "    print(\"No trades recorded. The A2C agent might not be executing actions.\")\n",
        "if num_rewards_a2c == 0:\n",
        "    print(\"No rewards recorded. The A2C environment might not be returning meaningful rewards.\")\n",
        "\n",
        "#Detect Stagnant Portfolio Value\n",
        "if num_trades_ppo > 0:\n",
        "    portfolio_changes = [t[\"Portfolio Value\"] for t in trade_log_ppo]\n",
        "    if len(set(portfolio_changes)) == 1:\n",
        "        print(\"PPO agent's portfolio value is not changing. Possible issue with trading logic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qfSVGSo2K_K",
        "outputId": "7464440d-f696-4e86-ad1d-1db92e7a8db8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating PPO Model...\n",
            "Executing action: 2\n",
            "Step 0: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 10: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Step 20: Action: 1, Reward: -0.0001\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Step 30: Action: 0, Reward: -0.0129\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Step 40: Action: 0, Reward: -0.0627\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Step 50: Action: 0, Reward: -0.0243\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Step 60: Action: 0, Reward: 0.0000\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Step 70: Action: 1, Reward: 0.0000\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 80: Action: 2, Reward: 0.0005\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Step 90: Action: 1, Reward: -0.0001\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Actions Taken: [2, 2, 1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 2, 0, 0]\n",
            "Total Test Reward: 3.8596\n",
            "\n",
            "Evaluating A2C Model...\n",
            "Executing action: 2\n",
            "Step 0: Action: 2, Reward: 0.0005\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 10: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 20: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 30: Action: 2, Reward: 0.0782\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 40: Action: 2, Reward: 0.1929\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 50: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 60: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 70: Action: 2, Reward: 0.0543\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 80: Action: 2, Reward: 0.0005\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 90: Action: 2, Reward: 0.0005\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Actions Taken: [2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 0]\n",
            "Total Test Reward: 2.4206\n",
            "\n",
            "PPO & A2C Evaluation Complete!\n",
            "Number of Trades Logged (PPO): 100\n",
            "Number of Rewards Logged (PPO): 100\n",
            "PPO Mean Reward: 0.1498, Max Reward: 1.8002\n",
            "Number of Trades Logged (A2C): 100\n",
            "Number of Rewards Logged (A2C): 100\n",
            "A2C Mean Reward: 0.1498, Max Reward: 1.8002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-jVIK3X4hVj2"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSAAgent:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=1.0, epsilon_decay=0.999, min_epsilon=0.01):\n",
        "        \"\"\"SARSA agent for discrete action space trading.\"\"\"\n",
        "        self.env = env\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "\n",
        "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))  # Q-table initialization\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return self.env.action_space.sample()  # Explore\n",
        "        return np.argmax(self.q_table[state])  # Exploit\n",
        "\n",
        "    def train(self, num_episodes=10000):\n",
        "        \"\"\"Train the SARSA agent.\"\"\"\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())  # Convert state to a tuple (hashable)\n",
        "            action = self.choose_action(state)\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())\n",
        "\n",
        "                next_action = self.choose_action(next_state)  # SARSA selects next action\n",
        "\n",
        "                #SARSA Update Rule\n",
        "                self.q_table[state][action] += self.alpha * (\n",
        "                    reward + self.gamma * self.q_table[next_state][next_action] - self.q_table[state][action]\n",
        "                )\n",
        "\n",
        "                state, action = next_state, next_action\n",
        "                total_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            #Adjust Epsilon Decay\n",
        "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "            if episode % 100 == 0:\n",
        "                print(f\"Episode {episode}/{num_episodes}, Total Reward: {total_reward:.2f}\")\n",
        "\n",
        "        print(\"\\nSARSA Training Complete!\")\n",
        "\n",
        "    def evaluate(self, num_episodes=100):\n",
        "        \"\"\"Evaluate the trained SARSA agent.\"\"\"\n",
        "        total_rewards = []\n",
        "        action_counts = {\"SELL\": 0, \"HOLD\": 0, \"BUY\": 0}\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):\n",
        "                action = np.argmax(self.q_table[state])\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())\n",
        "\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "\n",
        "                #Log Actions\n",
        "                if action == 0:\n",
        "                    action_counts[\"SELL\"] += 1\n",
        "                elif action == 1:\n",
        "                    action_counts[\"HOLD\"] += 1\n",
        "                else:\n",
        "                    action_counts[\"BUY\"] += 1\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            total_rewards.append(total_reward)\n",
        "            print(f\"Episode {episode+1}/{num_episodes}, Reward: {total_reward:.2f}\")\n",
        "\n",
        "        avg_reward = np.mean(total_rewards)\n",
        "        print(f\"\\nAverage Test Reward: {avg_reward:.2f}\")\n",
        "        print(\"\\nAction Distribution:\")\n",
        "        print(f\"SELL: {action_counts['SELL']}\")\n",
        "        print(f\"HOLD: {action_counts['HOLD']}\")\n",
        "        print(f\"BUY: {action_counts['BUY']}\")\n",
        "\n",
        "        #Detect Imbalance in Action Distribution\n",
        "        if action_counts[\"SELL\"] > action_counts[\"BUY\"] * 5:\n",
        "            print(\"Warning: Too much selling compared to buying! Adjust reward incentives.\")"
      ],
      "metadata": {
        "id": "Cz9_Oo1jUXLE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate SARSA Agent with Adjusted Reward Function\n",
        "env_discrete_sarsa = DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)\n",
        "sarsa_agent = SARSAAgent(env_discrete_sarsa)\n",
        "\n",
        "#Train SARSA Model\n",
        "print(\"\\nTraining SARSA Model...\")\n",
        "sarsa_agent.train(num_episodes=10000)\n",
        "\n",
        "#Evaluate SARSA Model\n",
        "print(\"\\nEvaluating SARSA Model...\")\n",
        "sarsa_agent.evaluate(num_episodes=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR2Lu40IET4_",
        "outputId": "78927ef9-1704-4cbe-f0dd-21e32b22567a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SARSA Model...\n",
            "Episode 0/10000, Total Reward: 118.77\n",
            "Episode 100/10000, Total Reward: 72.08\n",
            "Episode 200/10000, Total Reward: 45.77\n",
            "Episode 300/10000, Total Reward: 85.47\n",
            "Episode 400/10000, Total Reward: 83.69\n",
            "Episode 500/10000, Total Reward: 77.74\n",
            "Episode 600/10000, Total Reward: 67.51\n",
            "Episode 700/10000, Total Reward: 40.46\n",
            "Episode 800/10000, Total Reward: 64.72\n",
            "Episode 900/10000, Total Reward: 83.10\n",
            "Episode 1000/10000, Total Reward: 79.16\n",
            "Episode 1100/10000, Total Reward: 53.82\n",
            "Episode 1200/10000, Total Reward: 44.18\n",
            "Episode 1300/10000, Total Reward: 17.45\n",
            "Episode 1400/10000, Total Reward: 21.69\n",
            "Episode 1500/10000, Total Reward: 24.48\n",
            "Episode 1600/10000, Total Reward: 11.03\n",
            "Episode 1700/10000, Total Reward: 7.19\n",
            "Episode 1800/10000, Total Reward: 13.56\n",
            "Episode 1900/10000, Total Reward: 24.29\n",
            "Episode 2000/10000, Total Reward: 30.45\n",
            "Episode 2100/10000, Total Reward: 40.57\n",
            "Episode 2200/10000, Total Reward: 82.59\n",
            "Episode 2300/10000, Total Reward: 24.78\n",
            "Episode 2400/10000, Total Reward: 26.13\n",
            "Episode 2500/10000, Total Reward: 25.59\n",
            "Episode 2600/10000, Total Reward: 31.81\n",
            "Episode 2700/10000, Total Reward: 7.89\n",
            "Episode 2800/10000, Total Reward: 13.94\n",
            "Episode 2900/10000, Total Reward: 23.86\n",
            "Episode 3000/10000, Total Reward: 20.96\n",
            "Episode 3100/10000, Total Reward: 31.56\n",
            "Episode 3200/10000, Total Reward: 14.37\n",
            "Episode 3300/10000, Total Reward: 21.95\n",
            "Episode 3400/10000, Total Reward: 24.70\n",
            "Episode 3500/10000, Total Reward: 33.33\n",
            "Episode 3600/10000, Total Reward: 12.99\n",
            "Episode 3700/10000, Total Reward: 26.05\n",
            "Episode 3800/10000, Total Reward: 32.38\n",
            "Episode 3900/10000, Total Reward: 57.10\n",
            "Episode 4000/10000, Total Reward: 42.28\n",
            "Episode 4100/10000, Total Reward: 68.69\n",
            "Episode 4200/10000, Total Reward: 69.57\n",
            "Episode 4300/10000, Total Reward: 16.11\n",
            "Episode 4400/10000, Total Reward: 68.59\n",
            "Episode 4500/10000, Total Reward: 40.36\n",
            "Episode 4600/10000, Total Reward: 70.48\n",
            "Episode 4700/10000, Total Reward: 68.74\n",
            "Episode 4800/10000, Total Reward: 33.79\n",
            "Episode 4900/10000, Total Reward: 11.98\n",
            "Episode 5000/10000, Total Reward: 69.99\n",
            "Episode 5100/10000, Total Reward: 69.85\n",
            "Episode 5200/10000, Total Reward: 69.53\n",
            "Episode 5300/10000, Total Reward: 45.75\n",
            "Episode 5400/10000, Total Reward: 36.02\n",
            "Episode 5500/10000, Total Reward: 24.17\n",
            "Episode 5600/10000, Total Reward: 69.25\n",
            "Episode 5700/10000, Total Reward: 24.98\n",
            "Episode 5800/10000, Total Reward: 49.43\n",
            "Episode 5900/10000, Total Reward: 22.65\n",
            "Episode 6000/10000, Total Reward: 69.37\n",
            "Episode 6100/10000, Total Reward: 42.88\n",
            "Episode 6200/10000, Total Reward: 20.21\n",
            "Episode 6300/10000, Total Reward: 81.14\n",
            "Episode 6400/10000, Total Reward: 49.31\n",
            "Episode 6500/10000, Total Reward: 21.99\n",
            "Episode 6600/10000, Total Reward: 47.82\n",
            "Episode 6700/10000, Total Reward: 81.90\n",
            "Episode 6800/10000, Total Reward: 29.13\n",
            "Episode 6900/10000, Total Reward: 19.17\n",
            "Episode 7000/10000, Total Reward: 10.29\n",
            "Episode 7100/10000, Total Reward: 31.75\n",
            "Episode 7200/10000, Total Reward: 69.78\n",
            "Episode 7300/10000, Total Reward: 45.71\n",
            "Episode 7400/10000, Total Reward: 26.32\n",
            "Episode 7500/10000, Total Reward: 57.73\n",
            "Episode 7600/10000, Total Reward: 85.67\n",
            "Episode 7700/10000, Total Reward: 14.10\n",
            "Episode 7800/10000, Total Reward: 70.29\n",
            "Episode 7900/10000, Total Reward: 68.63\n",
            "Episode 8000/10000, Total Reward: 44.93\n",
            "Episode 8100/10000, Total Reward: 49.38\n",
            "Episode 8200/10000, Total Reward: 49.05\n",
            "Episode 8300/10000, Total Reward: 49.06\n",
            "Episode 8400/10000, Total Reward: 49.44\n",
            "Episode 8500/10000, Total Reward: 86.56\n",
            "Episode 8600/10000, Total Reward: 22.87\n",
            "Episode 8700/10000, Total Reward: 44.62\n",
            "Episode 8800/10000, Total Reward: 59.26\n",
            "Episode 8900/10000, Total Reward: 48.95\n",
            "Episode 9000/10000, Total Reward: 53.35\n",
            "Episode 9100/10000, Total Reward: 86.64\n",
            "Episode 9200/10000, Total Reward: 81.06\n",
            "Episode 9300/10000, Total Reward: 96.46\n",
            "Episode 9400/10000, Total Reward: 44.88\n",
            "Episode 9500/10000, Total Reward: 40.48\n",
            "Episode 9600/10000, Total Reward: 69.93\n",
            "Episode 9700/10000, Total Reward: 28.78\n",
            "Episode 9800/10000, Total Reward: 44.72\n",
            "Episode 9900/10000, Total Reward: 85.23\n",
            "\n",
            "SARSA Training Complete!\n",
            "\n",
            "Evaluating SARSA Model...\n",
            "Episode 1/100, Reward: 113.49\n",
            "Episode 2/100, Reward: 113.49\n",
            "Episode 3/100, Reward: 113.49\n",
            "Episode 4/100, Reward: 113.49\n",
            "Episode 5/100, Reward: 113.49\n",
            "Episode 6/100, Reward: 113.49\n",
            "Episode 7/100, Reward: 113.49\n",
            "Episode 8/100, Reward: 113.49\n",
            "Episode 9/100, Reward: 113.49\n",
            "Episode 10/100, Reward: 113.49\n",
            "Episode 11/100, Reward: 113.49\n",
            "Episode 12/100, Reward: 113.49\n",
            "Episode 13/100, Reward: 113.49\n",
            "Episode 14/100, Reward: 113.49\n",
            "Episode 15/100, Reward: 113.49\n",
            "Episode 16/100, Reward: 113.49\n",
            "Episode 17/100, Reward: 113.49\n",
            "Episode 18/100, Reward: 113.49\n",
            "Episode 19/100, Reward: 113.49\n",
            "Episode 20/100, Reward: 113.49\n",
            "Episode 21/100, Reward: 113.49\n",
            "Episode 22/100, Reward: 113.49\n",
            "Episode 23/100, Reward: 113.49\n",
            "Episode 24/100, Reward: 113.49\n",
            "Episode 25/100, Reward: 113.49\n",
            "Episode 26/100, Reward: 113.49\n",
            "Episode 27/100, Reward: 113.49\n",
            "Episode 28/100, Reward: 113.49\n",
            "Episode 29/100, Reward: 113.49\n",
            "Episode 30/100, Reward: 113.49\n",
            "Episode 31/100, Reward: 113.49\n",
            "Episode 32/100, Reward: 113.49\n",
            "Episode 33/100, Reward: 113.49\n",
            "Episode 34/100, Reward: 113.49\n",
            "Episode 35/100, Reward: 113.49\n",
            "Episode 36/100, Reward: 113.49\n",
            "Episode 37/100, Reward: 113.49\n",
            "Episode 38/100, Reward: 113.49\n",
            "Episode 39/100, Reward: 113.49\n",
            "Episode 40/100, Reward: 113.49\n",
            "Episode 41/100, Reward: 113.49\n",
            "Episode 42/100, Reward: 113.49\n",
            "Episode 43/100, Reward: 113.49\n",
            "Episode 44/100, Reward: 113.49\n",
            "Episode 45/100, Reward: 113.49\n",
            "Episode 46/100, Reward: 113.49\n",
            "Episode 47/100, Reward: 113.49\n",
            "Episode 48/100, Reward: 113.49\n",
            "Episode 49/100, Reward: 113.49\n",
            "Episode 50/100, Reward: 113.49\n",
            "Episode 51/100, Reward: 113.49\n",
            "Episode 52/100, Reward: 113.49\n",
            "Episode 53/100, Reward: 113.49\n",
            "Episode 54/100, Reward: 113.49\n",
            "Episode 55/100, Reward: 113.49\n",
            "Episode 56/100, Reward: 113.49\n",
            "Episode 57/100, Reward: 113.49\n",
            "Episode 58/100, Reward: 113.49\n",
            "Episode 59/100, Reward: 113.49\n",
            "Episode 60/100, Reward: 113.49\n",
            "Episode 61/100, Reward: 113.49\n",
            "Episode 62/100, Reward: 113.49\n",
            "Episode 63/100, Reward: 113.49\n",
            "Episode 64/100, Reward: 113.49\n",
            "Episode 65/100, Reward: 113.49\n",
            "Episode 66/100, Reward: 113.49\n",
            "Episode 67/100, Reward: 113.49\n",
            "Episode 68/100, Reward: 113.49\n",
            "Episode 69/100, Reward: 113.49\n",
            "Episode 70/100, Reward: 113.49\n",
            "Episode 71/100, Reward: 113.49\n",
            "Episode 72/100, Reward: 113.49\n",
            "Episode 73/100, Reward: 113.49\n",
            "Episode 74/100, Reward: 113.49\n",
            "Episode 75/100, Reward: 113.49\n",
            "Episode 76/100, Reward: 113.49\n",
            "Episode 77/100, Reward: 113.49\n",
            "Episode 78/100, Reward: 113.49\n",
            "Episode 79/100, Reward: 113.49\n",
            "Episode 80/100, Reward: 113.49\n",
            "Episode 81/100, Reward: 113.49\n",
            "Episode 82/100, Reward: 113.49\n",
            "Episode 83/100, Reward: 113.49\n",
            "Episode 84/100, Reward: 113.49\n",
            "Episode 85/100, Reward: 113.49\n",
            "Episode 86/100, Reward: 113.49\n",
            "Episode 87/100, Reward: 113.49\n",
            "Episode 88/100, Reward: 113.49\n",
            "Episode 89/100, Reward: 113.49\n",
            "Episode 90/100, Reward: 113.49\n",
            "Episode 91/100, Reward: 113.49\n",
            "Episode 92/100, Reward: 113.49\n",
            "Episode 93/100, Reward: 113.49\n",
            "Episode 94/100, Reward: 113.49\n",
            "Episode 95/100, Reward: 113.49\n",
            "Episode 96/100, Reward: 113.49\n",
            "Episode 97/100, Reward: 113.49\n",
            "Episode 98/100, Reward: 113.49\n",
            "Episode 99/100, Reward: 113.49\n",
            "Episode 100/100, Reward: 113.49\n",
            "\n",
            "Average Test Reward: 113.49\n",
            "\n",
            "Action Distribution:\n",
            "SELL: 83500\n",
            "HOLD: 1400\n",
            "BUY: 15100\n",
            "Warning: Too much selling compared to buying! Adjust reward incentives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nInitial Portfolio Value: {env_discrete_sarsa.initial_balance}\")\n",
        "print(f\"Final Portfolio Value After Evaluation: {env_discrete_sarsa.portfolio_value}\")\n"
      ],
      "metadata": {
        "id": "MUiR8q-B--Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1497c7c-e526-4d8c-b7b2-e6468eba3815"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Portfolio Value: 100000\n",
            "Final Portfolio Value After Evaluation: 100083.84625843192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_counts = {0: 0, 1: 0, 2: 0}  # Sell, Hold, Buy\n",
        "\n",
        "for state in sarsa_agent.q_table.keys():\n",
        "    action = np.argmax(sarsa_agent.q_table[state])\n",
        "    action_counts[action] += 1\n",
        "\n",
        "print(\"\\nAction Distribution:\")\n",
        "print(f\"SELL: {action_counts[0]}\")\n",
        "print(f\"HOLD: {action_counts[1]}\")\n",
        "print(f\"BUY: {action_counts[2]}\")\n"
      ],
      "metadata": {
        "id": "slxOynA_-_VI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22fe493-c043-4ad6-e895-1a887a82a7b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Action Distribution:\n",
            "SELL: 7698161\n",
            "HOLD: 169874\n",
            "BUY: 343816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_volatility = df.copy()\n",
        "df_volatility['Close'] = df_volatility['Close'] * np.random.uniform(0.9, 1.1, len(df))  # Simulated high volatility\n",
        "\n",
        "env_stress = DiscreteTradingEnv(df=df_volatility, frame_bound=(10, len(df_volatility)), window_size=10)\n",
        "sarsa_stress_test = SARSAAgent(env_stress)\n",
        "\n",
        "print(\"\\nStress Testing SARSA Model...\")\n",
        "sarsa_stress_test.evaluate(num_episodes=100)\n"
      ],
      "metadata": {
        "id": "ZjGzXPwiQ59F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_values = [np.max(sarsa_agent.q_table[state]) for state in sarsa_agent.q_table.keys()]\n",
        "plt.plot(q_values)\n",
        "plt.xlabel(\"State Index\")\n",
        "plt.ylabel(\"Max Q-Value\")\n",
        "plt.title(\"Q-Value Convergence\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gXYTzId4Q_Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLong-Term Test (1,000 Episodes)...\")\n",
        "sarsa_agent.evaluate(num_episodes=1000)\n"
      ],
      "metadata": {
        "id": "hTVlG8kW_NYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8528fc-94cb-4796-cba9-cf0ac7f554c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Long-Term Test (1,000 Episodes)...\n",
            "Episode 1/1000, Reward: 84.89\n",
            "Episode 2/1000, Reward: 84.89\n",
            "Episode 3/1000, Reward: 84.89\n",
            "Episode 4/1000, Reward: 84.89\n",
            "Episode 5/1000, Reward: 84.89\n",
            "Episode 6/1000, Reward: 84.89\n",
            "Episode 7/1000, Reward: 84.89\n",
            "Episode 8/1000, Reward: 84.89\n",
            "Episode 9/1000, Reward: 84.89\n",
            "Episode 10/1000, Reward: 84.89\n",
            "Episode 11/1000, Reward: 84.89\n",
            "Episode 12/1000, Reward: 84.89\n",
            "Episode 13/1000, Reward: 84.89\n",
            "Episode 14/1000, Reward: 84.89\n",
            "Episode 15/1000, Reward: 84.89\n",
            "Episode 16/1000, Reward: 84.89\n",
            "Episode 17/1000, Reward: 84.89\n",
            "Episode 18/1000, Reward: 84.89\n",
            "Episode 19/1000, Reward: 84.89\n",
            "Episode 20/1000, Reward: 84.89\n",
            "Episode 21/1000, Reward: 84.89\n",
            "Episode 22/1000, Reward: 84.89\n",
            "Episode 23/1000, Reward: 84.89\n",
            "Episode 24/1000, Reward: 84.89\n",
            "Episode 25/1000, Reward: 84.89\n",
            "Episode 26/1000, Reward: 84.89\n",
            "Episode 27/1000, Reward: 84.89\n",
            "Episode 28/1000, Reward: 84.89\n",
            "Episode 29/1000, Reward: 84.89\n",
            "Episode 30/1000, Reward: 84.89\n",
            "Episode 31/1000, Reward: 84.89\n",
            "Episode 32/1000, Reward: 84.89\n",
            "Episode 33/1000, Reward: 84.89\n",
            "Episode 34/1000, Reward: 84.89\n",
            "Episode 35/1000, Reward: 84.89\n",
            "Episode 36/1000, Reward: 84.89\n",
            "Episode 37/1000, Reward: 84.89\n",
            "Episode 38/1000, Reward: 84.89\n",
            "Episode 39/1000, Reward: 84.89\n",
            "Episode 40/1000, Reward: 84.89\n",
            "Episode 41/1000, Reward: 84.89\n",
            "Episode 42/1000, Reward: 84.89\n",
            "Episode 43/1000, Reward: 84.89\n",
            "Episode 44/1000, Reward: 84.89\n",
            "Episode 45/1000, Reward: 84.89\n",
            "Episode 46/1000, Reward: 84.89\n",
            "Episode 47/1000, Reward: 84.89\n",
            "Episode 48/1000, Reward: 84.89\n",
            "Episode 49/1000, Reward: 84.89\n",
            "Episode 50/1000, Reward: 84.89\n",
            "Episode 51/1000, Reward: 84.89\n",
            "Episode 52/1000, Reward: 84.89\n",
            "Episode 53/1000, Reward: 84.89\n",
            "Episode 54/1000, Reward: 84.89\n",
            "Episode 55/1000, Reward: 84.89\n",
            "Episode 56/1000, Reward: 84.89\n",
            "Episode 57/1000, Reward: 84.89\n",
            "Episode 58/1000, Reward: 84.89\n",
            "Episode 59/1000, Reward: 84.89\n",
            "Episode 60/1000, Reward: 84.89\n",
            "Episode 61/1000, Reward: 84.89\n",
            "Episode 62/1000, Reward: 84.89\n",
            "Episode 63/1000, Reward: 84.89\n",
            "Episode 64/1000, Reward: 84.89\n",
            "Episode 65/1000, Reward: 84.89\n",
            "Episode 66/1000, Reward: 84.89\n",
            "Episode 67/1000, Reward: 84.89\n",
            "Episode 68/1000, Reward: 84.89\n",
            "Episode 69/1000, Reward: 84.89\n",
            "Episode 70/1000, Reward: 84.89\n",
            "Episode 71/1000, Reward: 84.89\n",
            "Episode 72/1000, Reward: 84.89\n",
            "Episode 73/1000, Reward: 84.89\n",
            "Episode 74/1000, Reward: 84.89\n",
            "Episode 75/1000, Reward: 84.89\n",
            "Episode 76/1000, Reward: 84.89\n",
            "Episode 77/1000, Reward: 84.89\n",
            "Episode 78/1000, Reward: 84.89\n",
            "Episode 79/1000, Reward: 84.89\n",
            "Episode 80/1000, Reward: 84.89\n",
            "Episode 81/1000, Reward: 84.89\n",
            "Episode 82/1000, Reward: 84.89\n",
            "Episode 83/1000, Reward: 84.89\n",
            "Episode 84/1000, Reward: 84.89\n",
            "Episode 85/1000, Reward: 84.89\n",
            "Episode 86/1000, Reward: 84.89\n",
            "Episode 87/1000, Reward: 84.89\n",
            "Episode 88/1000, Reward: 84.89\n",
            "Episode 89/1000, Reward: 84.89\n",
            "Episode 90/1000, Reward: 84.89\n",
            "Episode 91/1000, Reward: 84.89\n",
            "Episode 92/1000, Reward: 84.89\n",
            "Episode 93/1000, Reward: 84.89\n",
            "Episode 94/1000, Reward: 84.89\n",
            "Episode 95/1000, Reward: 84.89\n",
            "Episode 96/1000, Reward: 84.89\n",
            "Episode 97/1000, Reward: 84.89\n",
            "Episode 98/1000, Reward: 84.89\n",
            "Episode 99/1000, Reward: 84.89\n",
            "Episode 100/1000, Reward: 84.89\n",
            "Episode 101/1000, Reward: 84.89\n",
            "Episode 102/1000, Reward: 84.89\n",
            "Episode 103/1000, Reward: 84.89\n",
            "Episode 104/1000, Reward: 84.89\n",
            "Episode 105/1000, Reward: 84.89\n",
            "Episode 106/1000, Reward: 84.89\n",
            "Episode 107/1000, Reward: 84.89\n",
            "Episode 108/1000, Reward: 84.89\n",
            "Episode 109/1000, Reward: 84.89\n",
            "Episode 110/1000, Reward: 84.89\n",
            "Episode 111/1000, Reward: 84.89\n",
            "Episode 112/1000, Reward: 84.89\n",
            "Episode 113/1000, Reward: 84.89\n",
            "Episode 114/1000, Reward: 84.89\n",
            "Episode 115/1000, Reward: 84.89\n",
            "Episode 116/1000, Reward: 84.89\n",
            "Episode 117/1000, Reward: 84.89\n",
            "Episode 118/1000, Reward: 84.89\n",
            "Episode 119/1000, Reward: 84.89\n",
            "Episode 120/1000, Reward: 84.89\n",
            "Episode 121/1000, Reward: 84.89\n",
            "Episode 122/1000, Reward: 84.89\n",
            "Episode 123/1000, Reward: 84.89\n",
            "Episode 124/1000, Reward: 84.89\n",
            "Episode 125/1000, Reward: 84.89\n",
            "Episode 126/1000, Reward: 84.89\n",
            "Episode 127/1000, Reward: 84.89\n",
            "Episode 128/1000, Reward: 84.89\n",
            "Episode 129/1000, Reward: 84.89\n",
            "Episode 130/1000, Reward: 84.89\n",
            "Episode 131/1000, Reward: 84.89\n",
            "Episode 132/1000, Reward: 84.89\n",
            "Episode 133/1000, Reward: 84.89\n",
            "Episode 134/1000, Reward: 84.89\n",
            "Episode 135/1000, Reward: 84.89\n",
            "Episode 136/1000, Reward: 84.89\n",
            "Episode 137/1000, Reward: 84.89\n",
            "Episode 138/1000, Reward: 84.89\n",
            "Episode 139/1000, Reward: 84.89\n",
            "Episode 140/1000, Reward: 84.89\n",
            "Episode 141/1000, Reward: 84.89\n",
            "Episode 142/1000, Reward: 84.89\n",
            "Episode 143/1000, Reward: 84.89\n",
            "Episode 144/1000, Reward: 84.89\n",
            "Episode 145/1000, Reward: 84.89\n",
            "Episode 146/1000, Reward: 84.89\n",
            "Episode 147/1000, Reward: 84.89\n",
            "Episode 148/1000, Reward: 84.89\n",
            "Episode 149/1000, Reward: 84.89\n",
            "Episode 150/1000, Reward: 84.89\n",
            "Episode 151/1000, Reward: 84.89\n",
            "Episode 152/1000, Reward: 84.89\n",
            "Episode 153/1000, Reward: 84.89\n",
            "Episode 154/1000, Reward: 84.89\n",
            "Episode 155/1000, Reward: 84.89\n",
            "Episode 156/1000, Reward: 84.89\n",
            "Episode 157/1000, Reward: 84.89\n",
            "Episode 158/1000, Reward: 84.89\n",
            "Episode 159/1000, Reward: 84.89\n",
            "Episode 160/1000, Reward: 84.89\n",
            "Episode 161/1000, Reward: 84.89\n",
            "Episode 162/1000, Reward: 84.89\n",
            "Episode 163/1000, Reward: 84.89\n",
            "Episode 164/1000, Reward: 84.89\n",
            "Episode 165/1000, Reward: 84.89\n",
            "Episode 166/1000, Reward: 84.89\n",
            "Episode 167/1000, Reward: 84.89\n",
            "Episode 168/1000, Reward: 84.89\n",
            "Episode 169/1000, Reward: 84.89\n",
            "Episode 170/1000, Reward: 84.89\n",
            "Episode 171/1000, Reward: 84.89\n",
            "Episode 172/1000, Reward: 84.89\n",
            "Episode 173/1000, Reward: 84.89\n",
            "Episode 174/1000, Reward: 84.89\n",
            "Episode 175/1000, Reward: 84.89\n",
            "Episode 176/1000, Reward: 84.89\n",
            "Episode 177/1000, Reward: 84.89\n",
            "Episode 178/1000, Reward: 84.89\n",
            "Episode 179/1000, Reward: 84.89\n",
            "Episode 180/1000, Reward: 84.89\n",
            "Episode 181/1000, Reward: 84.89\n",
            "Episode 182/1000, Reward: 84.89\n",
            "Episode 183/1000, Reward: 84.89\n",
            "Episode 184/1000, Reward: 84.89\n",
            "Episode 185/1000, Reward: 84.89\n",
            "Episode 186/1000, Reward: 84.89\n",
            "Episode 187/1000, Reward: 84.89\n",
            "Episode 188/1000, Reward: 84.89\n",
            "Episode 189/1000, Reward: 84.89\n",
            "Episode 190/1000, Reward: 84.89\n",
            "Episode 191/1000, Reward: 84.89\n",
            "Episode 192/1000, Reward: 84.89\n",
            "Episode 193/1000, Reward: 84.89\n",
            "Episode 194/1000, Reward: 84.89\n",
            "Episode 195/1000, Reward: 84.89\n",
            "Episode 196/1000, Reward: 84.89\n",
            "Episode 197/1000, Reward: 84.89\n",
            "Episode 198/1000, Reward: 84.89\n",
            "Episode 199/1000, Reward: 84.89\n",
            "Episode 200/1000, Reward: 84.89\n",
            "Episode 201/1000, Reward: 84.89\n",
            "Episode 202/1000, Reward: 84.89\n",
            "Episode 203/1000, Reward: 84.89\n",
            "Episode 204/1000, Reward: 84.89\n",
            "Episode 205/1000, Reward: 84.89\n",
            "Episode 206/1000, Reward: 84.89\n",
            "Episode 207/1000, Reward: 84.89\n",
            "Episode 208/1000, Reward: 84.89\n",
            "Episode 209/1000, Reward: 84.89\n",
            "Episode 210/1000, Reward: 84.89\n",
            "Episode 211/1000, Reward: 84.89\n",
            "Episode 212/1000, Reward: 84.89\n",
            "Episode 213/1000, Reward: 84.89\n",
            "Episode 214/1000, Reward: 84.89\n",
            "Episode 215/1000, Reward: 84.89\n",
            "Episode 216/1000, Reward: 84.89\n",
            "Episode 217/1000, Reward: 84.89\n",
            "Episode 218/1000, Reward: 84.89\n",
            "Episode 219/1000, Reward: 84.89\n",
            "Episode 220/1000, Reward: 84.89\n",
            "Episode 221/1000, Reward: 84.89\n",
            "Episode 222/1000, Reward: 84.89\n",
            "Episode 223/1000, Reward: 84.89\n",
            "Episode 224/1000, Reward: 84.89\n",
            "Episode 225/1000, Reward: 84.89\n",
            "Episode 226/1000, Reward: 84.89\n",
            "Episode 227/1000, Reward: 84.89\n",
            "Episode 228/1000, Reward: 84.89\n",
            "Episode 229/1000, Reward: 84.89\n",
            "Episode 230/1000, Reward: 84.89\n",
            "Episode 231/1000, Reward: 84.89\n",
            "Episode 232/1000, Reward: 84.89\n",
            "Episode 233/1000, Reward: 84.89\n",
            "Episode 234/1000, Reward: 84.89\n",
            "Episode 235/1000, Reward: 84.89\n",
            "Episode 236/1000, Reward: 84.89\n",
            "Episode 237/1000, Reward: 84.89\n",
            "Episode 238/1000, Reward: 84.89\n",
            "Episode 239/1000, Reward: 84.89\n",
            "Episode 240/1000, Reward: 84.89\n",
            "Episode 241/1000, Reward: 84.89\n",
            "Episode 242/1000, Reward: 84.89\n",
            "Episode 243/1000, Reward: 84.89\n",
            "Episode 244/1000, Reward: 84.89\n",
            "Episode 245/1000, Reward: 84.89\n",
            "Episode 246/1000, Reward: 84.89\n",
            "Episode 247/1000, Reward: 84.89\n",
            "Episode 248/1000, Reward: 84.89\n",
            "Episode 249/1000, Reward: 84.89\n",
            "Episode 250/1000, Reward: 84.89\n",
            "Episode 251/1000, Reward: 84.89\n",
            "Episode 252/1000, Reward: 84.89\n",
            "Episode 253/1000, Reward: 84.89\n",
            "Episode 254/1000, Reward: 84.89\n",
            "Episode 255/1000, Reward: 84.89\n",
            "Episode 256/1000, Reward: 84.89\n",
            "Episode 257/1000, Reward: 84.89\n",
            "Episode 258/1000, Reward: 84.89\n",
            "Episode 259/1000, Reward: 84.89\n",
            "Episode 260/1000, Reward: 84.89\n",
            "Episode 261/1000, Reward: 84.89\n",
            "Episode 262/1000, Reward: 84.89\n",
            "Episode 263/1000, Reward: 84.89\n",
            "Episode 264/1000, Reward: 84.89\n",
            "Episode 265/1000, Reward: 84.89\n",
            "Episode 266/1000, Reward: 84.89\n",
            "Episode 267/1000, Reward: 84.89\n",
            "Episode 268/1000, Reward: 84.89\n",
            "Episode 269/1000, Reward: 84.89\n",
            "Episode 270/1000, Reward: 84.89\n",
            "Episode 271/1000, Reward: 84.89\n",
            "Episode 272/1000, Reward: 84.89\n",
            "Episode 273/1000, Reward: 84.89\n",
            "Episode 274/1000, Reward: 84.89\n",
            "Episode 275/1000, Reward: 84.89\n",
            "Episode 276/1000, Reward: 84.89\n",
            "Episode 277/1000, Reward: 84.89\n",
            "Episode 278/1000, Reward: 84.89\n",
            "Episode 279/1000, Reward: 84.89\n",
            "Episode 280/1000, Reward: 84.89\n",
            "Episode 281/1000, Reward: 84.89\n",
            "Episode 282/1000, Reward: 84.89\n",
            "Episode 283/1000, Reward: 84.89\n",
            "Episode 284/1000, Reward: 84.89\n",
            "Episode 285/1000, Reward: 84.89\n",
            "Episode 286/1000, Reward: 84.89\n",
            "Episode 287/1000, Reward: 84.89\n",
            "Episode 288/1000, Reward: 84.89\n",
            "Episode 289/1000, Reward: 84.89\n",
            "Episode 290/1000, Reward: 84.89\n",
            "Episode 291/1000, Reward: 84.89\n",
            "Episode 292/1000, Reward: 84.89\n",
            "Episode 293/1000, Reward: 84.89\n",
            "Episode 294/1000, Reward: 84.89\n",
            "Episode 295/1000, Reward: 84.89\n",
            "Episode 296/1000, Reward: 84.89\n",
            "Episode 297/1000, Reward: 84.89\n",
            "Episode 298/1000, Reward: 84.89\n",
            "Episode 299/1000, Reward: 84.89\n",
            "Episode 300/1000, Reward: 84.89\n",
            "Episode 301/1000, Reward: 84.89\n",
            "Episode 302/1000, Reward: 84.89\n",
            "Episode 303/1000, Reward: 84.89\n",
            "Episode 304/1000, Reward: 84.89\n",
            "Episode 305/1000, Reward: 84.89\n",
            "Episode 306/1000, Reward: 84.89\n",
            "Episode 307/1000, Reward: 84.89\n",
            "Episode 308/1000, Reward: 84.89\n",
            "Episode 309/1000, Reward: 84.89\n",
            "Episode 310/1000, Reward: 84.89\n",
            "Episode 311/1000, Reward: 84.89\n",
            "Episode 312/1000, Reward: 84.89\n",
            "Episode 313/1000, Reward: 84.89\n",
            "Episode 314/1000, Reward: 84.89\n",
            "Episode 315/1000, Reward: 84.89\n",
            "Episode 316/1000, Reward: 84.89\n",
            "Episode 317/1000, Reward: 84.89\n",
            "Episode 318/1000, Reward: 84.89\n",
            "Episode 319/1000, Reward: 84.89\n",
            "Episode 320/1000, Reward: 84.89\n",
            "Episode 321/1000, Reward: 84.89\n",
            "Episode 322/1000, Reward: 84.89\n",
            "Episode 323/1000, Reward: 84.89\n",
            "Episode 324/1000, Reward: 84.89\n",
            "Episode 325/1000, Reward: 84.89\n",
            "Episode 326/1000, Reward: 84.89\n",
            "Episode 327/1000, Reward: 84.89\n",
            "Episode 328/1000, Reward: 84.89\n",
            "Episode 329/1000, Reward: 84.89\n",
            "Episode 330/1000, Reward: 84.89\n",
            "Episode 331/1000, Reward: 84.89\n",
            "Episode 332/1000, Reward: 84.89\n",
            "Episode 333/1000, Reward: 84.89\n",
            "Episode 334/1000, Reward: 84.89\n",
            "Episode 335/1000, Reward: 84.89\n",
            "Episode 336/1000, Reward: 84.89\n",
            "Episode 337/1000, Reward: 84.89\n",
            "Episode 338/1000, Reward: 84.89\n",
            "Episode 339/1000, Reward: 84.89\n",
            "Episode 340/1000, Reward: 84.89\n",
            "Episode 341/1000, Reward: 84.89\n",
            "Episode 342/1000, Reward: 84.89\n",
            "Episode 343/1000, Reward: 84.89\n",
            "Episode 344/1000, Reward: 84.89\n",
            "Episode 345/1000, Reward: 84.89\n",
            "Episode 346/1000, Reward: 84.89\n",
            "Episode 347/1000, Reward: 84.89\n",
            "Episode 348/1000, Reward: 84.89\n",
            "Episode 349/1000, Reward: 84.89\n",
            "Episode 350/1000, Reward: 84.89\n",
            "Episode 351/1000, Reward: 84.89\n",
            "Episode 352/1000, Reward: 84.89\n",
            "Episode 353/1000, Reward: 84.89\n",
            "Episode 354/1000, Reward: 84.89\n",
            "Episode 355/1000, Reward: 84.89\n",
            "Episode 356/1000, Reward: 84.89\n",
            "Episode 357/1000, Reward: 84.89\n",
            "Episode 358/1000, Reward: 84.89\n",
            "Episode 359/1000, Reward: 84.89\n",
            "Episode 360/1000, Reward: 84.89\n",
            "Episode 361/1000, Reward: 84.89\n",
            "Episode 362/1000, Reward: 84.89\n",
            "Episode 363/1000, Reward: 84.89\n",
            "Episode 364/1000, Reward: 84.89\n",
            "Episode 365/1000, Reward: 84.89\n",
            "Episode 366/1000, Reward: 84.89\n",
            "Episode 367/1000, Reward: 84.89\n",
            "Episode 368/1000, Reward: 84.89\n",
            "Episode 369/1000, Reward: 84.89\n",
            "Episode 370/1000, Reward: 84.89\n",
            "Episode 371/1000, Reward: 84.89\n",
            "Episode 372/1000, Reward: 84.89\n",
            "Episode 373/1000, Reward: 84.89\n",
            "Episode 374/1000, Reward: 84.89\n",
            "Episode 375/1000, Reward: 84.89\n",
            "Episode 376/1000, Reward: 84.89\n",
            "Episode 377/1000, Reward: 84.89\n",
            "Episode 378/1000, Reward: 84.89\n",
            "Episode 379/1000, Reward: 84.89\n",
            "Episode 380/1000, Reward: 84.89\n",
            "Episode 381/1000, Reward: 84.89\n",
            "Episode 382/1000, Reward: 84.89\n",
            "Episode 383/1000, Reward: 84.89\n",
            "Episode 384/1000, Reward: 84.89\n",
            "Episode 385/1000, Reward: 84.89\n",
            "Episode 386/1000, Reward: 84.89\n",
            "Episode 387/1000, Reward: 84.89\n",
            "Episode 388/1000, Reward: 84.89\n",
            "Episode 389/1000, Reward: 84.89\n",
            "Episode 390/1000, Reward: 84.89\n",
            "Episode 391/1000, Reward: 84.89\n",
            "Episode 392/1000, Reward: 84.89\n",
            "Episode 393/1000, Reward: 84.89\n",
            "Episode 394/1000, Reward: 84.89\n",
            "Episode 395/1000, Reward: 84.89\n",
            "Episode 396/1000, Reward: 84.89\n",
            "Episode 397/1000, Reward: 84.89\n",
            "Episode 398/1000, Reward: 84.89\n",
            "Episode 399/1000, Reward: 84.89\n",
            "Episode 400/1000, Reward: 84.89\n",
            "Episode 401/1000, Reward: 84.89\n",
            "Episode 402/1000, Reward: 84.89\n",
            "Episode 403/1000, Reward: 84.89\n",
            "Episode 404/1000, Reward: 84.89\n",
            "Episode 405/1000, Reward: 84.89\n",
            "Episode 406/1000, Reward: 84.89\n",
            "Episode 407/1000, Reward: 84.89\n",
            "Episode 408/1000, Reward: 84.89\n",
            "Episode 409/1000, Reward: 84.89\n",
            "Episode 410/1000, Reward: 84.89\n",
            "Episode 411/1000, Reward: 84.89\n",
            "Episode 412/1000, Reward: 84.89\n",
            "Episode 413/1000, Reward: 84.89\n",
            "Episode 414/1000, Reward: 84.89\n",
            "Episode 415/1000, Reward: 84.89\n",
            "Episode 416/1000, Reward: 84.89\n",
            "Episode 417/1000, Reward: 84.89\n",
            "Episode 418/1000, Reward: 84.89\n",
            "Episode 419/1000, Reward: 84.89\n",
            "Episode 420/1000, Reward: 84.89\n",
            "Episode 421/1000, Reward: 84.89\n",
            "Episode 422/1000, Reward: 84.89\n",
            "Episode 423/1000, Reward: 84.89\n",
            "Episode 424/1000, Reward: 84.89\n",
            "Episode 425/1000, Reward: 84.89\n",
            "Episode 426/1000, Reward: 84.89\n",
            "Episode 427/1000, Reward: 84.89\n",
            "Episode 428/1000, Reward: 84.89\n",
            "Episode 429/1000, Reward: 84.89\n",
            "Episode 430/1000, Reward: 84.89\n",
            "Episode 431/1000, Reward: 84.89\n",
            "Episode 432/1000, Reward: 84.89\n",
            "Episode 433/1000, Reward: 84.89\n",
            "Episode 434/1000, Reward: 84.89\n",
            "Episode 435/1000, Reward: 84.89\n",
            "Episode 436/1000, Reward: 84.89\n",
            "Episode 437/1000, Reward: 84.89\n",
            "Episode 438/1000, Reward: 84.89\n",
            "Episode 439/1000, Reward: 84.89\n",
            "Episode 440/1000, Reward: 84.89\n",
            "Episode 441/1000, Reward: 84.89\n",
            "Episode 442/1000, Reward: 84.89\n",
            "Episode 443/1000, Reward: 84.89\n",
            "Episode 444/1000, Reward: 84.89\n",
            "Episode 445/1000, Reward: 84.89\n",
            "Episode 446/1000, Reward: 84.89\n",
            "Episode 447/1000, Reward: 84.89\n",
            "Episode 448/1000, Reward: 84.89\n",
            "Episode 449/1000, Reward: 84.89\n",
            "Episode 450/1000, Reward: 84.89\n",
            "Episode 451/1000, Reward: 84.89\n",
            "Episode 452/1000, Reward: 84.89\n",
            "Episode 453/1000, Reward: 84.89\n",
            "Episode 454/1000, Reward: 84.89\n",
            "Episode 455/1000, Reward: 84.89\n",
            "Episode 456/1000, Reward: 84.89\n",
            "Episode 457/1000, Reward: 84.89\n",
            "Episode 458/1000, Reward: 84.89\n",
            "Episode 459/1000, Reward: 84.89\n",
            "Episode 460/1000, Reward: 84.89\n",
            "Episode 461/1000, Reward: 84.89\n",
            "Episode 462/1000, Reward: 84.89\n",
            "Episode 463/1000, Reward: 84.89\n",
            "Episode 464/1000, Reward: 84.89\n",
            "Episode 465/1000, Reward: 84.89\n",
            "Episode 466/1000, Reward: 84.89\n",
            "Episode 467/1000, Reward: 84.89\n",
            "Episode 468/1000, Reward: 84.89\n",
            "Episode 469/1000, Reward: 84.89\n",
            "Episode 470/1000, Reward: 84.89\n",
            "Episode 471/1000, Reward: 84.89\n",
            "Episode 472/1000, Reward: 84.89\n",
            "Episode 473/1000, Reward: 84.89\n",
            "Episode 474/1000, Reward: 84.89\n",
            "Episode 475/1000, Reward: 84.89\n",
            "Episode 476/1000, Reward: 84.89\n",
            "Episode 477/1000, Reward: 84.89\n",
            "Episode 478/1000, Reward: 84.89\n",
            "Episode 479/1000, Reward: 84.89\n",
            "Episode 480/1000, Reward: 84.89\n",
            "Episode 481/1000, Reward: 84.89\n",
            "Episode 482/1000, Reward: 84.89\n",
            "Episode 483/1000, Reward: 84.89\n",
            "Episode 484/1000, Reward: 84.89\n",
            "Episode 485/1000, Reward: 84.89\n",
            "Episode 486/1000, Reward: 84.89\n",
            "Episode 487/1000, Reward: 84.89\n",
            "Episode 488/1000, Reward: 84.89\n",
            "Episode 489/1000, Reward: 84.89\n",
            "Episode 490/1000, Reward: 84.89\n",
            "Episode 491/1000, Reward: 84.89\n",
            "Episode 492/1000, Reward: 84.89\n",
            "Episode 493/1000, Reward: 84.89\n",
            "Episode 494/1000, Reward: 84.89\n",
            "Episode 495/1000, Reward: 84.89\n",
            "Episode 496/1000, Reward: 84.89\n",
            "Episode 497/1000, Reward: 84.89\n",
            "Episode 498/1000, Reward: 84.89\n",
            "Episode 499/1000, Reward: 84.89\n",
            "Episode 500/1000, Reward: 84.89\n",
            "Episode 501/1000, Reward: 84.89\n",
            "Episode 502/1000, Reward: 84.89\n",
            "Episode 503/1000, Reward: 84.89\n",
            "Episode 504/1000, Reward: 84.89\n",
            "Episode 505/1000, Reward: 84.89\n",
            "Episode 506/1000, Reward: 84.89\n",
            "Episode 507/1000, Reward: 84.89\n",
            "Episode 508/1000, Reward: 84.89\n",
            "Episode 509/1000, Reward: 84.89\n",
            "Episode 510/1000, Reward: 84.89\n",
            "Episode 511/1000, Reward: 84.89\n",
            "Episode 512/1000, Reward: 84.89\n",
            "Episode 513/1000, Reward: 84.89\n",
            "Episode 514/1000, Reward: 84.89\n",
            "Episode 515/1000, Reward: 84.89\n",
            "Episode 516/1000, Reward: 84.89\n",
            "Episode 517/1000, Reward: 84.89\n",
            "Episode 518/1000, Reward: 84.89\n",
            "Episode 519/1000, Reward: 84.89\n",
            "Episode 520/1000, Reward: 84.89\n",
            "Episode 521/1000, Reward: 84.89\n",
            "Episode 522/1000, Reward: 84.89\n",
            "Episode 523/1000, Reward: 84.89\n",
            "Episode 524/1000, Reward: 84.89\n",
            "Episode 525/1000, Reward: 84.89\n",
            "Episode 526/1000, Reward: 84.89\n",
            "Episode 527/1000, Reward: 84.89\n",
            "Episode 528/1000, Reward: 84.89\n",
            "Episode 529/1000, Reward: 84.89\n",
            "Episode 530/1000, Reward: 84.89\n",
            "Episode 531/1000, Reward: 84.89\n",
            "Episode 532/1000, Reward: 84.89\n",
            "Episode 533/1000, Reward: 84.89\n",
            "Episode 534/1000, Reward: 84.89\n",
            "Episode 535/1000, Reward: 84.89\n",
            "Episode 536/1000, Reward: 84.89\n",
            "Episode 537/1000, Reward: 84.89\n",
            "Episode 538/1000, Reward: 84.89\n",
            "Episode 539/1000, Reward: 84.89\n",
            "Episode 540/1000, Reward: 84.89\n",
            "Episode 541/1000, Reward: 84.89\n",
            "Episode 542/1000, Reward: 84.89\n",
            "Episode 543/1000, Reward: 84.89\n",
            "Episode 544/1000, Reward: 84.89\n",
            "Episode 545/1000, Reward: 84.89\n",
            "Episode 546/1000, Reward: 84.89\n",
            "Episode 547/1000, Reward: 84.89\n",
            "Episode 548/1000, Reward: 84.89\n",
            "Episode 549/1000, Reward: 84.89\n",
            "Episode 550/1000, Reward: 84.89\n",
            "Episode 551/1000, Reward: 84.89\n",
            "Episode 552/1000, Reward: 84.89\n",
            "Episode 553/1000, Reward: 84.89\n",
            "Episode 554/1000, Reward: 84.89\n",
            "Episode 555/1000, Reward: 84.89\n",
            "Episode 556/1000, Reward: 84.89\n",
            "Episode 557/1000, Reward: 84.89\n",
            "Episode 558/1000, Reward: 84.89\n",
            "Episode 559/1000, Reward: 84.89\n",
            "Episode 560/1000, Reward: 84.89\n",
            "Episode 561/1000, Reward: 84.89\n",
            "Episode 562/1000, Reward: 84.89\n",
            "Episode 563/1000, Reward: 84.89\n",
            "Episode 564/1000, Reward: 84.89\n",
            "Episode 565/1000, Reward: 84.89\n",
            "Episode 566/1000, Reward: 84.89\n",
            "Episode 567/1000, Reward: 84.89\n",
            "Episode 568/1000, Reward: 84.89\n",
            "Episode 569/1000, Reward: 84.89\n",
            "Episode 570/1000, Reward: 84.89\n",
            "Episode 571/1000, Reward: 84.89\n",
            "Episode 572/1000, Reward: 84.89\n",
            "Episode 573/1000, Reward: 84.89\n",
            "Episode 574/1000, Reward: 84.89\n",
            "Episode 575/1000, Reward: 84.89\n",
            "Episode 576/1000, Reward: 84.89\n",
            "Episode 577/1000, Reward: 84.89\n",
            "Episode 578/1000, Reward: 84.89\n",
            "Episode 579/1000, Reward: 84.89\n",
            "Episode 580/1000, Reward: 84.89\n",
            "Episode 581/1000, Reward: 84.89\n",
            "Episode 582/1000, Reward: 84.89\n",
            "Episode 583/1000, Reward: 84.89\n",
            "Episode 584/1000, Reward: 84.89\n",
            "Episode 585/1000, Reward: 84.89\n",
            "Episode 586/1000, Reward: 84.89\n",
            "Episode 587/1000, Reward: 84.89\n",
            "Episode 588/1000, Reward: 84.89\n",
            "Episode 589/1000, Reward: 84.89\n",
            "Episode 590/1000, Reward: 84.89\n",
            "Episode 591/1000, Reward: 84.89\n",
            "Episode 592/1000, Reward: 84.89\n",
            "Episode 593/1000, Reward: 84.89\n",
            "Episode 594/1000, Reward: 84.89\n",
            "Episode 595/1000, Reward: 84.89\n",
            "Episode 596/1000, Reward: 84.89\n",
            "Episode 597/1000, Reward: 84.89\n",
            "Episode 598/1000, Reward: 84.89\n",
            "Episode 599/1000, Reward: 84.89\n",
            "Episode 600/1000, Reward: 84.89\n",
            "Episode 601/1000, Reward: 84.89\n",
            "Episode 602/1000, Reward: 84.89\n",
            "Episode 603/1000, Reward: 84.89\n",
            "Episode 604/1000, Reward: 84.89\n",
            "Episode 605/1000, Reward: 84.89\n",
            "Episode 606/1000, Reward: 84.89\n",
            "Episode 607/1000, Reward: 84.89\n",
            "Episode 608/1000, Reward: 84.89\n",
            "Episode 609/1000, Reward: 84.89\n",
            "Episode 610/1000, Reward: 84.89\n",
            "Episode 611/1000, Reward: 84.89\n",
            "Episode 612/1000, Reward: 84.89\n",
            "Episode 613/1000, Reward: 84.89\n",
            "Episode 614/1000, Reward: 84.89\n",
            "Episode 615/1000, Reward: 84.89\n",
            "Episode 616/1000, Reward: 84.89\n",
            "Episode 617/1000, Reward: 84.89\n",
            "Episode 618/1000, Reward: 84.89\n",
            "Episode 619/1000, Reward: 84.89\n",
            "Episode 620/1000, Reward: 84.89\n",
            "Episode 621/1000, Reward: 84.89\n",
            "Episode 622/1000, Reward: 84.89\n",
            "Episode 623/1000, Reward: 84.89\n",
            "Episode 624/1000, Reward: 84.89\n",
            "Episode 625/1000, Reward: 84.89\n",
            "Episode 626/1000, Reward: 84.89\n",
            "Episode 627/1000, Reward: 84.89\n",
            "Episode 628/1000, Reward: 84.89\n",
            "Episode 629/1000, Reward: 84.89\n",
            "Episode 630/1000, Reward: 84.89\n",
            "Episode 631/1000, Reward: 84.89\n",
            "Episode 632/1000, Reward: 84.89\n",
            "Episode 633/1000, Reward: 84.89\n",
            "Episode 634/1000, Reward: 84.89\n",
            "Episode 635/1000, Reward: 84.89\n",
            "Episode 636/1000, Reward: 84.89\n",
            "Episode 637/1000, Reward: 84.89\n",
            "Episode 638/1000, Reward: 84.89\n",
            "Episode 639/1000, Reward: 84.89\n",
            "Episode 640/1000, Reward: 84.89\n",
            "Episode 641/1000, Reward: 84.89\n",
            "Episode 642/1000, Reward: 84.89\n",
            "Episode 643/1000, Reward: 84.89\n",
            "Episode 644/1000, Reward: 84.89\n",
            "Episode 645/1000, Reward: 84.89\n",
            "Episode 646/1000, Reward: 84.89\n",
            "Episode 647/1000, Reward: 84.89\n",
            "Episode 648/1000, Reward: 84.89\n",
            "Episode 649/1000, Reward: 84.89\n",
            "Episode 650/1000, Reward: 84.89\n",
            "Episode 651/1000, Reward: 84.89\n",
            "Episode 652/1000, Reward: 84.89\n",
            "Episode 653/1000, Reward: 84.89\n",
            "Episode 654/1000, Reward: 84.89\n",
            "Episode 655/1000, Reward: 84.89\n",
            "Episode 656/1000, Reward: 84.89\n",
            "Episode 657/1000, Reward: 84.89\n",
            "Episode 658/1000, Reward: 84.89\n",
            "Episode 659/1000, Reward: 84.89\n",
            "Episode 660/1000, Reward: 84.89\n",
            "Episode 661/1000, Reward: 84.89\n",
            "Episode 662/1000, Reward: 84.89\n",
            "Episode 663/1000, Reward: 84.89\n",
            "Episode 664/1000, Reward: 84.89\n",
            "Episode 665/1000, Reward: 84.89\n",
            "Episode 666/1000, Reward: 84.89\n",
            "Episode 667/1000, Reward: 84.89\n",
            "Episode 668/1000, Reward: 84.89\n",
            "Episode 669/1000, Reward: 84.89\n",
            "Episode 670/1000, Reward: 84.89\n",
            "Episode 671/1000, Reward: 84.89\n",
            "Episode 672/1000, Reward: 84.89\n",
            "Episode 673/1000, Reward: 84.89\n",
            "Episode 674/1000, Reward: 84.89\n",
            "Episode 675/1000, Reward: 84.89\n",
            "Episode 676/1000, Reward: 84.89\n",
            "Episode 677/1000, Reward: 84.89\n",
            "Episode 678/1000, Reward: 84.89\n",
            "Episode 679/1000, Reward: 84.89\n",
            "Episode 680/1000, Reward: 84.89\n",
            "Episode 681/1000, Reward: 84.89\n",
            "Episode 682/1000, Reward: 84.89\n",
            "Episode 683/1000, Reward: 84.89\n",
            "Episode 684/1000, Reward: 84.89\n",
            "Episode 685/1000, Reward: 84.89\n",
            "Episode 686/1000, Reward: 84.89\n",
            "Episode 687/1000, Reward: 84.89\n",
            "Episode 688/1000, Reward: 84.89\n",
            "Episode 689/1000, Reward: 84.89\n",
            "Episode 690/1000, Reward: 84.89\n",
            "Episode 691/1000, Reward: 84.89\n",
            "Episode 692/1000, Reward: 84.89\n",
            "Episode 693/1000, Reward: 84.89\n",
            "Episode 694/1000, Reward: 84.89\n",
            "Episode 695/1000, Reward: 84.89\n",
            "Episode 696/1000, Reward: 84.89\n",
            "Episode 697/1000, Reward: 84.89\n",
            "Episode 698/1000, Reward: 84.89\n",
            "Episode 699/1000, Reward: 84.89\n",
            "Episode 700/1000, Reward: 84.89\n",
            "Episode 701/1000, Reward: 84.89\n",
            "Episode 702/1000, Reward: 84.89\n",
            "Episode 703/1000, Reward: 84.89\n",
            "Episode 704/1000, Reward: 84.89\n",
            "Episode 705/1000, Reward: 84.89\n",
            "Episode 706/1000, Reward: 84.89\n",
            "Episode 707/1000, Reward: 84.89\n",
            "Episode 708/1000, Reward: 84.89\n",
            "Episode 709/1000, Reward: 84.89\n",
            "Episode 710/1000, Reward: 84.89\n",
            "Episode 711/1000, Reward: 84.89\n",
            "Episode 712/1000, Reward: 84.89\n",
            "Episode 713/1000, Reward: 84.89\n",
            "Episode 714/1000, Reward: 84.89\n",
            "Episode 715/1000, Reward: 84.89\n",
            "Episode 716/1000, Reward: 84.89\n",
            "Episode 717/1000, Reward: 84.89\n",
            "Episode 718/1000, Reward: 84.89\n",
            "Episode 719/1000, Reward: 84.89\n",
            "Episode 720/1000, Reward: 84.89\n",
            "Episode 721/1000, Reward: 84.89\n",
            "Episode 722/1000, Reward: 84.89\n",
            "Episode 723/1000, Reward: 84.89\n",
            "Episode 724/1000, Reward: 84.89\n",
            "Episode 725/1000, Reward: 84.89\n",
            "Episode 726/1000, Reward: 84.89\n",
            "Episode 727/1000, Reward: 84.89\n",
            "Episode 728/1000, Reward: 84.89\n",
            "Episode 729/1000, Reward: 84.89\n",
            "Episode 730/1000, Reward: 84.89\n",
            "Episode 731/1000, Reward: 84.89\n",
            "Episode 732/1000, Reward: 84.89\n",
            "Episode 733/1000, Reward: 84.89\n",
            "Episode 734/1000, Reward: 84.89\n",
            "Episode 735/1000, Reward: 84.89\n",
            "Episode 736/1000, Reward: 84.89\n",
            "Episode 737/1000, Reward: 84.89\n",
            "Episode 738/1000, Reward: 84.89\n",
            "Episode 739/1000, Reward: 84.89\n",
            "Episode 740/1000, Reward: 84.89\n",
            "Episode 741/1000, Reward: 84.89\n",
            "Episode 742/1000, Reward: 84.89\n",
            "Episode 743/1000, Reward: 84.89\n",
            "Episode 744/1000, Reward: 84.89\n",
            "Episode 745/1000, Reward: 84.89\n",
            "Episode 746/1000, Reward: 84.89\n",
            "Episode 747/1000, Reward: 84.89\n",
            "Episode 748/1000, Reward: 84.89\n",
            "Episode 749/1000, Reward: 84.89\n",
            "Episode 750/1000, Reward: 84.89\n",
            "Episode 751/1000, Reward: 84.89\n",
            "Episode 752/1000, Reward: 84.89\n",
            "Episode 753/1000, Reward: 84.89\n",
            "Episode 754/1000, Reward: 84.89\n",
            "Episode 755/1000, Reward: 84.89\n",
            "Episode 756/1000, Reward: 84.89\n",
            "Episode 757/1000, Reward: 84.89\n",
            "Episode 758/1000, Reward: 84.89\n",
            "Episode 759/1000, Reward: 84.89\n",
            "Episode 760/1000, Reward: 84.89\n",
            "Episode 761/1000, Reward: 84.89\n",
            "Episode 762/1000, Reward: 84.89\n",
            "Episode 763/1000, Reward: 84.89\n",
            "Episode 764/1000, Reward: 84.89\n",
            "Episode 765/1000, Reward: 84.89\n",
            "Episode 766/1000, Reward: 84.89\n",
            "Episode 767/1000, Reward: 84.89\n",
            "Episode 768/1000, Reward: 84.89\n",
            "Episode 769/1000, Reward: 84.89\n",
            "Episode 770/1000, Reward: 84.89\n",
            "Episode 771/1000, Reward: 84.89\n",
            "Episode 772/1000, Reward: 84.89\n",
            "Episode 773/1000, Reward: 84.89\n",
            "Episode 774/1000, Reward: 84.89\n",
            "Episode 775/1000, Reward: 84.89\n",
            "Episode 776/1000, Reward: 84.89\n",
            "Episode 777/1000, Reward: 84.89\n",
            "Episode 778/1000, Reward: 84.89\n",
            "Episode 779/1000, Reward: 84.89\n",
            "Episode 780/1000, Reward: 84.89\n",
            "Episode 781/1000, Reward: 84.89\n",
            "Episode 782/1000, Reward: 84.89\n",
            "Episode 783/1000, Reward: 84.89\n",
            "Episode 784/1000, Reward: 84.89\n",
            "Episode 785/1000, Reward: 84.89\n",
            "Episode 786/1000, Reward: 84.89\n",
            "Episode 787/1000, Reward: 84.89\n",
            "Episode 788/1000, Reward: 84.89\n",
            "Episode 789/1000, Reward: 84.89\n",
            "Episode 790/1000, Reward: 84.89\n",
            "Episode 791/1000, Reward: 84.89\n",
            "Episode 792/1000, Reward: 84.89\n",
            "Episode 793/1000, Reward: 84.89\n",
            "Episode 794/1000, Reward: 84.89\n",
            "Episode 795/1000, Reward: 84.89\n",
            "Episode 796/1000, Reward: 84.89\n",
            "Episode 797/1000, Reward: 84.89\n",
            "Episode 798/1000, Reward: 84.89\n",
            "Episode 799/1000, Reward: 84.89\n",
            "Episode 800/1000, Reward: 84.89\n",
            "Episode 801/1000, Reward: 84.89\n",
            "Episode 802/1000, Reward: 84.89\n",
            "Episode 803/1000, Reward: 84.89\n",
            "Episode 804/1000, Reward: 84.89\n",
            "Episode 805/1000, Reward: 84.89\n",
            "Episode 806/1000, Reward: 84.89\n",
            "Episode 807/1000, Reward: 84.89\n",
            "Episode 808/1000, Reward: 84.89\n",
            "Episode 809/1000, Reward: 84.89\n",
            "Episode 810/1000, Reward: 84.89\n",
            "Episode 811/1000, Reward: 84.89\n",
            "Episode 812/1000, Reward: 84.89\n",
            "Episode 813/1000, Reward: 84.89\n",
            "Episode 814/1000, Reward: 84.89\n",
            "Episode 815/1000, Reward: 84.89\n",
            "Episode 816/1000, Reward: 84.89\n",
            "Episode 817/1000, Reward: 84.89\n",
            "Episode 818/1000, Reward: 84.89\n",
            "Episode 819/1000, Reward: 84.89\n",
            "Episode 820/1000, Reward: 84.89\n",
            "Episode 821/1000, Reward: 84.89\n",
            "Episode 822/1000, Reward: 84.89\n",
            "Episode 823/1000, Reward: 84.89\n",
            "Episode 824/1000, Reward: 84.89\n",
            "Episode 825/1000, Reward: 84.89\n",
            "Episode 826/1000, Reward: 84.89\n",
            "Episode 827/1000, Reward: 84.89\n",
            "Episode 828/1000, Reward: 84.89\n",
            "Episode 829/1000, Reward: 84.89\n",
            "Episode 830/1000, Reward: 84.89\n",
            "Episode 831/1000, Reward: 84.89\n",
            "Episode 832/1000, Reward: 84.89\n",
            "Episode 833/1000, Reward: 84.89\n",
            "Episode 834/1000, Reward: 84.89\n",
            "Episode 835/1000, Reward: 84.89\n",
            "Episode 836/1000, Reward: 84.89\n",
            "Episode 837/1000, Reward: 84.89\n",
            "Episode 838/1000, Reward: 84.89\n",
            "Episode 839/1000, Reward: 84.89\n",
            "Episode 840/1000, Reward: 84.89\n",
            "Episode 841/1000, Reward: 84.89\n",
            "Episode 842/1000, Reward: 84.89\n",
            "Episode 843/1000, Reward: 84.89\n",
            "Episode 844/1000, Reward: 84.89\n",
            "Episode 845/1000, Reward: 84.89\n",
            "Episode 846/1000, Reward: 84.89\n",
            "Episode 847/1000, Reward: 84.89\n",
            "Episode 848/1000, Reward: 84.89\n",
            "Episode 849/1000, Reward: 84.89\n",
            "Episode 850/1000, Reward: 84.89\n",
            "Episode 851/1000, Reward: 84.89\n",
            "Episode 852/1000, Reward: 84.89\n",
            "Episode 853/1000, Reward: 84.89\n",
            "Episode 854/1000, Reward: 84.89\n",
            "Episode 855/1000, Reward: 84.89\n",
            "Episode 856/1000, Reward: 84.89\n",
            "Episode 857/1000, Reward: 84.89\n",
            "Episode 858/1000, Reward: 84.89\n",
            "Episode 859/1000, Reward: 84.89\n",
            "Episode 860/1000, Reward: 84.89\n",
            "Episode 861/1000, Reward: 84.89\n",
            "Episode 862/1000, Reward: 84.89\n",
            "Episode 863/1000, Reward: 84.89\n",
            "Episode 864/1000, Reward: 84.89\n",
            "Episode 865/1000, Reward: 84.89\n",
            "Episode 866/1000, Reward: 84.89\n",
            "Episode 867/1000, Reward: 84.89\n",
            "Episode 868/1000, Reward: 84.89\n",
            "Episode 869/1000, Reward: 84.89\n",
            "Episode 870/1000, Reward: 84.89\n",
            "Episode 871/1000, Reward: 84.89\n",
            "Episode 872/1000, Reward: 84.89\n",
            "Episode 873/1000, Reward: 84.89\n",
            "Episode 874/1000, Reward: 84.89\n",
            "Episode 875/1000, Reward: 84.89\n",
            "Episode 876/1000, Reward: 84.89\n",
            "Episode 877/1000, Reward: 84.89\n",
            "Episode 878/1000, Reward: 84.89\n",
            "Episode 879/1000, Reward: 84.89\n",
            "Episode 880/1000, Reward: 84.89\n",
            "Episode 881/1000, Reward: 84.89\n",
            "Episode 882/1000, Reward: 84.89\n",
            "Episode 883/1000, Reward: 84.89\n",
            "Episode 884/1000, Reward: 84.89\n",
            "Episode 885/1000, Reward: 84.89\n",
            "Episode 886/1000, Reward: 84.89\n",
            "Episode 887/1000, Reward: 84.89\n",
            "Episode 888/1000, Reward: 84.89\n",
            "Episode 889/1000, Reward: 84.89\n",
            "Episode 890/1000, Reward: 84.89\n",
            "Episode 891/1000, Reward: 84.89\n",
            "Episode 892/1000, Reward: 84.89\n",
            "Episode 893/1000, Reward: 84.89\n",
            "Episode 894/1000, Reward: 84.89\n",
            "Episode 895/1000, Reward: 84.89\n",
            "Episode 896/1000, Reward: 84.89\n",
            "Episode 897/1000, Reward: 84.89\n",
            "Episode 898/1000, Reward: 84.89\n",
            "Episode 899/1000, Reward: 84.89\n",
            "Episode 900/1000, Reward: 84.89\n",
            "Episode 901/1000, Reward: 84.89\n",
            "Episode 902/1000, Reward: 84.89\n",
            "Episode 903/1000, Reward: 84.89\n",
            "Episode 904/1000, Reward: 84.89\n",
            "Episode 905/1000, Reward: 84.89\n",
            "Episode 906/1000, Reward: 84.89\n",
            "Episode 907/1000, Reward: 84.89\n",
            "Episode 908/1000, Reward: 84.89\n",
            "Episode 909/1000, Reward: 84.89\n",
            "Episode 910/1000, Reward: 84.89\n",
            "Episode 911/1000, Reward: 84.89\n",
            "Episode 912/1000, Reward: 84.89\n",
            "Episode 913/1000, Reward: 84.89\n",
            "Episode 914/1000, Reward: 84.89\n",
            "Episode 915/1000, Reward: 84.89\n",
            "Episode 916/1000, Reward: 84.89\n",
            "Episode 917/1000, Reward: 84.89\n",
            "Episode 918/1000, Reward: 84.89\n",
            "Episode 919/1000, Reward: 84.89\n",
            "Episode 920/1000, Reward: 84.89\n",
            "Episode 921/1000, Reward: 84.89\n",
            "Episode 922/1000, Reward: 84.89\n",
            "Episode 923/1000, Reward: 84.89\n",
            "Episode 924/1000, Reward: 84.89\n",
            "Episode 925/1000, Reward: 84.89\n",
            "Episode 926/1000, Reward: 84.89\n",
            "Episode 927/1000, Reward: 84.89\n",
            "Episode 928/1000, Reward: 84.89\n",
            "Episode 929/1000, Reward: 84.89\n",
            "Episode 930/1000, Reward: 84.89\n",
            "Episode 931/1000, Reward: 84.89\n",
            "Episode 932/1000, Reward: 84.89\n",
            "Episode 933/1000, Reward: 84.89\n",
            "Episode 934/1000, Reward: 84.89\n",
            "Episode 935/1000, Reward: 84.89\n",
            "Episode 936/1000, Reward: 84.89\n",
            "Episode 937/1000, Reward: 84.89\n",
            "Episode 938/1000, Reward: 84.89\n",
            "Episode 939/1000, Reward: 84.89\n",
            "Episode 940/1000, Reward: 84.89\n",
            "Episode 941/1000, Reward: 84.89\n",
            "Episode 942/1000, Reward: 84.89\n",
            "Episode 943/1000, Reward: 84.89\n",
            "Episode 944/1000, Reward: 84.89\n",
            "Episode 945/1000, Reward: 84.89\n",
            "Episode 946/1000, Reward: 84.89\n",
            "Episode 947/1000, Reward: 84.89\n",
            "Episode 948/1000, Reward: 84.89\n",
            "Episode 949/1000, Reward: 84.89\n",
            "Episode 950/1000, Reward: 84.89\n",
            "Episode 951/1000, Reward: 84.89\n",
            "Episode 952/1000, Reward: 84.89\n",
            "Episode 953/1000, Reward: 84.89\n",
            "Episode 954/1000, Reward: 84.89\n",
            "Episode 955/1000, Reward: 84.89\n",
            "Episode 956/1000, Reward: 84.89\n",
            "Episode 957/1000, Reward: 84.89\n",
            "Episode 958/1000, Reward: 84.89\n",
            "Episode 959/1000, Reward: 84.89\n",
            "Episode 960/1000, Reward: 84.89\n",
            "Episode 961/1000, Reward: 84.89\n",
            "Episode 962/1000, Reward: 84.89\n",
            "Episode 963/1000, Reward: 84.89\n",
            "Episode 964/1000, Reward: 84.89\n",
            "Episode 965/1000, Reward: 84.89\n",
            "Episode 966/1000, Reward: 84.89\n",
            "Episode 967/1000, Reward: 84.89\n",
            "Episode 968/1000, Reward: 84.89\n",
            "Episode 969/1000, Reward: 84.89\n",
            "Episode 970/1000, Reward: 84.89\n",
            "Episode 971/1000, Reward: 84.89\n",
            "Episode 972/1000, Reward: 84.89\n",
            "Episode 973/1000, Reward: 84.89\n",
            "Episode 974/1000, Reward: 84.89\n",
            "Episode 975/1000, Reward: 84.89\n",
            "Episode 976/1000, Reward: 84.89\n",
            "Episode 977/1000, Reward: 84.89\n",
            "Episode 978/1000, Reward: 84.89\n",
            "Episode 979/1000, Reward: 84.89\n",
            "Episode 980/1000, Reward: 84.89\n",
            "Episode 981/1000, Reward: 84.89\n",
            "Episode 982/1000, Reward: 84.89\n",
            "Episode 983/1000, Reward: 84.89\n",
            "Episode 984/1000, Reward: 84.89\n",
            "Episode 985/1000, Reward: 84.89\n",
            "Episode 986/1000, Reward: 84.89\n",
            "Episode 987/1000, Reward: 84.89\n",
            "Episode 988/1000, Reward: 84.89\n",
            "Episode 989/1000, Reward: 84.89\n",
            "Episode 990/1000, Reward: 84.89\n",
            "Episode 991/1000, Reward: 84.89\n",
            "Episode 992/1000, Reward: 84.89\n",
            "Episode 993/1000, Reward: 84.89\n",
            "Episode 994/1000, Reward: 84.89\n",
            "Episode 995/1000, Reward: 84.89\n",
            "Episode 996/1000, Reward: 84.89\n",
            "Episode 997/1000, Reward: 84.89\n",
            "Episode 998/1000, Reward: 84.89\n",
            "Episode 999/1000, Reward: 84.89\n",
            "Episode 1000/1000, Reward: 84.89\n",
            "\n",
            "Average Test Reward: 84.89\n",
            "\n",
            "Action Distribution:\n",
            "SELL: 844000\n",
            "HOLD: 18000\n",
            "BUY: 138000\n",
            "Warning: Too much selling compared to buying! Adjust reward incentives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Stock Data\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\"Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"TSLA\")\n",
        "if df_live is None:\n",
        "    print(\"Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/teslafeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)\n",
        "\n",
        "# Prepare Dataset\n",
        "df = df_live.copy()"
      ],
      "metadata": {
        "id": "YYa-9B0AtAWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab564885-32a2-405a-9fe2-e5a23cc31a9e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: Downloading TSLA stock data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded stock data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Multi-Index Issues\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "# Feature Engineering\n",
        "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']\n",
        "df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Create Trade Labels\n",
        "df['Future_Close'] = df['Close'].shift(-10)\n",
        "df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "N3XFsQaVtEcs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContinuousTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10):\n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "\n",
        "        self.action_space = Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(13,), dtype=np.float32)\n",
        "\n",
        "        self.initial_balance = 10_000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = self.df['Close'].iloc[max(0, self.current_step - self.window_size):self.current_step].values\n",
        "        if len(stock_prices) < self.window_size:\n",
        "            stock_prices = np.pad(stock_prices, (self.window_size - len(stock_prices), 0), mode='edge')\n",
        "\n",
        "        ema_10 = self.df['EMA_10'].iloc[self.current_step] if 'EMA_10' in self.df.columns else 0\n",
        "        ema_50 = self.df['EMA_50'].iloc[self.current_step] if 'EMA_50' in self.df.columns else 0\n",
        "\n",
        "        obs = np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held, ema_10, ema_50]), dtype=np.float32)\n",
        "        obs = obs[:13] if len(obs) > 13 else np.pad(obs, (0, 13 - len(obs)), mode='edge')\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Processes a trading action and updates the portfolio.\"\"\"\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            return self._next_observation(), 0, True, False, {}  #Include 'truncated' as False\n",
        "\n",
        "        self.current_step += 1\n",
        "        stock_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        action = float(action)  #Ensure action is a scalar float\n",
        "\n",
        "        trade_size = action * 0.1 * self.portfolio_value  #No indexing needed\n",
        "        shares_traded = abs(trade_size) / max(stock_price, 1e-3)\n",
        "\n",
        "        reward = 0\n",
        "        if trade_size > 0 and self.portfolio_value >= shares_traded * stock_price:\n",
        "            self.shares_held += shares_traded\n",
        "            self.portfolio_value -= shares_traded * stock_price\n",
        "            reward += 0.2\n",
        "\n",
        "        elif trade_size < 0 and self.shares_held > 0:\n",
        "            shares_sold = min(shares_traded, self.shares_held)\n",
        "            self.shares_held -= shares_sold\n",
        "            self.portfolio_value += shares_sold * stock_price\n",
        "            profit_margin = (stock_price - self.df['Close'].iloc[self.current_step - 1]) / max(self.df['Close'].iloc[self.current_step - 1], 1e-6)\n",
        "            reward += profit_margin * 100 if profit_margin > 0.005 else -0.05\n",
        "\n",
        "        return self._next_observation(), reward, False, False, {}  #Ensure correct return structure\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"Resets the environment for a new episode.\"\"\"\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        return self._next_observation().astype(np.float32), {}\n"
      ],
      "metadata": {
        "id": "c59d9PpktI78"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TD3 Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "env = DummyVecEnv([lambda: ContinuousTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)])\n",
        "\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "td3_model = TD3(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    action_noise=action_noise,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=128,\n",
        "    gamma=0.99,\n",
        "    tau=0.01,\n",
        "    gradient_steps=2,\n",
        "    tensorboard_log=\"./td3_tensorboard/\",\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "td3_model.learn(total_timesteps=10000)\n",
        "td3_model.save(\"td3_trading_model_v1\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib28M8fOfpx4",
        "outputId": "f72f25af-ab34-4428-a4bb-f5734ed61614"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Logging to ./td3_tensorboard/TD3_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-9fd72917ac17>:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action)  #Ensure action is a scalar float\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, num_steps=100):\n",
        "    \"\"\"Evaluates a trained RL model and logs trading signals.\"\"\"\n",
        "    result = env.reset()\n",
        "    if isinstance(result, tuple):  #Handle Gymnasium tuple return\n",
        "        obs, _ = result\n",
        "    else:\n",
        "        obs = result\n",
        "\n",
        "    trade_log = []  #Store TD3 trading signals\n",
        "    portfolio_values = []\n",
        "    total_rewards = np.zeros(env.num_envs)  #VecEnv handles multiple environments\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "        #Extract single element safely\n",
        "        trade_log.append(int(np.squeeze(action)))\n",
        "\n",
        "        obs, reward, done, _ = env.step(action)  #Ensure action is passed as an array\n",
        "        total_rewards += reward  #Sum rewards across environments\n",
        "\n",
        "        #Track portfolio value from the first wrapped environment\n",
        "        portfolio_value = env.get_attr(\"portfolio_value\")[0]\n",
        "        portfolio_values.append(portfolio_value)\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}: Action: {trade_log[-1]}, Reward: {reward.mean():.4f}, Portfolio: {portfolio_value:.2f}\")\n",
        "\n",
        "        if done.any():  #Handle VecEnv `done`\n",
        "            result = env.reset()\n",
        "            obs = result[0] if isinstance(result, tuple) else result\n",
        "\n",
        "    #Return trade log and portfolio values\n",
        "    return trade_log, portfolio_values, total_rewards.sum()\n"
      ],
      "metadata": {
        "id": "i-_XNiNr7v_d"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate TD3 Model\n",
        "print(\"\\nEvaluating TD3 Model with Portfolio Tracking...\")\n",
        "td3_trade_log, portfolio_values, total_rewards = evaluate_model(td3_model, env, num_steps=100)\n",
        "\n",
        "#Store TD3 trade results in a separate DataFrame\n",
        "td3_results_df = pd.DataFrame({\n",
        "    \"TD3_Trade_Signal\": td3_trade_log,\n",
        "    \"Portfolio_Value\": portfolio_values,\n",
        "    \"Reward\": total_rewards\n",
        "})\n",
        "\n",
        "#Print trade signal counts\n",
        "print(\"\\nTD3 Trade Signal Counts:\")\n",
        "print(td3_results_df[\"TD3_Trade_Signal\"].value_counts())\n",
        "\n",
        "#Display first 20 trades\n",
        "print(\"\\nTD3 Trading Strategy Completed Successfully!\")\n",
        "print(td3_results_df.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxISOmOMjSqX",
        "outputId": "7619209c-23d9-48ba-952f-ff0d36ae623b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating TD3 Model with Portfolio Tracking...\n",
            "Step 0: Action: 1, Reward: 0.2000, Portfolio: 9000.00\n",
            "Step 10: Action: 1, Reward: 0.2000, Portfolio: 3138.11\n",
            "Step 20: Action: 1, Reward: 0.2000, Portfolio: 1094.19\n",
            "Step 30: Action: 1, Reward: 0.2000, Portfolio: 381.52\n",
            "Step 40: Action: 1, Reward: 0.2000, Portfolio: 133.03\n",
            "Step 50: Action: 1, Reward: 0.2000, Portfolio: 46.38\n",
            "Step 60: Action: 1, Reward: 0.2000, Portfolio: 16.17\n",
            "Step 70: Action: 1, Reward: 0.2000, Portfolio: 5.64\n",
            "Step 80: Action: 1, Reward: 0.2000, Portfolio: 1.97\n",
            "Step 90: Action: 1, Reward: 0.2000, Portfolio: 0.69\n",
            "\n",
            "TD3 Trade Signal Counts:\n",
            "TD3_Trade_Signal\n",
            "1    100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TD3 Trading Strategy Completed Successfully!\n",
            "    TD3_Trade_Signal  Portfolio_Value  Reward\n",
            "0                  1      9000.000000    20.0\n",
            "1                  1      8100.000000    20.0\n",
            "2                  1      7290.000000    20.0\n",
            "3                  1      6561.000000    20.0\n",
            "4                  1      5904.900000    20.0\n",
            "5                  1      5314.410000    20.0\n",
            "6                  1      4782.969000    20.0\n",
            "7                  1      4304.672100    20.0\n",
            "8                  1      3874.204890    20.0\n",
            "9                  1      3486.784401    20.0\n",
            "10                 1      3138.105961    20.0\n",
            "11                 1      2824.295365    20.0\n",
            "12                 1      2541.865828    20.0\n",
            "13                 1      2287.679245    20.0\n",
            "14                 1      2058.911321    20.0\n",
            "15                 1      1853.020189    20.0\n",
            "16                 1      1667.718170    20.0\n",
            "17                 1      1500.946353    20.0\n",
            "18                 1      1350.851718    20.0\n",
            "19                 1      1215.766546    20.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-9fd72917ac17>:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action)  #Ensure action is a scalar float\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"volatility\" not in df.columns:\n",
        "    print(\"'volatility' column missing! Computing now...\")\n",
        "    df[\"volatility\"] = df[\"Close\"].pct_change().rolling(20).std()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "required_features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "if not all(feature in df.columns for feature in required_features):\n",
        "    raise ValueError(f\"Missing Features: {set(required_features) - set(df.columns)}. Run feature engineering first!\")\n",
        "\n",
        "if 'Target' not in df.columns:\n",
        "    raise ValueError(\"'Target' column is missing! Ensure generate_trade_labels(df) was applied.\")\n",
        "\n",
        "print(\"Features and labels are ready for evaluation.\")\n"
      ],
      "metadata": {
        "id": "BZC3HIhXjl_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60197122-7082-40a4-e188-7f744bab9cab"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and labels are ready for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to Evaluate Sklearn Models (XGBoost & Random Forest)\n",
        "def evaluate_sklearn_model(model, df):\n",
        "    \"\"\"Evaluates a scikit-learn model (XGBoost or Random Forest) for trading.\"\"\"\n",
        "    X = df[feature_columns]\n",
        "    y = df[target_column]\n",
        "\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Simulate Trading Strategy\n",
        "    portfolio_value = 100000  # Initial balance\n",
        "    shares_held = 0\n",
        "    portfolio_values = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if predictions[i] == 1 and shares_held == 0:  # BUY signal\n",
        "            shares_held = portfolio_value / df[\"Close\"].iloc[i]\n",
        "            portfolio_value = 0\n",
        "        elif predictions[i] == 0 and shares_held > 0:  # SELL signal\n",
        "            portfolio_value = shares_held * df[\"Close\"].iloc[i]\n",
        "            shares_held = 0\n",
        "\n",
        "        portfolio_values.append(portfolio_value + (shares_held * df[\"Close\"].iloc[i]))\n",
        "\n",
        "    final_value = portfolio_values[-1]\n",
        "    profit_loss = final_value - 100000\n",
        "    return portfolio_values, final_value, profit_loss"
      ],
      "metadata": {
        "id": "_kwQjoA-D6rz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to Evaluate SARSA Model\n",
        "def evaluate_sarsa_model(agent, env, df):\n",
        "    \"\"\"Evaluates a trained SARSA agent and calculates profit/loss.\"\"\"\n",
        "    result = env.reset()\n",
        "    obs = result[0] if isinstance(result, tuple) else result  #Fix reset handling\n",
        "\n",
        "    portfolio_value = 100000  # Initial balance\n",
        "    shares_held = 0\n",
        "    portfolio_values = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        state = tuple(obs.flatten())  # Convert state to tuple\n",
        "        action = np.argmax(agent.q_table[state]) if state in agent.q_table else 1  # Default to HOLD if state unknown\n",
        "\n",
        "        if action == 2 and shares_held == 0:  # BUY\n",
        "            shares_held = portfolio_value / df[\"Close\"].iloc[i]\n",
        "            portfolio_value = 0\n",
        "        elif action == 0 and shares_held > 0:  # SELL\n",
        "            portfolio_value = shares_held * df[\"Close\"].iloc[i]\n",
        "            shares_held = 0\n",
        "\n",
        "        portfolio_values.append(portfolio_value + (shares_held * df[\"Close\"].iloc[i]))\n",
        "\n",
        "        result = env.step(action)\n",
        "        obs = result[0] if isinstance(result, tuple) else result\n",
        "\n",
        "    final_value = portfolio_values[-1]\n",
        "    profit_loss = final_value - 100000\n",
        "    return portfolio_values, final_value, profit_loss\n"
      ],
      "metadata": {
        "id": "vrU5mnHbD8Th"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, num_steps=100):\n",
        "    \"\"\"Evaluates a trained RL model and ensures correct handling of discrete and continuous actions.\"\"\"\n",
        "    result = env.reset()\n",
        "    obs = np.squeeze(result[0]) if isinstance(result, tuple) else np.squeeze(result)\n",
        "\n",
        "    portfolio_value = 100000  # Initial balance\n",
        "    shares_held = 0\n",
        "    portfolio_values = []\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        action = np.squeeze(action)  #Convert NumPy array to scalar\n",
        "\n",
        "        #Convert Continuous Action to Discrete if Necessary\n",
        "        if isinstance(env.action_space, Discrete):  # PPO, A2C, SARSA\n",
        "            action = int(round(float(action)))  #Ensure action is an integer\n",
        "            action = np.clip(action, 0, 2)  #Restrict to valid discrete actions (0=SELL, 1=HOLD, 2=BUY)\n",
        "        else:  # TD3 (Continuous)\n",
        "            action = float(action)  #Ensure float for continuous environment\n",
        "\n",
        "        #Apply Trading Logic\n",
        "        if action == 0 and shares_held > 0:  # SELL\n",
        "            portfolio_value += shares_held * df[\"Close\"].iloc[step]\n",
        "            shares_held = 0\n",
        "        elif action == 2 and shares_held == 0:  # BUY\n",
        "            shares_held = portfolio_value / df[\"Close\"].iloc[step]\n",
        "            portfolio_value = 0\n",
        "\n",
        "        portfolio_values.append(portfolio_value + (shares_held * df[\"Close\"].iloc[step]))\n",
        "\n",
        "        result = env.step([action])  #Pass as list for VecEnv compatibility\n",
        "        obs = np.squeeze(result[0]) if isinstance(result, tuple) else np.squeeze(result)\n",
        "\n",
        "    final_value = portfolio_values[-1]\n",
        "    profit_loss = final_value - 100000\n",
        "    return portfolio_values, final_value, profit_loss\n"
      ],
      "metadata": {
        "id": "huSiojQGEIPG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Sklearn Models\n",
        "xgb_results = evaluate_sklearn_model(xgb_model, df)\n",
        "rf_results = evaluate_sklearn_model(rf_model, df)\n",
        "\n",
        "#Evaluate RL Models (with Correct Environments)\n",
        "num_steps = len(df)\n",
        "\n",
        "td3_results = evaluate_model(td3_model, env, num_steps)  # Continuous Env\n",
        "ppo_results = evaluate_model(ppo_model, env_discrete, num_steps)  # Discrete Env\n",
        "a2c_results = evaluate_model(a2c_model, env_discrete, num_steps)  # Discrete Env\n",
        "\n",
        "#Evaluate SARSA Model\n",
        "sarsa_results = evaluate_sarsa_model(sarsa_agent, env_discrete_sarsa, df)\n",
        "\n",
        "#Rank Models Based on Profit/Loss\n",
        "model_performance = {}\n",
        "\n",
        "for model_name, result in [\n",
        "    (\"XGBoost\", xgb_results),\n",
        "    (\"Random Forest\", rf_results),\n",
        "    (\"TD3\", td3_results),\n",
        "    (\"PPO\", ppo_results),\n",
        "    (\"A2C\", a2c_results),\n",
        "    (\"SARSA\", sarsa_results),\n",
        "]:\n",
        "    if isinstance(result, tuple) and len(result) == 3:\n",
        "        model_performance[model_name] = result[2]\n",
        "\n",
        "#Rank Models\n",
        "sorted_models = sorted(model_performance.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#Print Model Rankings\n",
        "print(\"\\nModel Ranking Based on Profit/Loss:\")\n",
        "for rank, (model, profit) in enumerate(sorted_models, start=1):\n",
        "    print(f\"{rank}. {model}: ${profit:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGB6WvXM7xs",
        "outputId": "127e3649-5a60-4fd8-e8ec-949484958c2f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Ranking Based on Profit/Loss:\n",
            "1. XGBoost: $60306.43\n",
            "2. Random Forest: $56310.20\n",
            "3. TD3: $0.00\n",
            "4. A2C: $-2610.65\n",
            "5. SARSA: $-16046.16\n",
            "6. PPO: $-23509.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Winner and Plot Performance\n",
        "best_model_name = sorted_models[0][0]\n",
        "best_model_results = locals()[f\"{best_model_name.lower()}_results\"]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(best_model_results[0], label=f\"{best_model_name} Portfolio Value\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value ($)\")\n",
        "plt.title(f\"{best_model_name} Trading Model Performance\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "8a00kYrKEPoM",
        "outputId": "07aca13f-1c28-4c07-b59a-7bebab70bdae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'xgboost_results'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-c88c1409ea59>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Select Winner and Plot Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_model_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{best_model_name.lower()}_results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'xgboost_results'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
