{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsi6CGawALcwDAZSkjCOiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/exploratory_daytrading/blob/main/ppo_alpaca_paper_trading_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-DEy5gEqqEi"
      },
      "outputs": [],
      "source": [
        "!pip install alpaca-trade-api\n",
        "!pip install alpaca-trade-api python-dotenv ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean any partials\n",
        "!pip uninstall -y stable-baselines3 shimmy gymnasium gym autorom AutoROM.accept-rom-license ale-py\n",
        "\n",
        "# Install the compatible trio (no [extra] to avoid Atari deps)\n",
        "!pip install \"gymnasium==0.29.1\" \"shimmy==1.3.0\" \"stable-baselines3==2.3.0\"\n",
        "\n",
        "# Your other libs (safe to keep separate)\n",
        "!pip install alpaca-trade-api ta python-dotenv gym-anytrading\n"
      ],
      "metadata": {
        "id": "9HgUjRXJs8ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install if not already\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "s8LJ--nts-e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, time, typing, numpy as np\n",
        "import warnings\n",
        "\n",
        "# Colab Drive (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Use a PPO-specific output dir (rename from LightGBM)\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Alpaca_Results/PPO\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "EIIJzHY2MKS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Prompts you to upload the .env file for the key"
      ],
      "metadata": {
        "id": "VVzj0Dm0MXPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Rename to .env so dotenv can recognize it\n",
        "os.rename(\"Alpaca_keys.env.txt\", \".env\")"
      ],
      "metadata": {
        "id": "XvugzyvHMZqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload: model_ABT.txt, features_ABT.txt, scaler_ABT.pkl\n"
      ],
      "metadata": {
        "id": "SvDVZyNkMb_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= UNH PPO Paper-Trading — End-to-End Script =======================\n",
        "# One cell / one file version. Defaults to DRY_RUN (log only). Set DRY_RUN=0 to place paper orders.\n",
        "\n",
        "# --- Imports & logging -------------------------------------------------------------------\n",
        "import os, re, json, csv, shutil, logging, pickle, warnings, time, math\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import Dict, Optional, Tuple, Any, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import alpaca_trade_api as tradeapi\n",
        "from alpaca_trade_api.rest import TimeFrame, APIError\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "load_dotenv(override=True)\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "\n",
        "# --- Alpaca API init ---------------------------------------------------------------------\n",
        "API_KEY    = os.getenv(\"APCA_API_KEY_ID\")     or os.getenv(\"ALPACA_API_KEY_ID\")     or \"\"\n",
        "API_SECRET = os.getenv(\"APCA_API_SECRET_KEY\") or os.getenv(\"ALPACA_API_SECRET_KEY\") or \"\"\n",
        "BASE_URL   = os.getenv(\"APCA_API_BASE_URL\")   or os.getenv(\"ALPACA_API_BASE_URL\")   or \"https://paper-api.alpaca.markets\"\n",
        "\n",
        "def init_alpaca() -> \"tradeapi.REST\":\n",
        "    if not API_KEY or not API_SECRET:\n",
        "        raise RuntimeError(\"Missing Alpaca API keys.\")\n",
        "    api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL)\n",
        "    _ = api.get_account()  # sanity\n",
        "    return api\n",
        "\n",
        "# --- Runtime knobs (env-driven) ----------------------------------------------------------\n",
        "ARTIFACTS_DIR     = os.getenv(\"ARTIFACTS_DIR\", \"/content\")\n",
        "BEST_WINDOW_ENV   = (os.getenv(\"BEST_WINDOW\", \"\").strip() or None)  # e.g., \"3\"\n",
        "TICKERS           = [s.strip() for s in os.getenv(\"TICKERS\", \"UNH\").split(\",\") if s.strip()]\n",
        "BARS_FEED         = os.getenv(\"BARS_FEED\", \"iex\").strip()\n",
        "DRY_RUN           = os.getenv(\"DRY_RUN\", \"1\").lower() in (\"1\",\"true\",\"yes\")\n",
        "INF_DETERMINISTIC = os.getenv(\"INF_DETERMINISTIC\", \"1\").lower() in (\"1\",\"true\",\"yes\")\n",
        "COOLDOWN_MIN      = int(os.getenv(\"COOLDOWN_MIN\", \"1\"))\n",
        "STALE_MAX_SEC     = int(os.getenv(\"STALE_MAX_SEC\", \"120\"))\n",
        "\n",
        "# Sizing / TP-SL\n",
        "SIZING_MODE     = os.getenv(\"SIZING_MODE\", \"linear\")        # \"linear\" | \"threshold\"\n",
        "WEIGHT_CAP      = float(os.getenv(\"WEIGHT_CAP\", \"0.10\"))    # Max portfolio weight for a symbol\n",
        "CONF_FLOOR      = float(os.getenv(\"CONF_FLOOR\", \"0.20\"))    # Threshold mode only\n",
        "TAKE_PROFIT_PCT = float(os.getenv(\"TAKE_PROFIT_PCT\", \"0\"))  # e.g., 0.05 = +5%\n",
        "STOP_LOSS_PCT   = float(os.getenv(\"STOP_LOSS_PCT\", \"0\"))    # e.g., 0.03 = -3%\n",
        "\n",
        "# --- Small time utils --------------------------------------------------------------------\n",
        "def now_utc() -> datetime:\n",
        "    return datetime.now(timezone.utc)\n",
        "\n",
        "def utc_ts(dt_like) -> int:\n",
        "    try:\n",
        "        return int(pd.Timestamp(dt_like, tz=\"UTC\").timestamp())\n",
        "    except Exception:\n",
        "        return int(datetime.fromtimestamp(float(dt_like), tz=timezone.utc).timestamp())\n",
        "# --- Helper: re-read sizing knobs from environment --------------------------------------\n",
        "def apply_env_overrides(verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Re-read SIZING_MODE / CONF_FLOOR from environment and update the globals.\n",
        "    Call this AFTER you set os.environ[...] and BEFORE running inference.\n",
        "    \"\"\"\n",
        "    global SIZING_MODE, CONF_FLOOR\n",
        "    old_mode, old_floor = SIZING_MODE, CONF_FLOOR\n",
        "    SIZING_MODE = os.getenv(\"SIZING_MODE\", SIZING_MODE)\n",
        "    CONF_FLOOR  = float(os.getenv(\"CONF_FLOOR\", str(CONF_FLOOR)))\n",
        "    if verbose:\n",
        "        print(f\"SIZING_MODE: {old_mode} -> {SIZING_MODE}\")\n",
        "        print(f\"CONF_FLOOR:  {old_floor:.2f} -> {CONF_FLOOR:.2f}\")\n",
        "\n",
        "# =========================================================================================\n",
        "# Artifacts & CSV logging\n",
        "# =========================================================================================\n",
        "RESULTS_DIR = Path(os.getenv(\"RESULTS_DIR\", ARTIFACTS_DIR))\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _append_csv_row(path: Path, row: dict):\n",
        "    write_header = not path.exists()\n",
        "    with path.open(\"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=row.keys())\n",
        "        if write_header:\n",
        "            w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "def log_trade(symbol: str,\n",
        "              bar_time,            # pandas/np datetime or ISO\n",
        "              signal: int,         # 1=Buy, 0=Sell/Hold\n",
        "              raw_action: float,   # PPO raw action\n",
        "              weight: float,       # target portfolio weight\n",
        "              confidence: float,   # |tanh(raw_action)|\n",
        "              price: float,        # last price\n",
        "              equity: float,       # account equity\n",
        "              dry_run: bool,\n",
        "              note: str = \"\"):\n",
        "    try:\n",
        "        bt_iso = pd.to_datetime(bar_time, utc=True).isoformat()\n",
        "    except Exception:\n",
        "        bt_iso = \"\"\n",
        "    row = {\n",
        "        \"log_time\": now_utc().isoformat(),\n",
        "        \"symbol\": symbol,\n",
        "        \"bar_time\": bt_iso,\n",
        "        \"signal\": \"BUY\" if int(signal) == 1 else \"SELL_OR_HOLD\",\n",
        "        \"raw_action\": float(raw_action) if np.isfinite(raw_action) else \"\",\n",
        "        \"weight\": float(weight) if np.isfinite(weight) else \"\",\n",
        "        \"confidence\": float(confidence) if np.isfinite(confidence) else \"\",\n",
        "        \"price\": float(price) if np.isfinite(price) else \"\",\n",
        "        \"equity\": float(equity) if np.isfinite(equity) else \"\",\n",
        "        \"dry_run\": int(bool(dry_run)),\n",
        "        \"note\": note,\n",
        "    }\n",
        "    _append_csv_row(RESULTS_DIR / f\"trade_log_{symbol}.csv\", row)\n",
        "\n",
        "# Optional: copy artifacts into ARTIFACTS_DIR if found in Drive\n",
        "ART_DIR = Path(ARTIFACTS_DIR)\n",
        "CANDIDATE_DRIVE_ROOTS = [Path(\"/content/drive/MyDrive\"), Path(\"/content/drive\")]\n",
        "if BEST_WINDOW_ENV:\n",
        "    need = [\n",
        "        f\"ppo_UNH_window{BEST_WINDOW_ENV}_model.zip\",\n",
        "        f\"ppo_UNH_window{BEST_WINDOW_ENV}_vecnorm.pkl\",\n",
        "        f\"ppo_UNH_window{BEST_WINDOW_ENV}_features.json\",\n",
        "    ]\n",
        "else:\n",
        "    # Fallback names if window not encoded\n",
        "    need = [\n",
        "        \"ppo_UNH_model.zip\",\n",
        "        \"ppo_UNH_vecnorm.pkl\",\n",
        "        \"ppo_UNH_features.json\",\n",
        "    ]\n",
        "\n",
        "for name in need:\n",
        "    dst = ART_DIR / name\n",
        "    if dst.exists():\n",
        "        continue\n",
        "    src = None\n",
        "    for root in CANDIDATE_DRIVE_ROOTS:\n",
        "        try:\n",
        "            src = next(root.rglob(name))\n",
        "            break\n",
        "        except StopIteration:\n",
        "            continue\n",
        "    if src:\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "print(\"ARTIFACTS_DIR =\", ART_DIR)\n",
        "print(\"Exists:\", ART_DIR.exists())\n",
        "print(\"Artifacts present:\", sorted(p.name for p in ART_DIR.glob(\"ppo_UNH*\")))\n",
        "print(\"DRY_RUN =\", DRY_RUN, \"| BARS_FEED =\", BARS_FEED)\n",
        "\n",
        "# =========================================================================================\n",
        "# Feature engineering & observation builders (live-time)\n",
        "# =========================================================================================\n",
        "def normalize_ohlcv_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cols_ci = {c.lower(): c for c in df.columns}\n",
        "    want = {\n",
        "        \"Open\":      [\"open\"],\n",
        "        \"High\":      [\"high\"],\n",
        "        \"Low\":       [\"low\"],\n",
        "        \"Close\":     [\"close\", \"close*\", \"last\"],\n",
        "        \"Adj Close\": [\"adj close\", \"adj_close\", \"adjclose\", \"adjusted close\"],\n",
        "        \"Volume\":    [\"volume\", \"vol\"],\n",
        "    }\n",
        "    rename = {}\n",
        "    for final, alts in want.items():\n",
        "        for a in [final.lower()] + alts:\n",
        "            if a in cols_ci:\n",
        "                rename[cols_ci[a]] = final\n",
        "                break\n",
        "    out = df.rename(columns=rename).copy()\n",
        "    if \"Adj Close\" not in out.columns and \"Close\" in out.columns:\n",
        "        out[\"Adj Close\"] = out[\"Close\"]\n",
        "    return out\n",
        "\n",
        "def denoise_wavelet(series: pd.Series, wavelet: str = \"db1\", level: int = 2) -> pd.Series:\n",
        "    try:\n",
        "        import pywt\n",
        "    except Exception:\n",
        "        return pd.Series(series).astype(float).ewm(span=5, adjust=False).mean()\n",
        "    s = pd.Series(series).astype(float).ffill().bfill()\n",
        "    arr = s.to_numpy()\n",
        "    try:\n",
        "        w = pywt.Wavelet(wavelet)\n",
        "        maxlvl = pywt.dwt_max_level(len(arr), w.dec_len)\n",
        "        lvl = int(max(0, min(level, maxlvl)))\n",
        "        if lvl < 1:\n",
        "            return s\n",
        "        coeffs = pywt.wavedec(arr, w, mode=\"symmetric\", level=lvl)\n",
        "        for i in range(1, len(coeffs)):\n",
        "            coeffs[i] = np.zeros_like(coeffs[i])\n",
        "        rec = pywt.waverec(coeffs, w, mode=\"symmetric\")\n",
        "        return pd.Series(rec[:len(arr)], index=s.index)\n",
        "    except Exception:\n",
        "        return s.ewm(span=5, adjust=False).mean()\n",
        "\n",
        "def add_regime(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df[\"Vol20\"] = df[\"Close\"].pct_change().rolling(20).std()\n",
        "    df[\"Ret20\"] = df[\"Close\"].pct_change(20)\n",
        "    vol_hi   = (df[\"Vol20\"] > df[\"Vol20\"].median()).astype(int)\n",
        "    trend_hi = (df[\"Ret20\"].abs() > df[\"Ret20\"].abs().median()).astype(int)\n",
        "    df[\"Regime4\"] = vol_hi * 2 + trend_hi\n",
        "    return df\n",
        "\n",
        "def add_features_live(\n",
        "    df: pd.DataFrame,\n",
        "    use_sentiment: bool = False,\n",
        "    rsi_wilder: bool = True,\n",
        "    atr_wilder: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    df = normalize_ohlcv_cols(df).copy().sort_index()\n",
        "\n",
        "    # Bollinger\n",
        "    df[\"SMA_20\"] = df[\"Close\"].rolling(20).mean()\n",
        "    df[\"STD_20\"] = df[\"Close\"].rolling(20).std()\n",
        "    df[\"Upper_Band\"] = df[\"SMA_20\"] + 2 * df[\"STD_20\"]\n",
        "    df[\"Lower_Band\"] = df[\"SMA_20\"] - 2 * df[\"STD_20\"]\n",
        "\n",
        "    # Stochastic\n",
        "    df[\"Lowest_Low\"]   = df[\"Low\"].rolling(14).min()\n",
        "    df[\"Highest_High\"] = df[\"High\"].rolling(14).max()\n",
        "    denom = (df[\"Highest_High\"] - df[\"Lowest_Low\"]).replace(0, np.nan)\n",
        "    df[\"Stoch\"] = ((df[\"Close\"] - df[\"Lowest_Low\"]) / denom) * 100\n",
        "\n",
        "    # Momentum / volume / CCI\n",
        "    df[\"ROC\"] = df[\"Close\"].pct_change(10)\n",
        "    sign = np.sign(df[\"Close\"].diff().fillna(0))\n",
        "    df[\"OBV\"] = (sign * df[\"Volume\"].fillna(0)).cumsum()\n",
        "\n",
        "    tp = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3.0\n",
        "    sma_tp = tp.rolling(20).mean()\n",
        "    md = (tp - sma_tp).abs().rolling(20).mean().replace(0, np.nan)\n",
        "    df[\"CCI\"] = (tp - sma_tp) / (0.015 * md)\n",
        "\n",
        "    # EMAs + MACD\n",
        "    df[\"EMA_10\"] = df[\"Close\"].ewm(span=10, adjust=False).mean()\n",
        "    df[\"EMA_50\"] = df[\"Close\"].ewm(span=50, adjust=False).mean()\n",
        "    ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
        "    ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
        "    df[\"MACD_Line\"]   = ema12 - ema26\n",
        "    df[\"MACD_Signal\"] = df[\"MACD_Line\"].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # RSI (Wilder default)\n",
        "    d = df[\"Close\"].diff()\n",
        "    gain = d.clip(lower=0)\n",
        "    loss = (-d.clip(upper=0))\n",
        "    if rsi_wilder:\n",
        "        avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()\n",
        "        avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()\n",
        "    else:\n",
        "        avg_gain = gain.rolling(14).mean()\n",
        "        avg_loss = loss.rolling(14).mean()\n",
        "    rs = avg_gain / avg_loss.replace(0, np.nan)\n",
        "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # ATR (Wilder)\n",
        "    tr = pd.concat([\n",
        "        (df[\"High\"] - df[\"Low\"]),\n",
        "        (df[\"High\"] - df[\"Close\"].shift()).abs(),\n",
        "        (df[\"Low\"]  - df[\"Close\"].shift()).abs(),\n",
        "    ], axis=1).max(axis=1)\n",
        "    df[\"ATR\"] = tr.ewm(alpha=1/14, adjust=False).mean() if atr_wilder else tr.rolling(14).mean()\n",
        "\n",
        "    # Vol + denoised close\n",
        "    df[\"Volatility\"]   = df[\"Close\"].pct_change().rolling(20).std()\n",
        "    df[\"Denoised_Close\"] = denoise_wavelet(df[\"Close\"])\n",
        "\n",
        "    # Regime + simple “Greeks” proxies + optional sentiment\n",
        "    df = add_regime(df)\n",
        "    df[\"SentimentScore\"] = (df.get(\"SentimentScore\", 0.0) if use_sentiment else 0.0)\n",
        "    df[\"Delta\"] = df[\"Close\"].pct_change(1).fillna(0.0)\n",
        "    df[\"Gamma\"] = df[\"Delta\"].diff().fillna(0.0)\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return df\n",
        "\n",
        "def compute_art_feat_order(features_hint: Any, df: pd.DataFrame) -> List[str]:\n",
        "    if features_hint is None:\n",
        "        return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    feats = features_hint.get(\"features\", features_hint) if isinstance(features_hint, dict) else list(features_hint)\n",
        "    drop = {\"datetime\", \"symbol\", \"target\", \"return\"}\n",
        "    return [c for c in feats if c not in drop and (c in df.columns) and pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "def build_obs_from_row(row: pd.Series, order: List[str]) -> np.ndarray:\n",
        "    vals = []\n",
        "    for c in order:\n",
        "        v = row.get(c, np.nan)\n",
        "        vals.append(0.0 if (pd.isna(v) or v is None or v is False) else float(v))\n",
        "    return np.array(vals, dtype=np.float32)\n",
        "\n",
        "def expected_obs_shape(model, vecnorm) -> Optional[tuple]:\n",
        "    for src in (vecnorm, model):\n",
        "        try:\n",
        "            shp = tuple(src.observation_space.shape)\n",
        "            if shp:\n",
        "                return shp\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def _pick_columns_for_channels(features_hint: Any, df: pd.DataFrame, channels: int) -> List[str]:\n",
        "    numeric = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    cols: List[str] = []\n",
        "    if isinstance(features_hint, dict) and \"features\" in features_hint:\n",
        "        cand = [c for c in features_hint[\"features\"] if c in df.columns and pd.api.types.is_numeric_dtype(df[c])]\n",
        "        if len(cand) >= channels:\n",
        "            cols = cand[:channels]\n",
        "    if not cols:\n",
        "        pref = [\"Close\", \"Volume\", \"Adj Close\", \"Open\", \"High\", \"Low\"]\n",
        "        cols = [c for c in pref if c in numeric]\n",
        "        cols += [c for c in numeric if c not in cols]\n",
        "        cols = cols[:channels]\n",
        "    if len(cols) < channels and cols:\n",
        "        while len(cols) < channels:\n",
        "            cols.append(cols[-1])\n",
        "    return cols[:channels]\n",
        "\n",
        "def prepare_observation_from_bars(\n",
        "    bars_df: pd.DataFrame,\n",
        "    features_hint: Any = None,\n",
        "    min_required_rows: int = 60,\n",
        "    expected_shape: Optional[tuple] = None,\n",
        ") -> Tuple[np.ndarray, int]:\n",
        "    feats_df = add_features_live(bars_df).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    ts = pd.Timestamp.utcnow()\n",
        "    try:\n",
        "        idx_ts = pd.Timestamp(feats_df.index[-1])\n",
        "        ts = idx_ts.tz_convert(\"UTC\") if idx_ts.tzinfo else idx_ts.tz_localize(\"UTC\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if expected_shape is not None and len(expected_shape) == 2:\n",
        "        lookback, channels = int(expected_shape[0]), int(expected_shape[1])\n",
        "        cols = _pick_columns_for_channels(features_hint, feats_df, channels)\n",
        "        window_df = feats_df[cols].tail(lookback)\n",
        "        arr = window_df.to_numpy(dtype=np.float32)\n",
        "        if arr.shape[0] < lookback:\n",
        "            pad_rows = lookback - arr.shape[0]\n",
        "            arr = np.vstack([np.zeros((pad_rows, channels), dtype=np.float32), arr])\n",
        "        arr = arr[-lookback:, :channels]\n",
        "        return arr.reshape(lookback, channels), int(ts.timestamp())\n",
        "\n",
        "    order = compute_art_feat_order(features_hint, feats_df)\n",
        "    if not order:\n",
        "        raise ValueError(\"No usable features after resolving artifact order.\")\n",
        "    feats_df = feats_df.dropna(subset=order)\n",
        "    if len(feats_df) < max(20, min_required_rows):\n",
        "        raise ValueError(f\"Not enough bars to compute features robustly (have {len(feats_df)}).\")\n",
        "    last = feats_df.iloc[-1]\n",
        "    obs = build_obs_from_row(last, order)\n",
        "    return obs.astype(np.float32), int(ts.timestamp())\n",
        "\n",
        "# =========================================================================================\n",
        "# Market data + account helpers\n",
        "# =========================================================================================\n",
        "def get_recent_bars(api, symbol: str, limit: int = 200, timeframe=TimeFrame.Minute) -> pd.DataFrame:\n",
        "    def _as_df(bars):\n",
        "        if hasattr(bars, \"df\"):\n",
        "            df = bars.df.copy()\n",
        "            if not df.empty:\n",
        "                if isinstance(df.index, pd.MultiIndex):\n",
        "                    df = df.xs(symbol, level=0)\n",
        "                df.index = pd.to_datetime(df.index, utc=True)\n",
        "                df = df.rename(columns={\"open\":\"Open\",\"high\":\"High\",\"low\":\"Low\",\"close\":\"Close\",\"volume\":\"Volume\"})\n",
        "                cols = [c for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"] if c in df.columns]\n",
        "                return df[cols].sort_index()\n",
        "            return pd.DataFrame(columns=[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
        "        rows = []\n",
        "        for b in bars:\n",
        "            ts = getattr(b, \"t\", None)\n",
        "            ts = pd.to_datetime(ts, utc=True) if ts is not None else pd.NaT\n",
        "            rows.append({\n",
        "                \"timestamp\": ts,\n",
        "                \"Open\":   float(getattr(b, \"o\", getattr(b, \"open\",  np.nan))),\n",
        "                \"High\":   float(getattr(b, \"h\", getattr(b, \"high\",  np.nan))),\n",
        "                \"Low\":    float(getattr(b, \"l\", getattr(b, \"low\",   np.nan))),\n",
        "                \"Close\":  float(getattr(b, \"c\", getattr(b, \"close\", np.nan))),\n",
        "                \"Volume\": float(getattr(b, \"v\", getattr(b, \"volume\",np.nan))),\n",
        "            })\n",
        "        df = pd.DataFrame(rows)\n",
        "        if df.empty:\n",
        "            return pd.DataFrame(columns=[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
        "        return df.set_index(pd.to_datetime(df[\"timestamp\"], utc=True)).drop(columns=[\"timestamp\"]).sort_index()\n",
        "\n",
        "    feed = os.getenv(\"BARS_FEED\", \"\").strip()\n",
        "    try:\n",
        "        logging.info(f\"[{symbol}] fetching {limit} {timeframe} bars (feed='{feed or 'default'}')\")\n",
        "        bars = api.get_bars(symbol, timeframe, limit=limit, feed=feed) if feed else api.get_bars(symbol, timeframe, limit=limit)\n",
        "        df = _as_df(bars)\n",
        "        if not df.empty:\n",
        "            return df\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"[{symbol}] get_bars(limit) failed: {e}\")\n",
        "\n",
        "    # Fallback 5-day window\n",
        "    try:\n",
        "        end   = datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
        "        start = (datetime.utcnow() - timedelta(days=5)).replace(microsecond=0).isoformat() + \"Z\"\n",
        "        logging.info(f\"[{symbol}] retry with window start={start} end={end} (feed='{feed or 'default'}')\")\n",
        "        bars = api.get_bars(symbol, timeframe, start=start, end=end, feed=feed) if feed else api.get_bars(symbol, timeframe, start=start, end=end)\n",
        "        return _as_df(bars)\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"[{symbol}] get_bars(start/end) failed: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
        "\n",
        "def get_account_equity(api) -> float:\n",
        "    return float(api.get_account().equity)\n",
        "\n",
        "def get_position(api, symbol: str):\n",
        "    try:\n",
        "        return api.get_position(symbol)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_position_qty(api, symbol: str) -> int:\n",
        "    pos = get_position(api, symbol)\n",
        "    if not pos:\n",
        "        return 0\n",
        "    try:\n",
        "        return int(float(pos.qty))\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def get_last_price(api, symbol: str) -> float:\n",
        "    try:\n",
        "        bars = api.get_bars(symbol, TimeFrame.Minute, limit=1)\n",
        "        if len(bars) > 0:\n",
        "            b = bars[0]\n",
        "            close = getattr(b, \"c\", getattr(b, \"close\", None))\n",
        "            if close is not None:\n",
        "                return float(close)\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"[{symbol}] get_last_price via bars failed: {e}\")\n",
        "    try:\n",
        "        pos = api.get_position(symbol)\n",
        "        return float(pos.avg_entry_price)\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def cancel_open_symbol_orders(api, symbol: str):\n",
        "    try:\n",
        "        for o in api.list_orders(status=\"open\"):\n",
        "            if o.symbol == symbol:\n",
        "                api.cancel_order(o.id)\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"[{symbol}] cancel orders failed: {e}\")\n",
        "\n",
        "def market_order_to_qty(api, symbol: str, side: str, qty: int):\n",
        "    if qty <= 0:\n",
        "        return None\n",
        "    if DRY_RUN:\n",
        "        logging.info(f\"[DRY_RUN] Would submit {side} {qty} {symbol} (market, day)\")\n",
        "        return None\n",
        "    try:\n",
        "        o = api.submit_order(\n",
        "            symbol=symbol,\n",
        "            side=side,\n",
        "            type=\"market\",\n",
        "            qty=qty,\n",
        "            time_in_force=\"day\"\n",
        "        )\n",
        "        logging.info(f\"[{symbol}] Submitted {side} {qty} (market) id={o.id}\")\n",
        "        return o\n",
        "    except Exception as e:\n",
        "        logging.error(f\"[{symbol}] submit_order failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================================================================================\n",
        "# Sizing / risk + (un)flatten + rebalancer\n",
        "# =========================================================================================\n",
        "def action_to_weight(action) -> Tuple[float, float, float]:\n",
        "    a = float(np.array(action).squeeze())\n",
        "    conf = float(abs(np.tanh(a)))\n",
        "    if a <= 0:\n",
        "        return 0.0, conf, a\n",
        "    if SIZING_MODE == \"linear\":\n",
        "        w = WEIGHT_CAP * conf\n",
        "    else:\n",
        "        w = 0.0 if conf < CONF_FLOOR else WEIGHT_CAP * (conf - CONF_FLOOR) / (1.0 - CONF_FLOOR)\n",
        "    w = max(0.0, min(WEIGHT_CAP, float(w)))\n",
        "    return w, conf, a\n",
        "\n",
        "MIN_POS_QTY = 1\n",
        "\n",
        "def compute_target_qty(equity: float, price: float, target_weight: float) -> int:\n",
        "    if not np.isfinite(price) or price <= 0:\n",
        "        return 0\n",
        "    notional = equity * target_weight\n",
        "    qty = int(notional // price)\n",
        "    if target_weight > 0 and qty == 0:\n",
        "        return MIN_POS_QTY\n",
        "    return max(0, qty)\n",
        "\n",
        "def compute_target_qty_by_cash(equity: float, price: float, target_weight: float, api=None) -> int:\n",
        "    if not np.isfinite(price) or price <= 0:\n",
        "        return 0\n",
        "    cash_cap = float(api.get_account().cash) if api else equity\n",
        "    notional = min(cash_cap, equity * target_weight)\n",
        "    qty = int(notional // price)\n",
        "    if target_weight > 0 and qty == 0 and notional >= price:\n",
        "        return 1\n",
        "    return max(0, qty)\n",
        "\n",
        "def flatten_symbol(api, symbol: str):\n",
        "    qty = get_position_qty(api, symbol)\n",
        "    if qty == 0:\n",
        "        return\n",
        "    cancel_open_symbol_orders(api, symbol)\n",
        "    side = \"sell\" if qty > 0 else \"buy\"\n",
        "    market_order_to_qty(api, symbol, side, abs(qty))\n",
        "\n",
        "def rebalance_to_weight(api, symbol: str, equity: float, target_weight: float):\n",
        "    if target_weight <= 0:\n",
        "        flatten_symbol(api, symbol)\n",
        "        return\n",
        "    price    = get_last_price(api, symbol)\n",
        "    if not np.isfinite(price) or price <= 0:\n",
        "        logging.warning(f\"[{symbol}] Price unavailable; skipping rebalance this cycle.\")\n",
        "        return\n",
        "    have_qty = get_position_qty(api, symbol)\n",
        "    want_qty = compute_target_qty_by_cash(equity, price, target_weight, api)\n",
        "    delta    = want_qty - have_qty\n",
        "    if delta == 0:\n",
        "        return\n",
        "    side = \"buy\" if delta > 0 else \"sell\"\n",
        "    market_order_to_qty(api, symbol, side, abs(delta))\n",
        "\n",
        "def check_tp_sl_and_maybe_flatten(api, symbol: str) -> bool:\n",
        "    if TAKE_PROFIT_PCT <= 0 and STOP_LOSS_PCT <= 0:\n",
        "        return False\n",
        "    pos = get_position(api, symbol)\n",
        "    if not pos:\n",
        "        return False\n",
        "    try:\n",
        "        plpc = float(pos.unrealized_plpc)  # +0.031 = +3.1%\n",
        "    except Exception:\n",
        "        return False\n",
        "    if TAKE_PROFIT_PCT > 0 and plpc >= TAKE_PROFIT_PCT:\n",
        "        logging.info(f\"[{symbol}] TP hit ({plpc:.4f} >= {TAKE_PROFIT_PCT:.4f}). Flattening.\")\n",
        "        flatten_symbol(api, symbol)\n",
        "        return True\n",
        "    if STOP_LOSS_PCT > 0 and plpc <= -abs(STOP_LOSS_PCT):\n",
        "        logging.info(f\"[{symbol}] SL hit ({plpc:.4f} <= {-abs(STOP_LOSS_PCT):.4f}). Flattening.\")\n",
        "        flatten_symbol(api, symbol)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# =========================================================================================\n",
        "# Artifact picker & loaders\n",
        "# =========================================================================================\n",
        "def _extract_window_idx(path: Path) -> Optional[int]:\n",
        "    m = re.search(r\"_window(\\d+)_\", path.stem, re.IGNORECASE)\n",
        "    if not m:\n",
        "        return None\n",
        "    try:\n",
        "        return int(m.group(1))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def pick_artifacts_for_ticker(\n",
        "    ticker: str,\n",
        "    artifacts_dir: str,\n",
        "    best_window: Optional[str] = None\n",
        ") -> Dict[str, Optional[Path]]:\n",
        "    p = Path(artifacts_dir)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Artifacts directory not found: {p.resolve()}\")\n",
        "\n",
        "    models = sorted(p.glob(f\"ppo_{ticker}_window*_model.zip\"))\n",
        "    if not models:\n",
        "        models = sorted(p.glob(f\"ppo_{ticker}_model.zip\")) or sorted(p.glob(f\"*{ticker}*model.zip\"))\n",
        "        if not models:\n",
        "            found = \"\\n\".join(f\" - {x}\" for x in p.rglob(\"*model.zip\"))\n",
        "            raise FileNotFoundError(f\"No PPO model for {ticker} in {p.resolve()}.\\nSeen:\\n{found or ' (none)'}\")\n",
        "\n",
        "    chosen: Optional[Path] = None\n",
        "    if best_window:\n",
        "        chosen = next((m for m in models if f\"_window{best_window}_\" in m.stem), None)\n",
        "        if chosen is None:\n",
        "            logging.warning(\"BEST_WINDOW=%s not found; falling back to best available.\", best_window)\n",
        "\n",
        "    if chosen is None:\n",
        "        with_idx = [(m, _extract_window_idx(m)) for m in models]\n",
        "        with_idx = [(m, w) for (m, w) in with_idx if w is not None]\n",
        "        chosen = max(with_idx, key=lambda t: t[1])[0] if with_idx else models[-1]\n",
        "\n",
        "    base    = chosen.stem.replace(\"_model\", \"\")\n",
        "    vecnorm = next(iter(sorted(p.glob(base + \"_vecnorm.pkl\"))), None)\n",
        "    feats   = next(iter(sorted(p.glob(base + \"_features.json\"))), None)\n",
        "\n",
        "    logging.info(f\"[{ticker}] model={chosen.name} | vecnorm={bool(vecnorm)} | features={bool(feats)}\")\n",
        "    return {\"model\": chosen, \"vecnorm\": vecnorm, \"features\": feats}\n",
        "\n",
        "def load_vecnormalize(path: Optional[Path]):\n",
        "    if path is None:\n",
        "        return None\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_features(path: Optional[Path]):\n",
        "    if path is None:\n",
        "        return None\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_ppo_model(model_path: Path):\n",
        "    return PPO.load(str(model_path))\n",
        "\n",
        "# =========================================================================================\n",
        "# Inference helpers\n",
        "# =========================================================================================\n",
        "def infer_target_weight(model: PPO, vecnorm: Optional[VecNormalize], obs: np.ndarray) -> Tuple[float, float, float]:\n",
        "    x = obs\n",
        "    if vecnorm is not None and hasattr(vecnorm, \"normalize_obs\"):\n",
        "        try:\n",
        "            x = vecnorm.normalize_obs(x)\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"VecNormalize.normalize_obs failed; using raw obs. Err: {e}\")\n",
        "    action, _ = model.predict(x, deterministic=INF_DETERMINISTIC)\n",
        "    return action_to_weight(action)\n",
        "\n",
        "# =========================================================================================\n",
        "# Live step & loop (optional)\n",
        "# =========================================================================================\n",
        "def ensure_market_open(api) -> bool:\n",
        "    try:\n",
        "        return bool(api.get_clock().is_open)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def run_live_once_for_symbol(api, symbol: str, model: PPO, vecnorm: Optional[VecNormalize], features_hint: Optional[dict] = None):\n",
        "    shape = expected_obs_shape(model, vecnorm)\n",
        "    bars_df = get_recent_bars(api, symbol, limit=200, timeframe=TimeFrame.Minute)\n",
        "    if bars_df.empty:\n",
        "        logging.warning(f\"[{symbol}] No recent bars; skipping.\")\n",
        "        return\n",
        "    obs, obs_ts = prepare_observation_from_bars(\n",
        "        bars_df,\n",
        "        features_hint=features_hint,\n",
        "        min_required_rows=60,\n",
        "        expected_shape=shape,\n",
        "    )\n",
        "    if utc_ts(now_utc()) - obs_ts > STALE_MAX_SEC:\n",
        "        logging.warning(f\"[{symbol}] Observation stale (> {STALE_MAX_SEC}s). Skipping.\")\n",
        "        return\n",
        "\n",
        "    if check_tp_sl_and_maybe_flatten(api, symbol):\n",
        "        return\n",
        "\n",
        "    target_w, conf, raw = infer_target_weight(model, vecnorm, obs)\n",
        "    eq = get_account_equity(api)\n",
        "    logging.info(f\"[{symbol}] action={raw:.4f} conf={conf:.3f} → target_w={target_w:.3f} | equity=${eq:,.2f}\")\n",
        "    bar_time = bars_df.index[-1] if not bars_df.empty else pd.NaT\n",
        "    price    = float(bars_df[\"Close\"].iloc[-1]) if not bars_df.empty else get_last_price(api, symbol)\n",
        "    log_trade(symbol, bar_time, int(target_w > 0.0), raw, target_w, conf, price, eq, DRY_RUN, note=\"live\")\n",
        "\n",
        "    rebalance_to_weight(api, symbol, eq, target_w)\n",
        "\n",
        "def run_live(tickers: List[str]):\n",
        "    api = init_alpaca()\n",
        "    per_ticker: Dict[str, Tuple[PPO, Optional[VecNormalize], Optional[dict]]] = {}\n",
        "    for t in tickers:\n",
        "        picks      = pick_artifacts_for_ticker(t, ARTIFACTS_DIR, best_window=BEST_WINDOW_ENV)\n",
        "        model      = load_ppo_model(picks[\"model\"])\n",
        "        vecnorm    = load_vecnormalize(picks[\"vecnorm\"]) if picks[\"vecnorm\"] else None\n",
        "        feat_order = load_features(picks[\"features\"])\n",
        "        per_ticker[t] = (model, vecnorm, feat_order)\n",
        "\n",
        "    logging.info(f\"Starting live execution for: {tickers}\")\n",
        "    last_exec_at = now_utc() - timedelta(minutes=COOLDOWN_MIN)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            if not ensure_market_open(api):\n",
        "                logging.info(\"Market closed. Sleeping 30s.\")\n",
        "                time.sleep(30)\n",
        "                continue\n",
        "\n",
        "            if (now_utc() - last_exec_at) < timedelta(minutes=COOLDOWN_MIN):\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "\n",
        "            for t in tickers:\n",
        "                model, vecnorm, feat_hint = per_ticker[t]\n",
        "                run_live_once_for_symbol(api, t, model, vecnorm, features_hint=feat_hint)\n",
        "\n",
        "            last_exec_at = now_utc()\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logging.info(\"KeyboardInterrupt: stopping live loop.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Live loop exception: {e}\")\n",
        "            time.sleep(5)\n",
        "\n",
        "# =========================================================================================\n",
        "# UNH Diagnostic (one-off; works even if market closed; respects DRY_RUN)\n",
        "# =========================================================================================\n",
        "def unh_diagnostic(dry_run: bool = DRY_RUN,\n",
        "                   timeframe: TimeFrame = TimeFrame.Minute,\n",
        "                   limit: int = 300):\n",
        "    ticker = \"UNH\"\n",
        "    print(f\"\\nRunning strategy for {ticker}...\")\n",
        "\n",
        "    # Snapshot start\n",
        "    try:\n",
        "        api = init_alpaca()\n",
        "        positions_start = len(api.list_positions())\n",
        "        orders_start    = len(api.list_orders(status=\"open\"))\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Alpaca: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load artifacts\n",
        "    try:\n",
        "        best   = (os.getenv(\"BEST_WINDOW\", \"\").strip() or None)\n",
        "        picks  = pick_artifacts_for_ticker(ticker, os.getenv(\"ARTIFACTS_DIR\", \"/content\"), best_window=best)\n",
        "        model  = load_ppo_model(picks[\"model\"])\n",
        "        vecnorm = load_vecnormalize(picks[\"vecnorm\"]) if picks[\"vecnorm\"] else None\n",
        "        feats   = load_features(picks[\"features\"])\n",
        "        print(f\"Model artifacts loaded for {ticker}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load model for {ticker}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Bars / shape-aware requirements\n",
        "    try:\n",
        "        shape    = expected_obs_shape(model, vecnorm)\n",
        "        lookback = int(shape[0]) if (shape is not None and len(shape) == 2) else None\n",
        "        bars_need = max(200, (lookback or 0) * 3)\n",
        "        bars_df  = get_recent_bars(api, ticker, limit=max(limit, bars_need), timeframe=timeframe)\n",
        "\n",
        "        min_rows_needed = lookback if lookback is not None else 60\n",
        "        if len(bars_df) < min_rows_needed:\n",
        "            print(f\"Not enough data for {ticker}: {len(bars_df)} rows (need ≥ {min_rows_needed})\")\n",
        "            bars_df = pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching bars for {ticker}: {e}\")\n",
        "        bars_df = pd.DataFrame()\n",
        "\n",
        "    # Build observation\n",
        "    obs, obs_ts = None, None\n",
        "    if not bars_df.empty:\n",
        "        try:\n",
        "            obs, obs_ts = prepare_observation_from_bars(\n",
        "                bars_df,\n",
        "                features_hint=feats,\n",
        "                min_required_rows=min_rows_needed,\n",
        "                expected_shape=shape,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing observation for {ticker}: {e}\")\n",
        "\n",
        "    # Predict\n",
        "    signal = None\n",
        "    target_w = conf = raw = float(\"nan\")\n",
        "    predictions_made = 0\n",
        "    bar_time = pd.NaT\n",
        "    price = float(\"nan\")\n",
        "    equity = float(\"nan\")\n",
        "\n",
        "    # Ensure summary fields are always defined\n",
        "    orders_submitted = 0\n",
        "    market_closed = 0\n",
        "\n",
        "    if obs is not None:\n",
        "        try:\n",
        "            target_w, conf, raw = infer_target_weight(model, vecnorm, obs)\n",
        "            signal = int(target_w > 0.0)  # 1 = Buy, 0 = Sell/Hold\n",
        "            predictions_made = 1\n",
        "            print(f\"Prediction for {ticker}: {signal} (1 = Buy, 0 = Sell)\")\n",
        "\n",
        "            # Debug details\n",
        "            bar_time = bars_df.index[-1] if not bars_df.empty else pd.NaT\n",
        "            price    = float(bars_df[\"Close\"].iloc[-1]) if not bars_df.empty else get_last_price(api, ticker)\n",
        "            equity   = get_account_equity(api)\n",
        "            print(f\"raw={raw:.4f} conf={conf:.3f} target_w={target_w:.3f} price=${price:.2f} equity=${equity:,.2f}\")\n",
        "\n",
        "            # Log to CSV\n",
        "            log_trade(ticker, bar_time, signal, raw, target_w, conf, price, equity,\n",
        "                      dry_run=dry_run, note=\"diagnostic\")\n",
        "\n",
        "            # Single (non-duplicated) order submission block\n",
        "            try:\n",
        "                clock = api.get_clock()\n",
        "                if not clock.is_open:\n",
        "                    print(\"Market is closed.\")\n",
        "                    market_closed = 1\n",
        "                else:\n",
        "                    if signal is not None:\n",
        "                        FORCE_FIRST_BUY = os.getenv(\"FORCE_FIRST_BUY\",\"0\").lower() in (\"1\",\"true\",\"yes\")\n",
        "                        if not dry_run:\n",
        "                            # Do we already hold UNH?\n",
        "                            has_position = False\n",
        "                            try:\n",
        "                                pos = api.get_position(ticker)\n",
        "                                has_position = float(pos.qty) > 0\n",
        "                            except APIError:\n",
        "                                has_position = False\n",
        "\n",
        "                            # Force a first 1-share buy OR follow the model if it says BUY\n",
        "                            if (FORCE_FIRST_BUY and not has_position) or (signal == 1 and not has_position):\n",
        "                                api.submit_order(symbol=ticker, qty=1, side=\"buy\", type=\"market\", time_in_force=\"day\")\n",
        "                                print(f\"BUY order submitted for {ticker}\")\n",
        "                                orders_submitted += 1\n",
        "                            elif signal == 0 and has_position:\n",
        "                                api.submit_order(symbol=ticker, qty=1, side=\"sell\", type=\"market\", time_in_force=\"day\")\n",
        "                                print(f\"SELL order submitted for {ticker}\")\n",
        "                                orders_submitted += 1\n",
        "                            else:\n",
        "                                print(f\"No action taken for {ticker}\")\n",
        "                        else:\n",
        "                            print(f\"(dry-run) No order submitted for {ticker} — signal={signal}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Trade/clock error for {ticker}: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error for {ticker}: {e}\")\n",
        "\n",
        "    # Snapshot end + summary\n",
        "    try:\n",
        "        positions_end = len(api.list_positions())\n",
        "        orders_end    = len(api.list_orders(status=\"open\"))\n",
        "        print(\"\\n========== SUMMARY ==========\")\n",
        "        print(f\"Processed:         1\")\n",
        "        print(f\"Models loaded:     1\")\n",
        "        print(f\"Predictions made:  {predictions_made}\")\n",
        "        print(f\"Market closed:     {market_closed}\")\n",
        "        print(f\"Orders submitted:  {orders_submitted} (dry_run={dry_run})\")\n",
        "        print(f\"Existing positions (start -> end): {positions_start} -> {positions_end}\")\n",
        "        print(f\"Open orders        (start -> end): {orders_start} -> {orders_end}\")\n",
        "        print(\"=============================\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        \"signal\": signal,\n",
        "        \"target_w\": target_w,\n",
        "        \"conf\": conf,\n",
        "        \"raw\": raw,\n",
        "        \"bar_time\": bar_time,\n",
        "        \"price\": price,\n",
        "        \"equity\": equity,\n",
        "        \"dry_run\": dry_run,\n",
        "    }\n",
        "\n",
        "# =========================================================================================\n",
        "# Fills / plotting utilities (optional visualization)\n",
        "# =========================================================================================\n",
        "SESSION_START = now_utc()\n",
        "\n",
        "def _rfc3339(dt_utc: datetime) -> str:\n",
        "    if dt_utc.tzinfo is None:\n",
        "        dt_utc = dt_utc.replace(tzinfo=timezone.utc)\n",
        "    else:\n",
        "        dt_utc = dt_utc.astimezone(timezone.utc)\n",
        "    return dt_utc.isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "def get_fills_since(api, symbol: str, since_utc: datetime):\n",
        "    try:\n",
        "        acts = api.get_activities(activity_types=\"FILL\", after=_rfc3339(since_utc))\n",
        "    except Exception as e:\n",
        "        logging.warning(\"get_activities(FILL) failed: %s\", e)\n",
        "        return []\n",
        "    fills = []\n",
        "    for a in acts or []:\n",
        "        sym = getattr(a, \"symbol\", None) or getattr(a, \"order_symbol\", None)\n",
        "        if str(sym or \"\") != symbol:\n",
        "            continue\n",
        "        t_raw = getattr(a, \"transaction_time\", None) or getattr(a, \"filled_at\", None) or getattr(a, \"activity_time\", None)\n",
        "        try:\n",
        "            ts = pd.to_datetime(t_raw, utc=True)\n",
        "        except Exception:\n",
        "            continue\n",
        "        fills.append({\n",
        "            \"symbol\": symbol,\n",
        "            \"side\":   (getattr(a, \"side\", \"\") or \"\").lower(),\n",
        "            \"qty\":    float(getattr(a, \"qty\", 0) or 0),\n",
        "            \"price\":  float(getattr(a, \"price\", np.nan)) if hasattr(a, \"price\") else np.nan,\n",
        "            \"ts\":     ts\n",
        "        })\n",
        "    fills.sort(key=lambda x: x[\"ts\"])\n",
        "    return fills\n",
        "\n",
        "def _bars_between(api, symbol: str, start_utc: pd.Timestamp, end_utc: pd.Timestamp) -> pd.DataFrame:\n",
        "    try:\n",
        "        mins = max(30, int((end_utc - start_utc).total_seconds() // 60) + 5)\n",
        "        df = get_recent_bars(api, symbol, limit=mins, timeframe=TimeFrame.Minute)\n",
        "        df = df.loc[(df.index >= start_utc) & (df.index <= end_utc)]\n",
        "        if not df.empty:\n",
        "            return df\n",
        "    except Exception:\n",
        "        pass\n",
        "    bars = api.get_bars(\n",
        "        symbol,\n",
        "        TimeFrame.Minute,\n",
        "        start=start_utc.isoformat().replace(\"+00:00\", \"Z\"),\n",
        "        end=end_utc.isoformat().replace(\"+00:00\", \"Z\"),\n",
        "    )\n",
        "    if hasattr(bars, \"df\"):\n",
        "        df = bars.df.copy()\n",
        "        if isinstance(df.index, pd.MultiIndex):\n",
        "            df = df.xs(symbol, level=0)\n",
        "        df.index = pd.to_datetime(df.index, utc=True)\n",
        "        df = df.rename(columns={\"open\":\"Open\",\"high\":\"High\",\"low\":\"Low\",\"close\":\"Close\",\"volume\":\"Volume\"})\n",
        "        return df[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]].sort_index()\n",
        "    rows = []\n",
        "    for b in bars:\n",
        "        rows.append({\n",
        "            \"timestamp\": pd.to_datetime(getattr(b, \"t\", None), utc=True),\n",
        "            \"Open\":  float(getattr(b, \"o\", getattr(b, \"open\", np.nan))),\n",
        "            \"High\":  float(getattr(b, \"h\", getattr(b, \"high\", np.nan))),\n",
        "            \"Low\":   float(getattr(b, \"l\", getattr(b, \"low\", np.nan))),\n",
        "            \"Close\": float(getattr(b, \"c\", getattr(b, \"close\", np.nan))),\n",
        "            \"Volume\":float(getattr(b, \"v\", getattr(b, \"volume\", np.nan))),\n",
        "        })\n",
        "    return pd.DataFrame(rows).set_index(\"timestamp\").sort_index()\n",
        "\n",
        "def plot_live_trades(api, symbol: str, since_utc: datetime, window_before=\"30min\", window_after=\"30min\"):\n",
        "    fills = get_fills_since(api, symbol, since_utc)\n",
        "    if not fills:\n",
        "        print(f\"No new fills for {symbol}; not plotting.\")\n",
        "        return\n",
        "    first_ts = min(f[\"ts\"] for f in fills)\n",
        "    last_ts  = max(f[\"ts\"] for f in fills)\n",
        "    start = first_ts - pd.Timedelta(window_before)\n",
        "    end   = last_ts  + pd.Timedelta(window_after)\n",
        "\n",
        "    df = _bars_between(api, symbol, start, end)\n",
        "    if df.empty:\n",
        "        print(f\"No bars available around fills for {symbol}; not plotting.\")\n",
        "        return\n",
        "\n",
        "    tz = \"America/New_York\"\n",
        "    idx_ny = df.index.tz_convert(tz)\n",
        "    close = df[\"Close\"]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(idx_ny, close.values, lw=2, label=f\"{symbol} Close\")\n",
        "    for f in fills:\n",
        "        ts_ny = f[\"ts\"].tz_convert(tz)\n",
        "        try:\n",
        "            near_idx = close.index.get_indexer([f[\"ts\"]], method=\"nearest\")[0]\n",
        "            y = close.iloc[near_idx]\n",
        "        except Exception:\n",
        "            y = np.nan\n",
        "        if f[\"side\"] == \"buy\":\n",
        "            plt.scatter([ts_ny], [y], marker=\"^\", s=80, label=\"BUY fill\", zorder=5)\n",
        "        elif f[\"side\"] == \"sell\":\n",
        "            plt.scatter([ts_ny], [y], marker=\"v\", s=80, label=\"SELL fill\", zorder=5)\n",
        "        else:\n",
        "            plt.scatter([ts_ny], [y], s=70, label=\"FILL\", zorder=5)\n",
        "        plt.axvline(ts_ny, linestyle=\"--\", alpha=0.2)\n",
        "    plt.title(f\"{symbol} — Live fills\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# =========================================================================================\n",
        "# Runner\n",
        "# =========================================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Keys loaded: %s/%s | BASE_URL=%s\", bool(API_KEY), bool(API_SECRET), BASE_URL)\n",
        "    try:\n",
        "        api = init_alpaca()\n",
        "        acct = api.get_account()\n",
        "        logging.info(\"Account status: %s | equity=%s | cash=%s\", acct.status, acct.equity, acct.cash)\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Failed to initialize Alpaca: %s\", e)\n",
        "        raise\n",
        "\n",
        "    # (Optional) BEFORE/AFTER override of sizing behavior\n",
        "    print(\"BEFORE override ->\", \"SIZING_MODE:\", SIZING_MODE, \"| CONF_FLOOR:\", CONF_FLOOR)\n",
        "    os.environ[\"SIZING_MODE\"] = \"threshold\"\n",
        "    os.environ[\"CONF_FLOOR\"]  = \"0.10\"   # lower than default 0.20\n",
        "    apply_env_overrides()\n",
        "    print(\"AFTER  override ->\", \"SIZING_MODE:\", SIZING_MODE, \"| CONF_FLOOR:\", CONF_FLOOR)\n",
        "\n",
        "    if os.getenv(\"AUTO_RUN_LIVE\", \"0\").lower() in (\"1\", \"true\", \"yes\"):\n",
        "        if not TICKERS:\n",
        "            raise SystemExit(\"No TICKERS provided (env var TICKERS).\")\n",
        "        run_live(TICKERS)\n",
        "    else:\n",
        "        res = unh_diagnostic(dry_run=DRY_RUN, timeframe=TimeFrame.Minute, limit=300)\n",
        "        # Optional: plot fills for UNH during this session\n",
        "        # plot_live_trades(api, \"UNH\", since_utc=SESSION_START)\n",
        "\n"
      ],
      "metadata": {
        "id": "cM2YQVmcZjEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_live_trades(api, \"UNH\", since_utc=SESSION_START)\n"
      ],
      "metadata": {
        "id": "YiJ7Y-beIwln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Predict\n",
        "    signal = None\n",
        "    target_w = conf = raw = float(\"nan\")\n",
        "    predictions_made = 0\n",
        "    if obs is not None:\n",
        "        try:\n",
        "            target_w, conf, raw = infer_target_weight(model, vecnorm, obs)\n",
        "            signal = int(target_w > 0.0)  # 1 = Buy, 0 = Sell/Hold\n",
        "            predictions_made = 1\n",
        "            print(f\"Prediction for {ticker}: {signal} (1 = Buy, 0 = Sell)\")\n",
        "\n",
        "            # --- debug details (add these lines) ---\n",
        "            bar_time = bars_df.index[-1] if not bars_df.empty else pd.NaT\n",
        "            price    = float(bars_df[\"Close\"].iloc[-1]) if not bars_df.empty else get_last_price(api, ticker)\n",
        "            equity   = get_account_equity(api)\n",
        "            print(f\"raw={raw:.4f} conf={conf:.3f} target_w={target_w:.3f} price=${price:.2f} equity=${equity:,.2f}\")\n",
        "            # ---------------------------------------\n",
        "\n",
        "            # log to CSV (keep this)\n",
        "            log_trade(ticker, bar_time, signal, raw, target_w, conf, price, equity,\n",
        "                      dry_run=dry_run, note=\"diagnostic\")\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error for {ticker}: {e}\")\n"
      ],
      "metadata": {
        "id": "NxQxxoxoT6nr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}